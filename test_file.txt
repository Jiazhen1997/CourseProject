is_const=True, is_virtual=True)<\exit>
cls.add_method('IsBridge',<\exit>
'bool',<\exit>
[],<\exit>
is_const=True, is_virtual=True)<\exit>
cls.add_method('IsPromisc',<\exit>
'bool',<\exit>
[])<\exit>
cls.add_method('NotifyPromiscTrace',<\exit>
'void',<\exit>
[param('ns3::Ptr< ns3::Packet >', 'p')])<\exit>
cls.add_method('DoSend',<\exit>
'bool',<\exit>
[param('ns3::Ptr< ns3::Packet >', 'packet'), param('ns3::Mac48Address const &', 'source'), param('ns3::Mac48Address const &', 'dest'), param('uint16_t', 'protocolNumber')],<\exit>
is_pure_virtual=True, visibility='private', is_virtual=True)<\exit>
cls.add_method('DoReceive',<\exit>
'void',<\exit>
[param('ns3::Ptr< ns3::Packet >', 'packet')],<\exit>
is_pure_virtual=True, visibility='private', is_virtual=True)<\exit>
cls.add_method('DoGetChannel',<\exit>
'ns3::Ptr< ns3::WimaxChannel >',<\exit>
[],<\exit>
is_const=True, visibility='private', is_virtual=True)<\exit>
return<\exit>
def register_Ns3AddressChecker_methods(root_module, cls):<\exit>
cls.add_constructor([])<\exit>
cls.add_constructor([param('ns3::AddressChecker const &', 'arg0')])<\exit>
return<\exit>
def register_Ns3AddressValue_methods(root_module, cls):<\exit>
cls.add_constructor([])<\exit>
cls.add_constructor([param('ns3::AddressValue const &', 'arg0')])<\exit>
cls.add_constructor([param('ns3::Address const &', 'value')])<\exit>
cls.add_method('Copy',<\exit>
'ns3::Ptr< ns3::AttributeValue >',<\exit>
[],<\exit>
is_const=True, is_virtual=True)<\exit>
cls.add_method('DeserializeFromString',<\exit>
'bool',<\exit>
[param('std::string', 'value'), param('ns3::Ptr< ns3::AttributeChecker const >', 'checker')],<\exit>
is_virtual=True)<\exit>
cls.add_method('Get',<\exit>
'ns3::Address',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('SerializeToString',<\exit>
'std::string',<\exit>
[param('ns3::Ptr< ns3::AttributeChecker const >', 'checker')],<\exit>
is_const=True, is_virtual=True)<\exit>
cls.add_method('Set',<\exit>
'void',<\exit>
[param('ns3::Address const &', 'value')])<\exit>
return<\exit>
def register_Ns3BaseStationNetDevice_methods(root_module, cls):<\exit>
cls.add_method('GetTypeId',<\exit>
'ns3::TypeId',<\exit>
[],<\exit>
is_static=True)<\exit>
cls.add_constructor([])<\exit>
cls.add_constructor([param('ns3::Ptr< ns3::Node >', 'node'), param('ns3::Ptr< ns3::WimaxPhy >', 'phy')])<\exit>
cls.add_constructor([param('ns3::Ptr< ns3::Node >', 'node'), param('ns3::Ptr< ns3::WimaxPhy >', 'phy'), param('ns3::Ptr< ns3::UplinkScheduler >', 'uplinkScheduler'), param('ns3::Ptr< ns3::BSScheduler >', 'bsScheduler')])<\exit>
cls.add_method('SetInitialRangingInterval',<\exit>
'void',<\exit>
[param('ns3::Time', 'initialRangInterval')])<\exit>
cls.add_method('InitBaseStationNetDevice',<\exit>
'void',<\exit>
[])<\exit>
cls.add_method('GetInitialRangingInterval',<\exit>
'ns3::Time',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('SetDcdInterval',<\exit>
'void',<\exit>
[param('ns3::Time', 'dcdInterval')])<\exit>
cls.add_method('GetDcdInterval',<\exit>
'ns3::Time',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('SetUcdInterval',<\exit>
'void',<\exit>
[param('ns3::Time', 'ucdInterval')])<\exit>
cls.add_method('GetUcdInterval',<\exit>
'ns3::Time',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('SetIntervalT8',<\exit>
'void',<\exit>
[param('ns3::Time', 'interval')])<\exit>
cls.add_method('GetIntervalT8',<\exit>
'ns3::Time',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('SetMaxRangingCorrectionRetries',<\exit>
'void',<\exit>
[param('uint8_t', 'maxRangCorrectionRetries')])<\exit>
cls.add_method('GetMaxRangingCorrectionRetries',<\exit>
'uint8_t',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('SetMaxInvitedRangRetries',<\exit>
'void',<\exit>
[param('uint8_t', 'maxInvitedRangRetries')])<\exit>
cls.add_method('GetMaxInvitedRangRetries',<\exit>
'uint8_t',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('SetRangReqOppSize',<\exit>
'void',<\exit>
[param('uint8_t', 'rangReqOppSize')])<\exit>
cls.add_method('GetRangReqOppSize',<\exit>
'uint8_t',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('SetBwReqOppSize',<\exit>
'void',<\exit>
[param('uint8_t', 'bwReqOppSize')])<\exit>
cls.add_method('GetBwReqOppSize',<\exit>
'uint8_t',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('SetNrDlSymbols',<\exit>
'void',<\exit>
[param('uint32_t', 'dlSymbols')])<\exit>
cls.add_method('GetNrDlSymbols',<\exit>
'uint32_t',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('SetNrUlSymbols',<\exit>
'void',<\exit>
[param('uint32_t', 'ulSymbols')])<\exit>
cls.add_method('GetNrUlSymbols',<\exit>
'uint32_t',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('GetNrDcdSent',<\exit>
'uint32_t',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('GetNrUcdSent',<\exit>
'uint32_t',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('GetDlSubframeStartTime',<\exit>
'ns3::Time',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('GetUlSubframeStartTime',<\exit>
'ns3::Time',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('GetRangingOppNumber',<\exit>
'uint8_t',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('GetSSManager',<\exit>
'ns3::Ptr< ns3::SSManager >',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('SetSSManager',<\exit>
'void',<\exit>
[param('ns3::Ptr< ns3::SSManager >', 'ssManager')])<\exit>
cls.add_method('GetUplinkScheduler',<\exit>
'ns3::Ptr< ns3::UplinkScheduler >',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('SetUplinkScheduler',<\exit>
'void',<\exit>
[param('ns3::Ptr< ns3::UplinkScheduler >', 'ulScheduler')])<\exit>
cls.add_method('GetLinkManager',<\exit>
'ns3::Ptr< ns3::BSLinkManager >',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('SetBSScheduler',<\exit>
'void',<\exit>
[param('ns3::Ptr< ns3::BSScheduler >', 'bsSchedule')])<\exit>
cls.add_method('GetBSScheduler',<\exit>
'ns3::Ptr< ns3::BSScheduler >',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('SetLinkManager',<\exit>
'void',<\exit>
[param('ns3::Ptr< ns3::BSLinkManager >', 'linkManager')])<\exit>
cls.add_method('GetBsClassifier',<\exit>
'ns3::Ptr< ns3::IpcsClassifier >',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('SetBsClassifier',<\exit>
'void',<\exit>
[param('ns3::Ptr< ns3::IpcsClassifier >', 'classifier')])<\exit>
cls.add_method('GetPsDuration',<\exit>
'ns3::Time',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('GetSymbolDuration',<\exit>
'ns3::Time',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('Start',<\exit>
'void',<\exit>
[],<\exit>
is_virtual=True)<\exit>
cls.add_method('Stop',<\exit>
'void',<\exit>
[],<\exit>
is_virtual=True)<\exit>
cls.add_method('Enqueue',<\exit>
'bool',<\exit>
[param('ns3::Ptr< ns3::Packet >', 'packet'), param('ns3::MacHeaderType const &', 'hdrType'), param('ns3::Ptr< ns3::WimaxConnection >', 'connection')],<\exit>
is_virtual=True)<\exit>
cls.add_method('GetConnection',<\exit>
'ns3::Ptr< ns3::WimaxConnection >',<\exit>
[param('ns3::Cid', 'cid')])<\exit>
cls.add_method('MarkUplinkAllocations',<\exit>
'void',<\exit>
[])<\exit>
cls.add_method('MarkRangingOppStart',<\exit>
'void',<\exit>
[param('ns3::Time', 'rangingOppStartTime')])<\exit>
cls.add_method('GetServiceFlowManager',<\exit>
'ns3::Ptr< ns3::BsServiceFlowManager >',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('SetServiceFlowManager',<\exit>
'void',<\exit>
[param('ns3::Ptr< ns3::BsServiceFlowManager >', 'arg0')])<\exit>
cls.add_method('DoDispose',<\exit>
'void',<\exit>
[],<\exit>
visibility='private', is_virtual=True)<\exit>
cls.add_method('DoSend',<\exit>
'bool',<\exit>
[param('ns3::Ptr< ns3::Packet >', 'packet'), param('ns3::Mac48Address const &', 'source'), param('ns3::Mac48Address const &', 'dest'), param('uint16_t', 'protocolNumber')],<\exit>
visibility='private', is_virtual=True)<\exit>
cls.add_method('DoReceive',<\exit>
'void',<\exit>
[param('ns3::Ptr< ns3::Packet >', 'packet')],<\exit>
visibility='private', is_virtual=True)<\exit>
return<\exit>
def register_Ns3SimpleOfdmWimaxChannel_methods(root_module, cls):<\exit>
cls.add_constructor([param('ns3::SimpleOfdmWimaxChannel const &', 'arg0')])<\exit>
cls.add_constructor([])<\exit>
cls.add_constructor([param('ns3::SimpleOfdmWimaxChannel::PropModel', 'propModel')])<\exit>
cls.add_method('Send',<\exit>
'void',<\exit>
[param('ns3::Time', 'BlockTime'), param('uint32_t', 'burstSize'), param('ns3::Ptr< ns3::WimaxPhy >', 'phy'), param('bool', 'isFirstBlock'), param('bool', 'isLastBlock'), param('uint64_t', 'frequency'), param('ns3::WimaxPhy::ModulationType', 'modulationType'), param('uint8_t', 'direction'), param('double', 'txPowerDbm'), param('ns3::Ptr< ns3::PacketBurst >', 'burst')])<\exit>
cls.add_method('SetPropagationModel',<\exit>
'void',<\exit>
[param('ns3::SimpleOfdmWimaxChannel::PropModel', 'propModel')])<\exit>
cls.add_method('DoAttach',<\exit>
'void',<\exit>
[param('ns3::Ptr< ns3::WimaxPhy >', 'phy')],<\exit>
visibility='private', is_virtual=True)<\exit>
cls.add_method('DoGetDevice',<\exit>
'ns3::Ptr< ns3::NetDevice >',<\exit>
[param('uint32_t', 'i')],<\exit>
is_const=True, visibility='private', is_virtual=True)<\exit>
cls.add_method('DoGetNDevices',<\exit>
'uint32_t',<\exit>
[],<\exit>
is_const=True, visibility='private', is_virtual=True)<\exit>
return<\exit>
def register_Ns3SubscriberStationNetDevice_methods(root_module, cls):<\exit>
cls.add_instance_attribute('m_linkManager', 'ns3::Ptr< ns3::SSLinkManager >', is_const=False)<\exit>
cls.add_method('GetTypeId',<\exit>
'ns3::TypeId',<\exit>
[],<\exit>
is_static=True)<\exit>
cls.add_constructor([])<\exit>
cls.add_constructor([param('ns3::Ptr< ns3::Node >', 'arg0'), param('ns3::Ptr< ns3::WimaxPhy >', 'arg1')])<\exit>
cls.add_method('InitSubscriberStationNetDevice',<\exit>
'void',<\exit>
[])<\exit>
cls.add_method('SetLostDlMapInterval',<\exit>
'void',<\exit>
[param('ns3::Time', 'lostDlMapInterval')])<\exit>
cls.add_method('GetLostDlMapInterval',<\exit>
'ns3::Time',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('SetLostUlMapInterval',<\exit>
'void',<\exit>
[param('ns3::Time', 'lostUlMapInterval')])<\exit>
cls.add_method('GetLostUlMapInterval',<\exit>
'ns3::Time',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('SetMaxDcdInterval',<\exit>
'void',<\exit>
[param('ns3::Time', 'maxDcdInterval')])<\exit>
cls.add_method('GetMaxDcdInterval',<\exit>
'ns3::Time',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('SetMaxUcdInterval',<\exit>
'void',<\exit>
[param('ns3::Time', 'maxUcdInterval')])<\exit>
cls.add_method('GetMaxUcdInterval',<\exit>
'ns3::Time',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('SetIntervalT1',<\exit>
'void',<\exit>
[param('ns3::Time', 'interval1')])<\exit>
cls.add_method('GetIntervalT1',<\exit>
'ns3::Time',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('SetIntervalT2',<\exit>
'void',<\exit>
[param('ns3::Time', 'interval2')])<\exit>
cls.add_method('GetIntervalT2',<\exit>
'ns3::Time',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('SetIntervalT3',<\exit>
'void',<\exit>
[param('ns3::Time', 'interval3')])<\exit>
cls.add_method('GetIntervalT3',<\exit>
'ns3::Time',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('SetIntervalT7',<\exit>
'void',<\exit>
[param('ns3::Time', 'interval7')])<\exit>
cls.add_method('GetIntervalT7',<\exit>
'ns3::Time',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('SetIntervalT12',<\exit>
'void',<\exit>
[param('ns3::Time', 'interval12')])<\exit>
cls.add_method('GetIntervalT12',<\exit>
'ns3::Time',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('SetIntervalT20',<\exit>
'void',<\exit>
[param('ns3::Time', 'interval20')])<\exit>
cls.add_method('GetIntervalT20',<\exit>
'ns3::Time',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('SetIntervalT21',<\exit>
'void',<\exit>
[param('ns3::Time', 'interval21')])<\exit>
cls.add_method('GetIntervalT21',<\exit>
'ns3::Time',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('SetMaxContentionRangingRetries',<\exit>
'void',<\exit>
[param('uint8_t', 'maxContentionRangingRetries')])<\exit>
cls.add_method('GetMaxContentionRangingRetries',<\exit>
'uint8_t',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('SetBasicConnection',<\exit>
'void',<\exit>
[param('ns3::Ptr< ns3::WimaxConnection >', 'basicConnection')])<\exit>
cls.add_method('GetBasicConnection',<\exit>
'ns3::Ptr< ns3::WimaxConnection >',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('SetPrimaryConnection',<\exit>
'void',<\exit>
[param('ns3::Ptr< ns3::WimaxConnection >', 'primaryConnection')])<\exit>
cls.add_method('GetPrimaryConnection',<\exit>
'ns3::Ptr< ns3::WimaxConnection >',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('GetBasicCid',<\exit>
'ns3::Cid',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('GetPrimaryCid',<\exit>
'ns3::Cid',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('SetModulationType',<\exit>
'void',<\exit>
[param('ns3::WimaxPhy::ModulationType', 'modulationType')])<\exit>
cls.add_method('GetModulationType',<\exit>
'ns3::WimaxPhy::ModulationType',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('SetAreManagementConnectionsAllocated',<\exit>
'void',<\exit>
[param('bool', 'areManagementConnectionsAllocated')])<\exit>
cls.add_method('GetAreManagementConnectionsAllocated',<\exit>
'bool',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('SetAreServiceFlowsAllocated',<\exit>
'void',<\exit>
[param('bool', 'areServiceFlowsAllocated')])<\exit>
cls.add_method('GetAreServiceFlowsAllocated',<\exit>
'bool',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('GetScheduler',<\exit>
'ns3::Ptr< ns3::SSScheduler >',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('SetScheduler',<\exit>
'void',<\exit>
[param('ns3::Ptr< ns3::SSScheduler >', 'ssScheduler')])<\exit>
cls.add_method('HasServiceFlows',<\exit>
'bool',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('Enqueue',<\exit>
'bool',<\exit>
[param('ns3::Ptr< ns3::Packet >', 'packet'), param('ns3::MacHeaderType const &', 'hdrType'), param('ns3::Ptr< ns3::WimaxConnection >', 'connection')],<\exit>
is_virtual=True)<\exit>
cls.add_method('SendBurst',<\exit>
'void',<\exit>
[param('uint8_t', 'uiuc'), param('uint16_t', 'nrSymbols'), param('ns3::Ptr< ns3::WimaxConnection >', 'connection'), param('ns3::MacHeaderType::HeaderType', 'packetType', default_value='::ns3::MacHeaderType::HEADER_TYPE_GENERIC')])<\exit>
cls.add_method('Start',<\exit>
'void',<\exit>
[],<\exit>
is_virtual=True)<\exit>
cls.add_method('Stop',<\exit>
'void',<\exit>
[],<\exit>
is_virtual=True)<\exit>
cls.add_method('AddServiceFlow',<\exit>
'void',<\exit>
[param('ns3::ServiceFlow *', 'sf')])<\exit>
cls.add_method('AddServiceFlow',<\exit>
'void',<\exit>
[param('ns3::ServiceFlow', 'sf')])<\exit>
cls.add_method('SetTimer',<\exit>
'void',<\exit>
[param('ns3::EventId', 'eventId'), param('ns3::EventId &', 'event')])<\exit>
cls.add_method('IsRegistered',<\exit>
'bool',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('GetTimeToAllocation',<\exit>
'ns3::Time',<\exit>
[param('ns3::Time', 'defferTime')])<\exit>
cls.add_method('GetIpcsClassifier',<\exit>
'ns3::Ptr< ns3::IpcsClassifier >',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('SetIpcsPacketClassifier',<\exit>
'void',<\exit>
[param('ns3::Ptr< ns3::IpcsClassifier >', 'arg0')])<\exit>
cls.add_method('GetLinkManager',<\exit>
'ns3::Ptr< ns3::SSLinkManager >',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('SetLinkManager',<\exit>
'void',<\exit>
[param('ns3::Ptr< ns3::SSLinkManager >', 'arg0')])<\exit>
cls.add_method('GetServiceFlowManager',<\exit>
'ns3::Ptr< ns3::SsServiceFlowManager >',<\exit>
[],<\exit>
is_const=True)<\exit>
cls.add_method('SetServiceFlowManager',<\exit>
'void',<\exit>
[param('ns3::Ptr< ns3::SsServiceFlowManager >', 'arg0')])<\exit>
cls.add_method('DoDispose',<\exit>
'void',<\exit>
[],<\exit>
visibility='private', is_virtual=True)<\exit>
cls.add_method('DoSend',<\exit>
'bool',<\exit>
[param('ns3::Ptr< ns3::Packet >', 'packet'), param('ns3::Mac48Address const &', 'source'), param('ns3::Mac48Address const &', 'dest'), param('uint16_t', 'protocolNumber')],<\exit>
visibility='private', is_virtual=True)<\exit>
cls.add_method('DoReceive',<\exit>
'void',<\exit>
[param('ns3::Ptr< ns3::Packet >', 'packet')],<\exit>
visibility='private', is_virtual=True)<\exit>
return<\exit>
def register_functions(root_module):<\exit>
module = root_module<\exit>
module.add_function('CRC8Calculate',<\exit>
'uint8_t',<\exit>
[param('uint8_t const *', 'data'), param('int', 'length')])<\exit>
register_functions_ns3_FatalImpl(module.get_submodule('FatalImpl'), root_module)<\exit>
register_functions_ns3_internal(module.get_submodule('internal'), root_module)<\exit>
return<\exit>
def register_functions_ns3_FatalImpl(module, root_module):<\exit>
return<\exit>
def register_functions_ns3_internal(module, root_module):<\exit>
return<\exit>
def main():<\exit>
out = FileCodeSink(sys.stdout)<\exit>
root_module = module_init()<\exit>
register_types(root_module)<\exit>
register_methods(root_module)<\exit>
register_functions(root_module)<\exit>
root_module.generate(out)<\exit>
if __name__ == '__main__':<\exit>
main()<\exit>
from pybindgen import Module, FileCodeSink, write_preamble, param, retval<\exit>
def register_types(module):<\exit>
module.add_class('MyClass')<\exit>
def register_methods(root_module):<\exit>
MyClass = root_module['MyClass']<\exit>
MyClass.add_constructor([], visibility='public')<\exit>
MyClass.add_constructor([param('double', 's'), param('double', 'l'), param('double', 'mean')], visibility='public')<\exit>
def register_functions(module):<\exit>
module.add_function('SomeFunction', 'int', [param('int', 'xpto')])<\exit>
MOD = 10 ** 9<\exit>
class Solution(object):<\exit>
def solve(self, n):<\exit>
result = []<\exit>
comb = 1<\exit>
result.append(comb)<\exit>
for i in xrange(1, n + 1):<\exit>
comb = comb * (n + 1 - i) / i<\exit>
result.append(comb % MOD)<\exit>
return " ".join(map(str, result))<\exit>
if __name__ == "__main__":<\exit>
import sys<\exit>
f = open("1.in", "r")<\exit>
testcases = int(f.readline().strip())<\exit>
for t in xrange(testcases):<\exit>
cipher = int(f.readline().strip())<\exit>
s = "%s\n" % (Solution().solve(cipher))<\exit>
print s,<\exit>
import numpy as np<\exit>
import math<\exit>
from sklearn.neighbors import NearestNeighbors as nn<\exit>
from facerec_py.facerec.feature import *<\exit>
from facerec_py.facerec.util import *<\exit>
class train():<\exit>
def __init__(self):<\exit>
self.mat = []<\exit>
self.labels = []<\exit>
self.dim = 0<\exit>
self.N = 0<\exit>
self.totalClass = 0<\exit>
class NDAFisher(AbstractFeature):<\exit>
def __init__(self, num_components=100):<\exit>
AbstractFeature.__init__(self)<\exit>
self._num_components = num_components<\exit>
def compute(self, X, y):<\exit>
nda = NDA()<\exit>
pca = PCA(self._num_components)<\exit>
model = ChainOperator(pca, nda)<\exit>
model.compute(X, y)<\exit>
self._eigenvectors = np.dot(pca.eigenvectors, nda.W.T)<\exit>
features = []<\exit>
for x in X:<\exit>
xp = self.project(x.reshape(-1, 1))<\exit>
features.append(xp)<\exit>
return features<\exit>
def extract(self, X):<\exit>
X = np.asarray(X).reshape(-1, 1)<\exit>
return self.project(X)<\exit>
def project(self, X):<\exit>
return np.dot(self._eigenvectors.T, X)<\exit>
class NDA(AbstractFeature):<\exit>
def __init__(self):<\exit>
AbstractFeature.__init__(self)<\exit>
def compute(self, X, y, K=1, useweights=0):<\exit>
self.train = train()<\exit>
self.train.mat = np.array(X)<\exit>
self.train.mat = asColumnMatrix(X)<\exit>
self.train.labels = y<\exit>
self.train.N = np.size(X, 0)<\exit>
self.train.dim = np.size(X, 1)<\exit>
self.train.totalClass = len(np.unique(y))<\exit>
self.K = K<\exit>
self.dim = np.size(X, 1)<\exit>
self.origdim = self.train.dim<\exit>
self.N = np.size(X, 0)<\exit>
self.totalClass = self.train.totalClass<\exit>
self.meandata = np.mean(self.train.mat, 1, dtype='float64')<\exit>
self.train.mat = self.train.mat - np.dot(self.meandata, np.ones((1, self.train.N)))<\exit>
self.indIn = np.zeros((K, self.N))<\exit>
self.indEx = np.zeros((K, self.N))<\exit>
self.valIn = np.zeros((K, self.N))<\exit>
self.valEx = np.zeros((K, self.N))<\exit>
self.compute_within_class_matrix_whitening()<\exit>
self.mnnInn = self.compute_within_class_scatter_matrix()<\exit>
self.diffIntra = self.train.mat - self.mnnInn<\exit>
self.Wscat = np.dot(self.diffIntra, self.diffIntra.transpose())/self.diffIntra.shape[1]<\exit>
self.eval, self.evec = np.linalg.eig(self.Wscat)<\exit>
self.ind = np.argsort(self.eval, 0)<\exit>
self.eval = self.eval[self.ind]<\exit>
self.eval = np.flipud(self.eval)<\exit>
self.ind = np.flipud(self.ind)<\exit>
self.evec = self.evec[:, self.ind]<\exit>
self.wdim = np.max(np.nonzero(self.eval > math.pow(10, -8))).real<\exit>
self.evec = self.evec[:, 0:self.wdim]<\exit>
self.whiteMat = np.dot(np.diag(1/np.sqrt(self.eval[0:self.wdim])), self.evec.transpose())<\exit>
self.Wtr = np.dot(self.whiteMat, self.train.mat)<\exit>
self.compute_bet_class_cluster_dist()<\exit>
self.mnnEx = self.compute_bet_class_cluster_matrix()<\exit>
self.diffExtra = self.Wtr - self.mnnEx<\exit>
if useweights:<\exit>
self.weights = np.minimum(self.valIn[self.K-1, :], self.valEx[self.K-1, :])<\exit>
temp = np.ones((self.Wtr.shape[1],))<\exit>
temp = np.dot(temp, self.weights)<\exit>
temp = temp * self.diffExtra<\exit>
self.bscat = np.dot(temp, np.transpose(self.diffExtra)) / self.N<\exit>
else:<\exit>
self.bscat = np.dot(self.diffExtra, self.diffExtra.conj().transpose())/self.N<\exit>
self.eigval, self.evec = np.linalg.eig(self.bscat)<\exit>
self.ind = np.argsort(self.eigval)<\exit>
self.val = self.eigval[self.ind]<\exit>
self.ind = np.flipud(self.ind)<\exit>
self.eigval = self.eigval[self.ind]<\exit>
self.eigvec = self.evec[:, self.ind[0:min(self.dim, self.wdim)]]<\exit>
self.mat = np.dot(self.eigvec.conj().transpose(), self.Wtr)<\exit>
self.W = np.dot(self.eigvec.conj().transpose(), self.whiteMat)<\exit>
self.proymat = self.W<\exit>
features = []<\exit>
for x in X:<\exit>
xp = self.project(x.reshape(-1, 1))<\exit>
features.append(xp)<\exit>
return features<\exit>
def compute_bet_class_cluster_dist(self):<\exit>
for x in np.unique(self.train.labels):<\exit>
who_cl = np.where(self.train.labels == x)[0]<\exit>
who_notcl = np.where((self.train.labels != x))[0]<\exit>
self.data_intra = self.Wtr[:, who_cl]<\exit>
self.data_extra = self.Wtr[:, who_notcl]<\exit>
knn = nn().fit(self.data_extra.transpose())<\exit>
self.dextra, self.indextra = knn.kneighbors(self.data_intra.transpose())<\exit>
self.dextra = self.dextra.transpose()<\exit>
self.indextra = self.indextra.transpose()<\exit>
self.indEx[:, who_cl] = who_notcl[self.indextra[1, :]]<\exit>
self.valEx[:, who_cl] = self.dextra[1, :]<\exit>
def compute_bet_class_cluster_matrix(self):<\exit>
if self.K == 1:<\exit>
mnnEx = self.Wtr[:, map(lambda x: int(x), self.indEx[0, :])]<\exit>
else:<\exit>
mnnEx = np.zeros((np.size(self.Wtr, 0), self.train.N))<\exit>
for n in range(0, self.train.N):<\exit>
mnnEx[:, n] == np.mean(self.Wtr[:, map(lambda x: int(x), self.indEx[:, n])], 1)<\exit>
return mnnEx<\exit>
def compute_within_class_matrix_whitening(self):<\exit>
for x in np.unique(self.train.labels):<\exit>
who_cl = np.where(self.train.labels == x)[0]<\exit>
self.data_intra = self.train.mat[:, who_cl]<\exit>
knn = nn().fit(self.data_intra.transpose())<\exit>
self.dintra, self.indintra = knn.kneighbors(self.data_intra.transpose())<\exit>
self.dintra = self.dintra.transpose()<\exit>
self.indintra = self.indintra.transpose()<\exit>
self.dintra[self.K, :] = []<\exit>
self.indintra[self.K, :] = []<\exit>
self.valIn[:, who_cl] = self.dintra[1, :]<\exit>
self.indIn[:, who_cl] = who_cl[self.indintra[1, :]]<\exit>
def compute_within_class_scatter_matrix(self):<\exit>
if self.K == 1:<\exit>
mnnInn = self.train.mat[:, map(lambda x: int(x), self.indIn[0])]<\exit>
else:<\exit>
mnnInn = np.zeros((self.train.dim, self.train.N))<\exit>
for n in range(0, self.train.N):<\exit>
mean = np.mean(self.train.mat[:, map(lambda x: int(x), self.indIn[:, n])], 1)<\exit>
for x in range(0, self.train.dim):<\exit>
mnnInn[x, n] = mean[x]<\exit>
return mnnInn<\exit>
def extract(self, X):<\exit>
X = np.asarray(X).reshape(-1, 1)<\exit>
return self.project(X)<\exit>
def project(self, X):<\exit>
return np.dot(self.W, X)<\exit>
def __repr__(self):<\exit>
return "NDA"<\exit>
from argparse import ArgumentParser<\exit>
from os.path import join as path_join<\exit>
from os.path import dirname<\exit>
try:<\exit>
from json import dumps<\exit>
except ImportError:<\exit>
from sys import path as sys_path<\exit>
sys_path.append(path_join(dirname(__file__), '../server/lib/ujson'))<\exit>
from ujson import dumps<\exit>
from subprocess import PIPE, Popen<\exit>
from random import choice, randint<\exit>
from sys import stderr<\exit>
from urlparse import urlparse<\exit>
try:<\exit>
from urlparse import parse_qs<\exit>
except ImportError:<\exit>
from cgi import parse_qs<\exit>
from BaseHTTPServer import HTTPServer, BaseHTTPRequestHandler<\exit>
import re<\exit>
from sentencesplit import sentencebreaks_to_newlines<\exit>
from BIOtoStandoff import BIO_lines_to_standoff<\exit>
DOCUMENT_BOUNDARY = 'END-DOCUMENT'<\exit>
NERSUITE_SCRIPT   = path_join(dirname(__file__), './nersuite_tag.sh')<\exit>
NERSUITE_COMMAND  = [NERSUITE_SCRIPT, '-multidoc', DOCUMENT_BOUNDARY]<\exit>
ARGPARSER = ArgumentParser(description='An example HTTP tagging service using NERsuite')<\exit>
ARGPARSER.add_argument('-p', '--port', type=int, default=47111,<\exit>
help='port to run the HTTP service on (default: 47111)')<\exit>
tagger_process = None<\exit>
def run_tagger(cmd):<\exit>
global tagger_process<\exit>
try:<\exit>
tagger_process = Popen(cmd, stdin=PIPE, stdout=PIPE, bufsize=1)<\exit>
except Exception, e:<\exit>
print >> stderr, "Error running '%s':" % cmd, e<\exit>
raise<\exit>
def _apply_tagger(text):<\exit>
global tagger_process, tagger_queue<\exit>
try:<\exit>
splittext = sentencebreaks_to_newlines(text)<\exit>
except:<\exit>
print >> stderr, "Warning: sentence splitting failed for input:\n'%s'" % text<\exit>
splittext = text<\exit>
print >> tagger_process.stdin, splittext<\exit>
print >> tagger_process.stdin, DOCUMENT_BOUNDARY<\exit>
tagger_process.stdin.flush()<\exit>
response_lines = []<\exit>
while True:<\exit>
l = tagger_process.stdout.readline()<\exit>
l = l.rstrip('\n')<\exit>
if l == DOCUMENT_BOUNDARY:<\exit>
break<\exit>
response_lines.append(l)<\exit>
try:<\exit>
tagged_entities = BIO_lines_to_standoff(response_lines, text)<\exit>
except:<\exit>
print >> stderr, "Warning: BIO-to-standoff conversion failed for BIO:\n'%s'" % '\n'.join(response_lines)<\exit>
return {}<\exit>
anns = {}<\exit>
for t in tagged_entities:<\exit>
anns["T%d" % t.idNum] = {<\exit>
'type': t.eType,<\exit>
'offsets': ((t.startOff, t.endOff), ),<\exit>
'texts': (t.eText, ),<\exit>
}<\exit>
return anns<\exit>
class NERsuiteTaggerHandler(BaseHTTPRequestHandler):<\exit>
def do_GET(self):<\exit>
query = parse_qs(urlparse(self.path).query)<\exit>
try:<\exit>
json_dic = _apply_tagger(query['text'][0])<\exit>
except KeyError:<\exit>
json_dic = {}<\exit>
self.send_response(200)<\exit>
self.send_header('Content-type', 'application/json; charset=utf-8')<\exit>
self.end_headers()<\exit>
self.wfile.write(dumps(json_dic))<\exit>
print >> stderr, ('Generated %d annotations' % len(json_dic))<\exit>
def log_message(self, format, *args):<\exit>
return<\exit>
def main(args):<\exit>
argp = ARGPARSER.parse_args(args[1:])<\exit>
print >> stderr, 'Starting NERsuite ...'<\exit>
run_tagger(NERSUITE_COMMAND)<\exit>
server_class = HTTPServer<\exit>
httpd = server_class(('localhost', argp.port), NERsuiteTaggerHandler)<\exit>
print >> stderr, 'NERsuite tagger service started'<\exit>
try:<\exit>
httpd.serve_forever()<\exit>
except KeyboardInterrupt:<\exit>
pass<\exit>
httpd.server_close()<\exit>
print >> stderr, 'NERsuite tagger service stopped'<\exit>
if __name__ == '__main__':<\exit>
from sys import argv<\exit>
exit(main(argv))<\exit>
import numpy as np<\exit>
def minmax(X, low, high, minX=None, maxX=None, dtype=np.float):<\exit>
X = np.asarray(X)<\exit>
if minX is None:<\exit>
minX = np.min(X)<\exit>
if maxX is None:<\exit>
maxX = np.max(X)<\exit>
X -= float(minX)<\exit>
X /= float((maxX - minX))<\exit>
X = X * (high - low)<\exit>
X = X + low<\exit>
return np.asarray(X, dtype=dtype)<\exit>
def zscore(X, mean=None, std=None):<\exit>
X = np.asarray(X)<\exit>
if mean is None:<\exit>
mean = X.mean()<\exit>
if std is None:<\exit>
std = X.std()<\exit>
X = (X - mean) / std<\exit>
return X<\exit>
def gaussian(X, mu, sig):<\exit>
return (1/(sig*np.sqrt(2*np.pi)))*\<\exit>
np.exp(-(X-mu)**2/(2*sig**2))<\exit>
def inverse_dissim(X):<\exit>
X = np.asarray(X)<\exit>
X = zscore(X)<\exit>
X = minmax(X, 0, 10)<\exit>
return 1./(1+X)<\exit>
def vector_normalize(x):<\exit>
return x / np.linalg.norm(x)<\exit>
def gaussian_kernel(X, mu=None, sig=None):<\exit>
X = np.asarray(X)<\exit>
if mu is None:<\exit>
mu = X.mean()<\exit>
if sig is None:<\exit>
sig = X.std()<\exit>
return np.exp(-np.power(X-mu, 2)/(2*sig**2))<\exit>
from __future__ import with_statement<\exit>
import sys<\exit>
import codecs<\exit>
from datetime import datetime<\exit>
from os.path import dirname, basename, splitext, join<\exit>
import sqlite3 as sqlite<\exit>
try:<\exit>
import simstring<\exit>
except ImportError:<\exit>
errorstr =<\exit>
print >> sys.stderr, errorstr<\exit>
sys.exit(1)<\exit>
DEFAULT_INPUT_ENCODING = 'UTF-8'<\exit>
NORM_DB_STRING = 'NORM_DB_VERSION'<\exit>
NORM_DB_VERSION = '1.0.1'<\exit>
SQL_DB_FILENAME_EXTENSION = 'db'<\exit>
SS_DB_FILENAME_EXTENSION = 'ss.db'<\exit>
DEFAULT_NGRAM_LENGTH = 3<\exit>
DEFAULT_INCLUDE_MARKS = False<\exit>
MAX_ERROR_LINES = 100<\exit>
TYPE_VALUES = ["name", "attr", "info"]<\exit>
TABLE_FOR_TYPE = {<\exit>
"name" : "names",<\exit>
"attr" : "attributes",<\exit>
"info" : "infos",<\exit>
}<\exit>
TABLE_HAS_NORMVALUE = {<\exit>
"names" : True,<\exit>
"attributes" : True,<\exit>
"infos" : False,<\exit>
}<\exit>
assert set(TYPE_VALUES) == set(TABLE_FOR_TYPE.keys())<\exit>
assert set(TABLE_FOR_TYPE.values()) == set(TABLE_HAS_NORMVALUE.keys())<\exit>
CREATE_TABLE_COMMANDS = [<\exit>
,<\exit>
,<\exit>
,<\exit>
,<\exit>
,<\exit>
]<\exit>
CREATE_INDEX_COMMANDS = [<\exit>
"CREATE INDEX entities_uid ON entities (uid);",<\exit>
"CREATE INDEX names_value ON names (value);",<\exit>
"CREATE INDEX names_normvalue ON names (normvalue);",<\exit>
"CREATE INDEX names_entity_id ON names (entity_id);",<\exit>
"CREATE INDEX attributes_value ON attributes (value);",<\exit>
"CREATE INDEX attributes_normvalue ON attributes (normvalue);",<\exit>
"CREATE INDEX attributes_entity_id ON attributes (entity_id);",<\exit>
"CREATE INDEX infos_entity_id ON infos (entity_id);",<\exit>
]<\exit>
SELECT_SIMSTRING_STRINGS_COMMAND =<\exit>
def string_norm_form(s):<\exit>
return s.lower().strip().replace('-', ' ')<\exit>
def default_db_dir():<\exit>
sys.path.append(join(dirname(__file__), '..'))<\exit>
try:<\exit>
from config import WORK_DIR<\exit>
return WORK_DIR<\exit>
except ImportError:<\exit>
print >> sys.stderr, "Warning: failed to determine brat work directory, using current instead."<\exit>
return "."<\exit>
def argparser():<\exit>
import argparse<\exit>
ap=argparse.ArgumentParser(description="Create normalization DBs for given file")<\exit>
ap.add_argument("-v", "--verbose", default=False, action="store_true", help="Verbose output")<\exit>
ap.add_argument("-d", "--database", default=None, help="Base name of databases to create (default by input file name in brat work directory)")<\exit>
ap.add_argument("-e", "--encoding", default=DEFAULT_INPUT_ENCODING, help="Input text encoding (default "+DEFAULT_INPUT_ENCODING+")")<\exit>
ap.add_argument("file", metavar="FILE", help="Normalization data")<\exit>
return ap<\exit>
def sqldb_filename(dbname):<\exit>
return join(default_db_dir(), dbname+'.'+SQL_DB_FILENAME_EXTENSION)<\exit>
def ssdb_filename(dbname):<\exit>
return join(default_db_dir(), dbname+'.'+SS_DB_FILENAME_EXTENSION)<\exit>
def main(argv):<\exit>
arg = argparser().parse_args(argv[1:])<\exit>
assert DEFAULT_NGRAM_LENGTH == 3, "Error: unsupported n-gram length"<\exit>
assert DEFAULT_INCLUDE_MARKS == False, "Error: begin/end marks not supported"<\exit>
infn = arg.file<\exit>
if arg.database is None:<\exit>
bn = splitext(basename(infn))[0]<\exit>
sqldbfn = sqldb_filename(bn)<\exit>
ssdbfn = ssdb_filename(bn)<\exit>
else:<\exit>
sqldbfn = arg.database+'.'+SQL_DB_FILENAME_EXTENSION<\exit>
ssdbfn = arg.database+'.'+SS_DB_FILENAME_EXTENSION<\exit>
if arg.verbose:<\exit>
print >> sys.stderr, "Storing SQL DB as %s and" % sqldbfn<\exit>
print >> sys.stderr, "  simstring DB as %s" % ssdbfn<\exit>
start_time = datetime.now()<\exit>
import_count, duplicate_count, error_count, simstring_count = 0, 0, 0, 0<\exit>
with codecs.open(infn, 'rU', encoding=arg.encoding) as inf:<\exit>
try:<\exit>
connection = sqlite.connect(sqldbfn)<\exit>
except sqlite.OperationalError, e:<\exit>
print >> sys.stderr, "Error connecting to DB %s:" % sqldbfn, e<\exit>
return 1<\exit>
cursor = connection.cursor()<\exit>
if arg.verbose:<\exit>
print >> sys.stderr, "Creating tables ...",<\exit>
for command in CREATE_TABLE_COMMANDS:<\exit>
try:<\exit>
cursor.execute(command)<\exit>
except sqlite.OperationalError, e:<\exit>
print >> sys.stderr, "Error creating %s:" % sqldbfn, e, "(DB exists?)"<\exit>
return 1<\exit>
if arg.verbose:<\exit>
print >> sys.stderr, "done."<\exit>
print >> sys.stderr, "Importing data ...",<\exit>
next_eid = 1<\exit>
label_id = {}<\exit>
next_lid = 1<\exit>
next_pid = dict([(t,1) for t in TYPE_VALUES])<\exit>
for i, l in enumerate(inf):<\exit>
l = l.rstrip('\n')<\exit>
try:<\exit>
id_, rest = l.split('\t', 1)<\exit>
except ValueError:<\exit>
if error_count < MAX_ERROR_LINES:<\exit>
print >> sys.stderr, "Error: skipping line %d: expected tab-separated fields, got '%s'" % (i+1, l)<\exit>
elif error_count == MAX_ERROR_LINES:<\exit>
print >> sys.stderr, "(Too many errors; suppressing further error messages)"<\exit>
error_count += 1<\exit>
continue<\exit>
try:<\exit>
triples = []<\exit>
for triple in rest.split('\t'):<\exit>
type_, label, string = triple.split(':', 2)<\exit>
if type_ not in TYPE_VALUES:<\exit>
print >> sys.stderr, "Unknown TYPE %s" % type_<\exit>
triples.append((type_, label, string))<\exit>
except ValueError:<\exit>
if error_count < MAX_ERROR_LINES:<\exit>
print >> sys.stderr, "Error: skipping line %d: expected tab-separated TYPE:LABEL:STRING triples, got '%s'" % (i+1, rest)<\exit>
elif error_count == MAX_ERROR_LINES:<\exit>
print >> sys.stderr, "(Too many errors; suppressing further error messages)"<\exit>
error_count += 1<\exit>
continue<\exit>
eid = next_eid<\exit>
next_eid += 1<\exit>
try:<\exit>
cursor.execute("INSERT into entities VALUES (?, ?)", (eid, id_))<\exit>
except sqlite.IntegrityError, e:<\exit>
if error_count < MAX_ERROR_LINES:<\exit>
print >> sys.stderr, "Error inserting %s (skipping): %s" % (id_, e)<\exit>
elif error_count == MAX_ERROR_LINES:<\exit>
print >> sys.stderr, "(Too many errors; suppressing further error messages)"<\exit>
error_count += 1<\exit>
continue<\exit>
labels = set([l for t,l,s in triples])<\exit>
new_labels = [l for l in labels if l not in label_id]<\exit>
for label in new_labels:<\exit>
lid = next_lid<\exit>
next_lid += 1<\exit>
cursor.execute("INSERT into labels VALUES (?, ?)", (lid, label))<\exit>
label_id[label] = lid<\exit>
for type_, label, string in triples:<\exit>
table = TABLE_FOR_TYPE[type_]<\exit>
pid = next_pid[type_]<\exit>
next_pid[type_] += 1<\exit>
lid = label_id[label]<\exit>
if TABLE_HAS_NORMVALUE[table]:<\exit>
normstring = string_norm_form(string)<\exit>
cursor.execute("INSERT into %s VALUES (?, ?, ?, ?, ?)" % table,<\exit>
(pid, eid, lid, string, normstring))<\exit>
else:<\exit>
cursor.execute("INSERT into %s VALUES (?, ?, ?, ?)" % table,<\exit>
(pid, eid, lid, string))<\exit>
import_count += 1<\exit>
if arg.verbose and (i+1)%10000 == 0:<\exit>
print >> sys.stderr, '.',<\exit>
if arg.verbose:<\exit>
print >> sys.stderr, "done."<\exit>
if arg.verbose:<\exit>
print >> sys.stderr, "Creating indices ...",<\exit>
for command in CREATE_INDEX_COMMANDS:<\exit>
try:<\exit>
cursor.execute(command)<\exit>
except sqlite.OperationalError, e:<\exit>
print >> sys.stderr, "Error creating index", e<\exit>
return 1<\exit>
if arg.verbose:<\exit>
print >> sys.stderr, "done."<\exit>
connection.commit()<\exit>
if arg.verbose:<\exit>
print >> sys.stderr, "Creating simstring DB ...",<\exit>
try:<\exit>
ssdb = simstring.writer(ssdbfn)<\exit>
for row in cursor.execute(SELECT_SIMSTRING_STRINGS_COMMAND):<\exit>
s = row[0].encode('utf-8')<\exit>
ssdb.insert(s)<\exit>
simstring_count += 1<\exit>
ssdb.close()<\exit>
except:<\exit>
print >> sys.stderr, "Error building simstring DB"<\exit>
raise<\exit>
if arg.verbose:<\exit>
print >> sys.stderr, "done."<\exit>
cursor.close()<\exit>
delta = datetime.now() - start_time<\exit>
if arg.verbose:<\exit>
print >> sys.stderr<\exit>
print >> sys.stderr, "Done in:", str(delta.seconds)+"."+str(delta.microseconds/10000), "seconds"<\exit>
print "Done, imported %d entries (%d strings), skipped %d duplicate keys, skipped %d invalid lines" % (import_count, simstring_count, duplicate_count, error_count)<\exit>
return 0<\exit>
if __name__ == "__main__":<\exit>
sys.exit(main(sys.argv))<\exit>
import sys<\exit>
import os.path<\exit>
import sqlite3 as sqlite<\exit>
TYPE_TABLES = ["names", "attributes", "infos"]<\exit>
NON_EMPTY_TABLES = set(["names"])<\exit>
def argparser():<\exit>
import argparse<\exit>
ap=argparse.ArgumentParser(description="Print results of lookup in normalization SQL DB for keys read from STDIN.")<\exit>
ap.add_argument("-v", "--verbose", default=False, action="store_true", help="Verbose output.")<\exit>
ap.add_argument("-np", "--no-prompt", default=False, action="store_true", help="No prompt.")<\exit>
ap.add_argument("database", metavar="DATABASE", help="Name of database to read")<\exit>
return ap<\exit>
def string_norm_form(s):<\exit>
return s.lower().strip().replace('-', ' ')<\exit>
def datas_by_ids(cursor, ids):<\exit>
responses = {}<\exit>
for table in TYPE_TABLES:<\exit>
command =  % (table, ','.join(['?' for i in ids]))<\exit>
cursor.execute(command, list(ids))<\exit>
response = cursor.fetchall()<\exit>
for id_, label, value in response:<\exit>
if id_ not in responses:<\exit>
responses[id_] = {}<\exit>
if table not in responses[id_]:<\exit>
responses[id_][table] = []<\exit>
responses[id_][table].append([label, value])<\exit>
if (table in NON_EMPTY_TABLES and<\exit>
len([i for i in responses if responses[i][table] == 0]) != 0):<\exit>
return None<\exit>
for id_ in responses:<\exit>
for t in NON_EMPTY_TABLES:<\exit>
if len(responses[id_][t]) == 0:<\exit>
return None<\exit>
datas = {}<\exit>
for id_ in responses:<\exit>
datas[id_] = []<\exit>
for t in TYPE_TABLES:<\exit>
datas[id_].append(responses[id_].get(t,[]))<\exit>
return datas<\exit>
def ids_by_name(cursor, name, exactmatch=False, return_match=False):<\exit>
return ids_by_names(cursor, [name], exactmatch, return_match)<\exit>
def ids_by_names(cursor, names, exactmatch=False, return_match=False):<\exit>
if not return_match:<\exit>
command = 'SELECT E.uid'<\exit>
else:<\exit>
command = 'SELECT E.uid, N.value'<\exit>
command +=<\exit>
if exactmatch:<\exit>
command += 'WHERE N.value IN (%s)' % ','.join(['?' for n in names])<\exit>
else:<\exit>
command += 'WHERE N.normvalue IN (%s)' % ','.join(['?' for n in names])<\exit>
names = [string_norm_form(n) for n in names]<\exit>
cursor.execute(command, names)<\exit>
responses = cursor.fetchall()<\exit>
if not return_match:<\exit>
return [r[0] for r in responses]<\exit>
else:<\exit>
return [(r[0],r[1]) for r in responses]<\exit>
def main(argv):<\exit>
arg = argparser().parse_args(argv[1:])<\exit>
dbn = arg.database<\exit>
dbpaths = [dbn, os.path.join('work', dbn), os.path.join('work', dbn)+'.db']<\exit>
dbfn = None<\exit>
for p in dbpaths:<\exit>
if os.path.exists(p):<\exit>
dbfn = p<\exit>
break<\exit>
if dbfn is None:<\exit>
print >> sys.stderr, "Error: %s: no such file" % dbfn<\exit>
return 1<\exit>
try:<\exit>
connection = sqlite.connect(dbfn)<\exit>
except sqlite.OperationalError, e:<\exit>
print >> sys.stderr, "Error connecting to DB %s:" % dbfn, e<\exit>
return 1<\exit>
cursor = connection.cursor()<\exit>
while True:<\exit>
if not arg.no_prompt:<\exit>
print ">>> ",<\exit>
l = sys.stdin.readline()<\exit>
if not l:<\exit>
break<\exit>
l = l.rstrip()<\exit>
try:<\exit>
r = ids_by_name(cursor, l)<\exit>
if len(r) != 0:<\exit>
d = datas_by_ids(cursor, r)<\exit>
for i in d:<\exit>
print i+'\t', '\t'.join([' '.join(["%s:%s" % (k,v) for k,v in a]) for a in d[i]])<\exit>
elif l == '':<\exit>
print "(Use Ctrl-D to exit)"<\exit>
else:<\exit>
print "(no record found for '%s')" % l<\exit>
except Exception, e:<\exit>
print >> sys.stderr, "Unexpected error", e<\exit>
return 1<\exit>
return 0<\exit>
if __name__ == "__main__":<\exit>
sys.exit(main(sys.argv))<\exit>
import warnings<\exit>
import sys<\exit>
import os<\exit>
import pybindgen.settings<\exit>
from pybindgen import Module, FileCodeSink, param, retval, cppclass, typehandlers<\exit>
from pybindgen.module import MultiSectionFactory<\exit>
import ns3modulegen_core_customizations<\exit>
pybindgen.settings.wrapper_registry = pybindgen.settings.StdMapWrapperRegistry<\exit>
class ErrorHandler(pybindgen.settings.ErrorHandler):<\exit>
def handle_error(self, wrapper, exception, traceback_):<\exit>
warnings.warn("exception %r in wrapper %s" % (exception, wrapper))<\exit>
return True<\exit>
pybindgen.settings.error_handler = ErrorHandler()<\exit>
pybindgen.settings.gcc_rtti_abi_complete = bool(eval(os.environ["GCC_RTTI_ABI_COMPLETE"]))<\exit>
class MyMultiSectionFactory(MultiSectionFactory):<\exit>
def __init__(self, main_file_name):<\exit>
super(MyMultiSectionFactory, self).__init__()<\exit>
self.main_file_name = main_file_name<\exit>
self.main_sink = FileCodeSink(open(main_file_name, "wt"))<\exit>
self.header_name = "ns3module.h"<\exit>
header_file_name = os.path.join(os.path.dirname(self.main_file_name), self.header_name)<\exit>
self.header_sink = FileCodeSink(open(header_file_name, "wt"))<\exit>
def get_section_code_sink(self, section_name):<\exit>
return self.main_sink<\exit>
def get_main_code_sink(self):<\exit>
return self.main_sink<\exit>
def get_common_header_code_sink(self):<\exit>
return self.header_sink<\exit>
def get_common_header_include(self):<\exit>
return '"%s"' % self.header_name<\exit>
def close(self):<\exit>
self.header_sink.file.close()<\exit>
self.main_sink.file.close()<\exit>
def main(argv):<\exit>
module_abs_src_path, target, extension_name, output_cc_file_name = argv[1:]<\exit>
module_name = os.path.basename(module_abs_src_path)<\exit>
out = MyMultiSectionFactory(output_cc_file_name)<\exit>
sys.path.insert(0, os.path.join(module_abs_src_path, "bindings"))<\exit>
try:<\exit>
module_apidefs = __import__("modulegen__%s" % target)<\exit>
del sys.modules["modulegen__%s" % target]<\exit>
try:<\exit>
module_customization = __import__("modulegen_customizations")<\exit>
del sys.modules["modulegen_customizations"]<\exit>
except ImportError:<\exit>
module_customization = object()<\exit>
try:<\exit>
from callbacks_list import callback_classes<\exit>
except ImportError, ex:<\exit>
print >> sys.stderr, "***************", repr(ex)<\exit>
callback_classes = []<\exit>
else:<\exit>
print >> sys.stderr, ">>>>>>>>>>>>>>>>", repr(callback_classes)<\exit>
finally:<\exit>
sys.path.pop(0)<\exit>
root_module = module_apidefs.module_init()<\exit>
root_module.set_name(extension_name)<\exit>
root_module.add_include('"ns3/%s-module.h"' % module_name)<\exit>
ns3modulegen_core_customizations.add_std_ios_openmode(root_module)<\exit>
module_apidefs.register_types(root_module)<\exit>
if hasattr(module_customization, 'post_register_types'):<\exit>
module_customization.post_register_types(root_module)<\exit>
ns3modulegen_core_customizations.generate_callback_classes(root_module.after_forward_declarations,<\exit>
callback_classes)<\exit>
module_apidefs.register_methods(root_module)<\exit>
if hasattr(module_customization, 'post_register_methods'):<\exit>
module_customization.post_register_methods(root_module)<\exit>
ns3modulegen_core_customizations.Object_customizations(root_module)<\exit>
ns3modulegen_core_customizations.Attribute_customizations(root_module)<\exit>
module_apidefs.register_functions(root_module)<\exit>
if hasattr(module_customization, 'post_register_functions'):<\exit>
module_customization.post_register_functions(root_module)<\exit>
root_module.generate(out)<\exit>
if __name__ == '__main__':<\exit>
import sys<\exit>
main(sys.argv)<\exit>
LOCAL_MODULES = [<\exit>
]<\exit>
import sys<\exit>
import os<\exit>
sys.path.insert(0, sys.argv[2])<\exit>
from pybindgen import FileCodeSink, write_preamble<\exit>
from pybindgen.module import MultiSectionFactory<\exit>
import pybindgen.settings<\exit>
pybindgen.settings.deprecated_virtuals = False<\exit>
from ns3modulegen_generated import module_init, register_types, register_methods, register_functions<\exit>
import ns3modulegen_core_customizations<\exit>
import callbacks_list<\exit>
import traceback<\exit>
this_script_dir = os.path.dirname(os.path.abspath(sys.argv[0]))<\exit>
class ErrorHandler(pybindgen.settings.ErrorHandler):<\exit>
def handle_error(self, wrapper, exception, traceback_):<\exit>
print >> sys.stderr<\exit>
print >> sys.stderr, "---- location:"<\exit>
traceback.print_stack()<\exit>
print >> sys.stderr, "---- error:"<\exit>
traceback.print_tb(traceback_)<\exit>
try:<\exit>
stack = wrapper.stack_where_defined<\exit>
except AttributeError:<\exit>
print >> sys.stderr, "??:??: %s / %r" % (wrapper, exception)<\exit>
else:<\exit>
stack = list(stack)<\exit>
stack.reverse()<\exit>
for (filename, line_number, function_name, text) in stack:<\exit>
file_dir = os.path.dirname(os.path.abspath(filename))<\exit>
if file_dir.startswith(this_script_dir):<\exit>
print >> sys.stderr, "%s:%i: %r" % (os.path.join("..", "bindings", "python", os.path.basename(filename)),<\exit>
line_number, exception)<\exit>
break<\exit>
return True<\exit>
pybindgen.settings.error_handler = ErrorHandler()<\exit>
pybindgen.settings.wrapper_registry = pybindgen.settings.StdMapWrapperRegistry<\exit>
class MyMultiSectionFactory(MultiSectionFactory):<\exit>
def __init__(self, main_file_name, modules):<\exit>
super(MyMultiSectionFactory, self).__init__()<\exit>
self.main_file_name = main_file_name<\exit>
self.main_sink = FileCodeSink(open(main_file_name, "wt"))<\exit>
self.header_name = "ns3module.h"<\exit>
header_file_name = os.path.join(os.path.dirname(self.main_file_name), 'pch', self.header_name)<\exit>
self.header_sink = FileCodeSink(open(header_file_name, "wt"))<\exit>
self.section_sinks = {'__main__': self.main_sink}<\exit>
for module in modules:<\exit>
section_name = 'ns3_module_%s' % module.replace('-', '_')<\exit>
file_name = os.path.join(os.path.dirname(self.main_file_name), "%s.cc" % section_name)<\exit>
sink = FileCodeSink(open(file_name, "wt"))<\exit>
self.section_sinks[section_name] = sink<\exit>
def get_section_code_sink(self, section_name):<\exit>
return self.section_sinks[section_name]<\exit>
def get_main_code_sink(self):<\exit>
return self.main_sink<\exit>
def get_common_header_code_sink(self):<\exit>
return self.header_sink<\exit>
def get_common_header_include(self):<\exit>
return '"%s"' % self.header_name<\exit>
def close(self):<\exit>
self.header_sink.file.close()<\exit>
self.main_sink.file.close()<\exit>
for sink in self.section_sinks.itervalues():<\exit>
sink.file.close()<\exit>
def main():<\exit>
out = MyMultiSectionFactory(sys.argv[1], sys.argv[3:])<\exit>
root_module = module_init()<\exit>
root_module.add_include('"everything.h"')<\exit>
register_types(root_module)<\exit>
ns3modulegen_core_customizations.Simulator_customizations(root_module)<\exit>
ns3modulegen_core_customizations.CommandLine_customizations(root_module)<\exit>
ns3modulegen_core_customizations.TypeId_customizations(root_module)<\exit>
ns3modulegen_core_customizations.add_std_ofstream(root_module)<\exit>
ns3modulegen_core_customizations.add_ipv4_address_tp_hash(root_module)<\exit>
for local_module in LOCAL_MODULES:<\exit>
mod = __import__(local_module)<\exit>
mod.register_types(root_module)<\exit>
ns3modulegen_core_customizations.generate_callback_classes(root_module.after_forward_declarations,<\exit>
callbacks_list.callback_classes)<\exit>
register_methods(root_module)<\exit>
for local_module in LOCAL_MODULES:<\exit>
mod = __import__(local_module)<\exit>
mod.register_methods(root_module)<\exit>
ns3modulegen_core_customizations.Object_customizations(root_module)<\exit>
ns3modulegen_core_customizations.Attribute_customizations(root_module)<\exit>
register_functions(root_module)<\exit>
for local_module in LOCAL_MODULES:<\exit>
mod = __import__(local_module)<\exit>
mod.register_functions(root_module)<\exit>
enabled_features = os.environ['NS3_ENABLED_FEATURES'].split(',')<\exit>
if 'GtkConfigStore' not in enabled_features:<\exit>
try:<\exit>
root_module.classes.remove(root_module['ns3::GtkConfigStore'])<\exit>
except KeyError:<\exit>
pass<\exit>
if 'SqliteDataOutput' not in enabled_features:<\exit>
try:<\exit>
root_module.classes.remove(root_module['ns3::SqliteDataOutput'])<\exit>
except KeyError:<\exit>
pass<\exit>
if 'Threading' not in enabled_features:<\exit>
for clsname in ['SystemThread', 'SystemMutex', 'SystemCondition', 'CriticalSection',<\exit>
'SimpleRefCount< ns3::SystemThread, ns3::empty, ns3::DefaultDeleter<ns3::SystemThread> >']:<\exit>
root_module.classes.remove(root_module['ns3::%s' % clsname])<\exit>
if 'EmuNetDevice' not in enabled_features:<\exit>
for clsname in ['EmuNetDevice', 'EmuHelper']:<\exit>
root_module.classes.remove(root_module['ns3::%s' % clsname])<\exit>
root_module.enums.remove(root_module['ns3::EmuNetDevice::EncapsulationMode'])<\exit>
if 'RealTime' not in enabled_features:<\exit>
for clsname in ['WallClockSynchronizer', 'RealtimeSimulatorImpl']:<\exit>
root_module.classes.remove(root_module['ns3::%s' % clsname])<\exit>
root_module.enums.remove(root_module['ns3::RealtimeSimulatorImpl::SynchronizationMode'])<\exit>
if 'TapBridge' not in enabled_features:<\exit>
for clsname in ['TapBridge', 'TapBridgeHelper', 'TapBridgeFdReader']:<\exit>
root_module.classes.remove(root_module['ns3::%s' % clsname])<\exit>
root_module.enums.remove(root_module['ns3::TapBridge::Mode'])<\exit>
root_module.generate(out, '_ns3')<\exit>
out.close()<\exit>
if __name__ == '__main__':<\exit>
if 0:<\exit>
try:<\exit>
import cProfile as profile<\exit>
except ImportError:<\exit>
main()<\exit>
else:<\exit>
print >> sys.stderr, "** running under profiler"<\exit>
profile.run('main()', 'ns3modulegen.pstat')<\exit>
else:<\exit>
main()<\exit>
import re<\exit>
from pybindgen.typehandlers import base as typehandlers<\exit>
from pybindgen import ReturnValue, Parameter<\exit>
from pybindgen.cppmethod import CustomCppMethodWrapper, CustomCppConstructorWrapper<\exit>
from pybindgen.typehandlers.codesink import MemoryCodeSink<\exit>
from pybindgen.typehandlers import ctypeparser<\exit>
from pybindgen import cppclass<\exit>
import warnings<\exit>
from pybindgen.typehandlers.base import CodeGenerationError<\exit>
import sys<\exit>
class SmartPointerTransformation(typehandlers.TypeTransformation):<\exit>
def __init__(self):<\exit>
super(SmartPointerTransformation, self).__init__()<\exit>
self.rx = re.compile(r'(ns3::|::ns3::|)Ptr<([^>]+)>\s*$')<\exit>
def _get_untransformed_type_traits(self, name):<\exit>
m = self.rx.match(name)<\exit>
is_const = False<\exit>
if m is None:<\exit>
return None, False<\exit>
else:<\exit>
name1 = m.group(2).strip()<\exit>
if name1.startswith('const '):<\exit>
name1 = name1[len('const '):]<\exit>
is_const = True<\exit>
if name1.endswith(' const'):<\exit>
name1 = name1[:-len(' const')]<\exit>
is_const = True<\exit>
new_name = name1+' *'<\exit>
if new_name.startswith('::'):<\exit>
new_name = new_name[2:]<\exit>
return new_name, is_const<\exit>
def get_untransformed_name(self, name):<\exit>
new_name, dummy_is_const = self._get_untransformed_type_traits(name)<\exit>
return new_name<\exit>
def create_type_handler(self, type_handler, *args, **kwargs):<\exit>
if issubclass(type_handler, Parameter):<\exit>
kwargs['transfer_ownership'] = False<\exit>
elif issubclass(type_handler, ReturnValue):<\exit>
kwargs['caller_owns_return'] = False<\exit>
else:<\exit>
raise AssertionError<\exit>
orig_ctype, is_const = self._get_untransformed_type_traits(args[0])<\exit>
if is_const:<\exit>
correct_ctype = 'ns3::Ptr< %s const >' % orig_ctype[:-2]<\exit>
else:<\exit>
correct_ctype = 'ns3::Ptr< %s >' % orig_ctype[:-2]<\exit>
args = tuple([correct_ctype] + list(args[1:]))<\exit>
handler = type_handler(*args, **kwargs)<\exit>
handler.set_tranformation(self, orig_ctype)<\exit>
return handler<\exit>
def untransform(self, type_handler, declarations, code_block, expression):<\exit>
return 'const_cast<%s> (ns3::PeekPointer (%s))' % (type_handler.untransformed_ctype, expression)<\exit>
def transform(self, type_handler, declarations, code_block, expression):<\exit>
assert type_handler.untransformed_ctype[-1] == '*'<\exit>
return 'ns3::Ptr< %s > (%s)' % (type_handler.untransformed_ctype[:-1], expression)<\exit>
transf = SmartPointerTransformation()<\exit>
typehandlers.return_type_matcher.register_transformation(transf)<\exit>
typehandlers.param_type_matcher.register_transformation(transf)<\exit>
del transf<\exit>
class ArgvParam(Parameter):<\exit>
DIRECTIONS = [Parameter.DIRECTION_IN]<\exit>
CTYPES = []<\exit>
def convert_c_to_python(self, wrapper):<\exit>
raise NotImplementedError<\exit>
def convert_python_to_c(self, wrapper):<\exit>
py_name = wrapper.declarations.declare_variable('PyObject*', 'py_' + self.name)<\exit>
argc_var = wrapper.declarations.declare_variable('int', 'argc')<\exit>
name = wrapper.declarations.declare_variable('char**', self.name)<\exit>
idx = wrapper.declarations.declare_variable('Py_ssize_t', 'idx')<\exit>
wrapper.parse_params.add_parameter('O!', ['&PyList_Type', '&'+py_name], self.name)<\exit>
wrapper.before_call.write_code("%s = (char **) malloc(sizeof(char*)*PyList_Size(%s));"<\exit>
% (name, py_name))<\exit>
wrapper.before_call.add_cleanup_code('free(%s);' % name)<\exit>
wrapper.before_call.write_code( % vars())<\exit>
wrapper.before_call.sink.indent()<\exit>
wrapper.before_call.write_code( % vars())<\exit>
wrapper.before_call.write_error_check(<\exit>
'!PyString_Check(item)',<\exit>
failure_cleanup=('PyErr_SetString(PyExc_TypeError, '<\exit>
'"argument %s must be a list of strings");') % self.name)<\exit>
wrapper.before_call.write_code(<\exit>
'%s[%s] = PyString_AsString(item);' % (name, idx))<\exit>
wrapper.before_call.sink.unindent()<\exit>
wrapper.before_call.write_code('}')<\exit>
wrapper.before_call.write_code('%s = PyList_Size(%s);' % (argc_var, py_name))<\exit>
wrapper.call_params.append(argc_var)<\exit>
wrapper.call_params.append(name)<\exit>
class CallbackImplProxyMethod(typehandlers.ReverseWrapperBase):<\exit>
def __init__(self, return_value, parameters):<\exit>
super(CallbackImplProxyMethod, self).__init__(return_value, parameters)<\exit>
def generate_python_call(self):<\exit>
build_params = self.build_params.get_parameters(force_tuple_creation=True)<\exit>
if build_params[0][0] == '"':<\exit>
build_params[0] = '(char *) ' + build_params[0]<\exit>
args = self.before_call.declare_variable('PyObject*', 'args')<\exit>
self.before_call.write_code('%s = Py_BuildValue(%s);'<\exit>
% (args, ', '.join(build_params)))<\exit>
self.before_call.add_cleanup_code('Py_DECREF(%s);' % args)<\exit>
self.before_call.write_code('py_retval = PyObject_CallObject(m_callback, %s);' % args)<\exit>
self.before_call.write_error_check('py_retval == NULL')<\exit>
self.before_call.add_cleanup_code('Py_DECREF(py_retval);')<\exit>
def generate_callback_classes(out, callbacks):<\exit>
for callback_impl_num, template_parameters in enumerate(callbacks):<\exit>
sink = MemoryCodeSink()<\exit>
cls_name = "ns3::Callback< %s >" % ', '.join(template_parameters)<\exit>
class_name = "PythonCallbackImpl%i" % callback_impl_num<\exit>
sink.writeln( % (class_name, ', '.join(template_parameters), class_name, class_name, class_name, class_name))<\exit>
sink.indent()<\exit>
callback_return = template_parameters[0]<\exit>
return_ctype = ctypeparser.parse_type(callback_return)<\exit>
if ('const' in return_ctype.remove_modifiers()):<\exit>
kwargs = {'is_const': True}<\exit>
else:<\exit>
kwargs = {}<\exit>
try:<\exit>
return_type = ReturnValue.new(str(return_ctype), **kwargs)<\exit>
except (typehandlers.TypeLookupError, typehandlers.TypeConfigurationError), ex:<\exit>
warnings.warn("***** Unable to register callback; Return value '%s' error (used in %s): %r"<\exit>
% (callback_return, cls_name, ex),<\exit>
Warning)<\exit>
continue<\exit>
arguments = []<\exit>
ok = True<\exit>
callback_parameters = [arg for arg in template_parameters[1:] if arg != 'ns3::empty']<\exit>
for arg_num, arg_type in enumerate(callback_parameters):<\exit>
arg_name = 'arg%i' % (arg_num+1)<\exit>
param_ctype = ctypeparser.parse_type(arg_type)<\exit>
if ('const' in param_ctype.remove_modifiers()):<\exit>
kwargs = {'is_const': True}<\exit>
else:<\exit>
kwargs = {}<\exit>
try:<\exit>
arguments.append(Parameter.new(str(param_ctype), arg_name, **kwargs))<\exit>
except (typehandlers.TypeLookupError, typehandlers.TypeConfigurationError), ex:<\exit>
warnings.warn("***** Unable to register callback; parameter '%s %s' error (used in %s): %r"<\exit>
% (arg_type, arg_name, cls_name, ex),<\exit>
Warning)<\exit>
ok = False<\exit>
if not ok:<\exit>
continue<\exit>
wrapper = CallbackImplProxyMethod(return_type, arguments)<\exit>
wrapper.generate(sink, 'operator()', decl_modifiers=[])<\exit>
sink.unindent()<\exit>
sink.writeln('};\n')<\exit>
sink.flush_to(out)<\exit>
class PythonCallbackParameter(Parameter):<\exit>
"Class handlers"<\exit>
CTYPES = [cls_name]<\exit>
print >> sys.stderr, "***** registering callback handler: %r" % ctypeparser.normalize_type_string(cls_name)<\exit>
DIRECTIONS = [Parameter.DIRECTION_IN]<\exit>
PYTHON_CALLBACK_IMPL_NAME = class_name<\exit>
TEMPLATE_ARGS = template_parameters<\exit>
def convert_python_to_c(self, wrapper):<\exit>
"parses python args to get C++ value"<\exit>
assert isinstance(wrapper, typehandlers.ForwardWrapperBase)<\exit>
if self.default_value is None:<\exit>
py_callback = wrapper.declarations.declare_variable('PyObject*', self.name)<\exit>
wrapper.parse_params.add_parameter('O', ['&'+py_callback], self.name)<\exit>
wrapper.before_call.write_error_check(<\exit>
'!PyCallable_Check(%s)' % py_callback,<\exit>
'PyErr_SetString(PyExc_TypeError, "parameter \'%s\' must be callbale");' % self.name)<\exit>
callback_impl = wrapper.declarations.declare_variable(<\exit>
'ns3::Ptr<%s>' % self.PYTHON_CALLBACK_IMPL_NAME,<\exit>
'%s_cb_impl' % self.name)<\exit>
wrapper.before_call.write_code("%s = ns3::Create<%s> (%s);"<\exit>
% (callback_impl, self.PYTHON_CALLBACK_IMPL_NAME, py_callback))<\exit>
wrapper.call_params.append(<\exit>
'ns3::Callback<%s> (%s)' % (', '.join(self.TEMPLATE_ARGS), callback_impl))<\exit>
else:<\exit>
py_callback = wrapper.declarations.declare_variable('PyObject*', self.name, 'NULL')<\exit>
wrapper.parse_params.add_parameter('O', ['&'+py_callback], self.name, optional=True)<\exit>
value = wrapper.declarations.declare_variable(<\exit>
'ns3::Callback<%s>' % ', '.join(self.TEMPLATE_ARGS),<\exit>
self.name+'_value',<\exit>
self.default_value)<\exit>
wrapper.before_call.write_code("if (%s) {" % (py_callback,))<\exit>
wrapper.before_call.indent()<\exit>
wrapper.before_call.write_error_check(<\exit>
'!PyCallable_Check(%s)' % py_callback,<\exit>
'PyErr_SetString(PyExc_TypeError, "parameter \'%s\' must be callbale");' % self.name)<\exit>
wrapper.before_call.write_code("%s = ns3::Callback<%s> (ns3::Create<%s> (%s));"<\exit>
% (value, ', '.join(self.TEMPLATE_ARGS),<\exit>
self.PYTHON_CALLBACK_IMPL_NAME, py_callback))<\exit>
wrapper.before_call.unindent()<\exit>
wrapper.before_call.write_code("}")<\exit>
wrapper.call_params.append(value)<\exit>
def convert_c_to_python(self, wrapper):<\exit>
raise typehandlers.NotSupportedError("Reverse wrappers for ns3::Callback<...> types "<\exit>
"(python using callbacks defined in C++) not implemented.")<\exit>
def Simulator_customizations(module):<\exit>
Simulator = module['ns3::Simulator']<\exit>
Simulator.add_custom_method_wrapper("Schedule", "_wrap_Simulator_Schedule",<\exit>
flags=["METH_VARARGS", "METH_KEYWORDS", "METH_STATIC"])<\exit>
Simulator.add_custom_method_wrapper("ScheduleNow", "_wrap_Simulator_ScheduleNow",<\exit>
flags=["METH_VARARGS", "METH_KEYWORDS", "METH_STATIC"])<\exit>
Simulator.add_custom_method_wrapper("ScheduleDestroy", "_wrap_Simulator_ScheduleDestroy",<\exit>
flags=["METH_VARARGS", "METH_KEYWORDS", "METH_STATIC"])<\exit>
Simulator.add_custom_method_wrapper("Run", "_wrap_Simulator_Run",<\exit>
flags=["METH_VARARGS", "METH_KEYWORDS", "METH_STATIC"])<\exit>
def CommandLine_customizations(module):<\exit>
CommandLine = module['ns3::CommandLine']<\exit>
CommandLine.add_method('Parse', None, [ArgvParam(None, 'argv')],<\exit>
is_static=False)<\exit>
CommandLine.add_custom_method_wrapper("AddValue", "_wrap_CommandLine_AddValue",<\exit>
flags=["METH_VARARGS", "METH_KEYWORDS"])<\exit>
def Object_customizations(module):<\exit>
try:<\exit>
Object = module['ns3::Object']<\exit>
except KeyError:<\exit>
return<\exit>
def helper_class_hook(helper_class):<\exit>
decl =   % (helper_class.name, helper_class.class_.full_name)<\exit>
helper_class.add_custom_method(decl)<\exit>
helper_class.add_post_generation_code(<\exit>
"NS_OBJECT_ENSURE_REGISTERED (%s);" % helper_class.name)<\exit>
Object.add_helper_class_hook(helper_class_hook)<\exit>
def ns3_object_instance_creation_function(cpp_class, code_block, lvalue,<\exit>
parameters, construct_type_name):<\exit>
assert lvalue<\exit>
assert not lvalue.startswith('None')<\exit>
if cpp_class.cannot_be_constructed:<\exit>
raise CodeGenerationError("%s cannot be constructed (%s)"<\exit>
% cpp_class.full_name)<\exit>
if cpp_class.incomplete_type:<\exit>
raise CodeGenerationError("%s cannot be constructed (incomplete type)"<\exit>
% cpp_class.full_name)<\exit>
code_block.write_code("%s = new %s(%s);" % (lvalue, construct_type_name, parameters))<\exit>
code_block.write_code("%s->Ref ();" % (lvalue))<\exit>
def ns3_object_post_instance_creation_function(cpp_class, code_block, lvalue,<\exit>
parameters, construct_type_name):<\exit>
code_block.write_code("ns3::CompleteConstruct(%s);" % (lvalue, ))<\exit>
Object.set_instance_creation_function(ns3_object_instance_creation_function)<\exit>
Object.set_post_instance_creation_function(ns3_object_post_instance_creation_function)<\exit>
def Attribute_customizations(module):<\exit>
for cls in module.classes:<\exit>
for meth in cls.get_all_methods():<\exit>
for param in meth.parameters:<\exit>
if isinstance(param, cppclass.CppClassRefParameter):<\exit>
if param.cpp_class.name == 'AttributeValue' \<\exit>
and param.default_value is not None \<\exit>
and param.default_value_type is None:<\exit>
param.default_value_type = 'ns3::EmptyAttributeValue'<\exit>
def TypeId_customizations(module):<\exit>
TypeId = module['ns3::TypeId']<\exit>
TypeId.add_custom_method_wrapper("LookupByNameFailSafe", "_wrap_TypeId_LookupByNameFailSafe",<\exit>
flags=["METH_VARARGS", "METH_KEYWORDS", "METH_STATIC"])<\exit>
def add_std_ofstream(module):<\exit>
module.add_include('<fstream>')<\exit>
ostream = module.add_class('ostream', foreign_cpp_namespace='::std')<\exit>
ostream.set_cannot_be_constructed("abstract base class")<\exit>
ofstream = module.add_class('ofstream', foreign_cpp_namespace='::std', parent=ostream)<\exit>
ofstream.add_enum('openmode', [<\exit>
('app', 'std::ios_base::app'),<\exit>
('ate', 'std::ios_base::ate'),<\exit>
('binary', 'std::ios_base::binary'),<\exit>
('in', 'std::ios_base::in'),<\exit>
('out', 'std::ios_base::out'),<\exit>
('trunc', 'std::ios_base::trunc'),<\exit>
])<\exit>
ofstream.add_constructor([Parameter.new("const char *", 'filename'),<\exit>
Parameter.new("::std::ofstream::openmode", 'mode', default_value="std::ios_base::out")])<\exit>
ofstream.add_method('close', None, [])<\exit>
add_std_ios_openmode(module)<\exit>
def add_std_ios_openmode(module):<\exit>
import pybindgen.typehandlers.base<\exit>
for alias in "std::_Ios_Openmode", "std::ios::openmode":<\exit>
pybindgen.typehandlers.base.param_type_matcher.add_type_alias(alias, "int")<\exit>
for flag in 'in', 'out', 'ate', 'app', 'trunc', 'binary':<\exit>
module.after_init.write_code('PyModule_AddIntConstant(m, (char *) "STD_IOS_%s", std::ios::%s);'<\exit>
% (flag.upper(), flag))<\exit>
def add_ipv4_address_tp_hash(module):<\exit>
module.body.writeln()<\exit>
module.header.writeln('long _ns3_Ipv4Address_tp_hash (PyObject *obj);')<\exit>
module['Ipv4Address'].pytype.slots['tp_hash'] = "_ns3_Ipv4Address_tp_hash"<\exit>
import sys<\exit>
import os.path<\exit>
import pybindgen.settings<\exit>
from pybindgen.gccxmlparser import ModuleParser, PygenClassifier, PygenSection, WrapperWarning, find_declaration_from_name<\exit>
from pybindgen.typehandlers.codesink import FileCodeSink<\exit>
from pygccxml.declarations import templates<\exit>
from pygccxml.declarations.enumeration import enumeration_t<\exit>
from pygccxml.declarations.class_declaration import class_t<\exit>
from pygccxml.declarations.calldef import free_function_t, member_function_t, constructor_t, calldef_t<\exit>
import ns3modulegen_core_customizations<\exit>
class ErrorHandler(pybindgen.settings.ErrorHandler):<\exit>
def handle_error(self, dummy_wrapper, dummy_exception, dummy_traceback_):<\exit>
return True<\exit>
pybindgen.settings.error_handler = ErrorHandler()<\exit>
import warnings<\exit>
warnings.filterwarnings(category=WrapperWarning, action='ignore')<\exit>
import ns3modulescan<\exit>
type_annotations = ns3modulescan.type_annotations<\exit>
def get_ns3_relative_path(path):<\exit>
l = []<\exit>
head = path<\exit>
while head:<\exit>
new_head, tail = os.path.split(head)<\exit>
if new_head == head:<\exit>
raise ValueError<\exit>
head = new_head<\exit>
if tail == 'ns3':<\exit>
return os.path.join(*l)<\exit>
l.insert(0, tail)<\exit>
raise AssertionError("is the path %r inside ns3?!" % path)<\exit>
class PreScanHook:<\exit>
def __init__(self, headers_map, module):<\exit>
self.headers_map = headers_map<\exit>
self.module = module<\exit>
def __call__(self, module_parser,<\exit>
pygccxml_definition,<\exit>
global_annotations,<\exit>
parameter_annotations):<\exit>
try:<\exit>
ns3_header = get_ns3_relative_path(pygccxml_definition.location.file_name)<\exit>
except ValueError:<\exit>
return<\exit>
definition_module = self.headers_map[ns3_header]<\exit>
global_annotations['pygen_comment'] = "%s (module %r): %s" % \<\exit>
(ns3_header, definition_module, pygccxml_definition)<\exit>
if isinstance(pygccxml_definition, member_function_t) \<\exit>
and pygccxml_definition.parent.name == 'Object' \<\exit>
and pygccxml_definition.name == 'GetObject':<\exit>
template_args = templates.args(pygccxml_definition.demangled_name)<\exit>
if template_args == ['ns3::Object']:<\exit>
global_annotations['template_instance_names'] = 'ns3::Object=>GetObject'<\exit>
if isinstance(pygccxml_definition, member_function_t) \<\exit>
and pygccxml_definition.parent.name == 'Simulator' \<\exit>
and pygccxml_definition.name.startswith('Schedule'):<\exit>
global_annotations['ignore'] = None<\exit>
if isinstance(pygccxml_definition, member_function_t) \<\exit>
and pygccxml_definition.parent.name == 'Simulator' \<\exit>
and pygccxml_definition.name == 'Run':<\exit>
global_annotations['ignore'] = True<\exit>
if isinstance(pygccxml_definition, calldef_t):<\exit>
for arg in pygccxml_definition.arguments:<\exit>
if arg.default_value is None:<\exit>
continue<\exit>
elif arg.default_value == "ns3::MilliSeconds( )":<\exit>
arg.default_value = "ns3::MilliSeconds(0)"<\exit>
elif arg.default_value == "ns3::Seconds( )":<\exit>
arg.default_value = "ns3::Seconds(0)"<\exit>
if isinstance(pygccxml_definition, class_t):<\exit>
print >> sys.stderr, pygccxml_definition<\exit>
if templates.is_instantiation(pygccxml_definition.decl_string):<\exit>
cls_name, template_parameters = templates.split(pygccxml_definition.name)<\exit>
template_parameters_decls = [find_declaration_from_name(module_parser.global_ns, templ_param)<\exit>
for templ_param in template_parameters]<\exit>
template_parameters_modules = []<\exit>
for templ in template_parameters_decls:<\exit>
if not hasattr(templ, 'location'):<\exit>
continue<\exit>
try:<\exit>
h = get_ns3_relative_path(templ.location.file_name)<\exit>
except ValueError:<\exit>
continue<\exit>
template_parameters_modules.append(self.headers_map[h])<\exit>
for templ_mod in template_parameters_modules:<\exit>
if templ_mod == self.module:<\exit>
definition_module = templ_mod<\exit>
break<\exit>
if definition_module != self.module:<\exit>
global_annotations['import_from_module'] = 'ns.%s' % (definition_module.replace('-', '_'),)<\exit>
if pygccxml_definition.decl_string.startswith('::ns3::SimpleRefCount<'):<\exit>
global_annotations['incref_method'] = 'Ref'<\exit>
global_annotations['decref_method'] = 'Unref'<\exit>
global_annotations['peekref_method'] = 'GetReferenceCount'<\exit>
global_annotations['automatic_type_narrowing'] = 'true'<\exit>
return<\exit>
if pygccxml_definition.decl_string.startswith('::ns3::Callback<'):<\exit>
global_annotations['ignore'] = None<\exit>
return<\exit>
if pygccxml_definition.decl_string.startswith('::ns3::TracedCallback<'):<\exit>
global_annotations['ignore'] = None<\exit>
return<\exit>
if pygccxml_definition.decl_string.startswith('::ns3::Ptr<'):<\exit>
global_annotations['ignore'] = None<\exit>
return<\exit>
try:<\exit>
annotations = type_annotations[pygccxml_definition.decl_string]<\exit>
except KeyError:<\exit>
pass<\exit>
else:<\exit>
global_annotations.update(annotations)<\exit>
if isinstance(pygccxml_definition, enumeration_t):<\exit>
if definition_module != self.module:<\exit>
global_annotations['import_from_module'] = 'ns.%s' % definition_module<\exit>
if isinstance(pygccxml_definition, free_function_t):<\exit>
if definition_module != self.module:<\exit>
global_annotations['ignore'] = None<\exit>
return<\exit>
if pygccxml_definition.name == 'PeekPointer':<\exit>
global_annotations['ignore'] = None<\exit>
return<\exit>
if isinstance(pygccxml_definition, (free_function_t, member_function_t, constructor_t)):<\exit>
try:<\exit>
annotations = type_annotations[str(pygccxml_definition)]<\exit>
except KeyError:<\exit>
pass<\exit>
else:<\exit>
for key,value in annotations.items():<\exit>
if key == 'params':<\exit>
parameter_annotations.update (value)<\exit>
del annotations['params']<\exit>
global_annotations.update(annotations)<\exit>
def scan_callback_classes(module_parser, callback_classes_file):<\exit>
callback_classes_file.write("callback_classes = [\n")<\exit>
for cls in module_parser.module_namespace.classes(function=module_parser.location_filter,<\exit>
recursive=False):<\exit>
if not cls.name.startswith("Callback<"):<\exit>
continue<\exit>
assert templates.is_instantiation(cls.decl_string), "%s is not a template instantiation" % cls<\exit>
dummy_cls_name, template_parameters = templates.split(cls.decl_string)<\exit>
callback_classes_file.write("    %r,\n" % template_parameters)<\exit>
callback_classes_file.write("]\n")<\exit>
def ns3_module_scan(top_builddir, module_name, headers_map, output_file_name, cflags):<\exit>
module_parser = ModuleParser('ns.%s' % module_name.replace('-', '_'), 'ns3')<\exit>
module_parser.add_pre_scan_hook(PreScanHook(headers_map, module_name))<\exit>
gccxml_options = dict(<\exit>
include_paths=[top_builddir],<\exit>
define_symbols={<\exit>
},<\exit>
cflags=('--gccxml-cxxflags "%s -DPYTHON_SCAN"' % cflags)<\exit>
)<\exit>
try:<\exit>
os.unlink(output_file_name)<\exit>
except OSError:<\exit>
pass<\exit>
try:<\exit>
os.makedirs(os.path.dirname(output_file_name))<\exit>
except OSError:<\exit>
pass<\exit>
output_file = open(output_file_name, "wt")<\exit>
output_sink = FileCodeSink(output_file)<\exit>
scan_header = os.path.join(os.path.dirname(output_file_name), "scan-header.h")<\exit>
if not os.path.exists(scan_header):<\exit>
scan_header = os.path.join(top_builddir, "ns3", "%s-module.h" % module_name)<\exit>
module_parser.parse_init([scan_header],<\exit>
None, whitelist_paths=[top_builddir],<\exit>
pygen_sink=output_sink,<\exit>
gccxml_options=gccxml_options)<\exit>
module_parser.scan_types()<\exit>
callback_classes_file = open(os.path.join(os.path.dirname(output_file_name), "callbacks_list.py"), "wt")<\exit>
scan_callback_classes(module_parser, callback_classes_file)<\exit>
callback_classes_file.close()<\exit>
module_parser.scan_methods()<\exit>
module_parser.scan_functions()<\exit>
module_parser.parse_finalize()<\exit>
output_file.close()<\exit>
os.chmod(output_file_name, 0400)<\exit>
if __name__ == '__main__':<\exit>
if len(sys.argv) != 6:<\exit>
print "ns3modulescan-modular.py top_builddir module_path module_headers output_file_name cflags"<\exit>
sys.exit(1)<\exit>
ns3_module_scan(sys.argv[1], sys.argv[2], eval(sys.argv[3]), sys.argv[4], sys.argv[5])<\exit>
sys.exit(0)<\exit>
import sys<\exit>
import os.path<\exit>
import pybindgen.settings<\exit>
from pybindgen.gccxmlparser import ModuleParser, PygenClassifier, PygenSection, WrapperWarning<\exit>
from pybindgen.typehandlers.codesink import FileCodeSink<\exit>
from pygccxml.declarations import templates<\exit>
from pygccxml.declarations.class_declaration import class_t<\exit>
from pygccxml.declarations.calldef import free_function_t, member_function_t, constructor_t, calldef_t<\exit>
import ns3modulegen_core_customizations<\exit>
class ErrorHandler(pybindgen.settings.ErrorHandler):<\exit>
def handle_error(self, dummy_wrapper, dummy_exception, dummy_traceback_):<\exit>
return True<\exit>
pybindgen.settings.error_handler = ErrorHandler()<\exit>
import warnings<\exit>
warnings.filterwarnings(category=WrapperWarning, action='ignore')<\exit>
type_annotations = {<\exit>
'::ns3::AttributeChecker': {<\exit>
'automatic_type_narrowing': 'true',<\exit>
'allow_subclassing': 'false',<\exit>
},<\exit>
'::ns3::AttributeValue': {<\exit>
'automatic_type_narrowing': 'true',<\exit>
'allow_subclassing': 'false',<\exit>
},<\exit>
'::ns3::CommandLine': {<\exit>
'allow_subclassing': 'true',<\exit>
},<\exit>
'::ns3::NscTcpL4Protocol': {<\exit>
'ignore': 'true',<\exit>
},<\exit>
'ns3::RandomVariable::RandomVariable(ns3::RandomVariableBase const & variable) [constructor]': {<\exit>
'ignore': None,<\exit>
},<\exit>
'ns3::RandomVariableBase * ns3::RandomVariable::Peek() const [member function]': {<\exit>
'ignore': None,<\exit>
},<\exit>
'void ns3::RandomVariable::GetSeed(uint32_t * seed) const [member function]': {<\exit>
'params': {'seed':{'direction':'out',<\exit>
'array_length':'6'}}<\exit>
},<\exit>
'bool ns3::TypeId::LookupAttributeByName(std::string name, ns3::TypeId::AttributeInfo * info) const [member function]': {<\exit>
'params': {'info':{'transfer_ownership': 'false'}}<\exit>
},<\exit>
'static bool ns3::TypeId::LookupByNameFailSafe(std::string name, ns3::TypeId * tid) [member function]': {<\exit>
'ignore': None,<\exit>
},<\exit>
'bool ns3::TraceSourceAccessor::ConnectWithoutContext(ns3::ObjectBase * obj, ns3::CallbackBase const & cb) const [member function]': {<\exit>
'params': {'obj': {'transfer_ownership':'false'}}<\exit>
},<\exit>
'bool ns3::TraceSourceAccessor::Connect(ns3::ObjectBase * obj, std::string context, ns3::CallbackBase const & cb) const [member function]': {<\exit>
'params': {'obj': {'transfer_ownership':'false'}}<\exit>
},<\exit>
'bool ns3::TraceSourceAccessor::DisconnectWithoutContext(ns3::ObjectBase * obj, ns3::CallbackBase const & cb) const [member function]': {<\exit>
'params': {'obj': {'transfer_ownership':'false'}}<\exit>
},<\exit>
'bool ns3::TraceSourceAccessor::Disconnect(ns3::ObjectBase * obj, std::string context, ns3::CallbackBase const & cb) const [member function]': {<\exit>
'params': {'obj': {'transfer_ownership':'false'}}<\exit>
},<\exit>
'bool ns3::AttributeAccessor::Set(ns3::ObjectBase * object, ns3::AttributeValue const & value) const [member function]': {<\exit>
'params': {'object': {'transfer_ownership':'false'}}<\exit>
},<\exit>
'ns3::EmpiricalVariable::EmpiricalVariable(ns3::RandomVariableBase const & variable) [constructor]': {<\exit>
'ignore': None<\exit>
},<\exit>
'static ns3::AttributeList * ns3::AttributeList::GetGlobal() [member function]': {<\exit>
'caller_owns_return': 'false'<\exit>
},<\exit>
'void ns3::CommandLine::Parse(int argc, char * * argv) const [member function]': {<\exit>
'ignore': None<\exit>
},<\exit>
'extern void ns3::PythonCompleteConstruct(ns3::Ptr<ns3::Object> object, ns3::TypeId typeId, ns3::AttributeList const & attributes) [free function]': {<\exit>
'ignore': None<\exit>
},<\exit>
'ns3::Ptr<ns3::Ipv4RoutingProtocol> ns3::Ipv4ListRouting::GetRoutingProtocol(uint32_t index, int16_t & priority) const [member function]': {<\exit>
'params': {'priority':{'direction':'out'}}<\exit>
},<\exit>
'ns3::Ipv4RoutingTableEntry * ns3::GlobalRouter::GetInjectedRoute(uint32_t i) [member function]': {<\exit>
'params': {'return': { 'caller_owns_return': 'false',}},<\exit>
},<\exit>
'ns3::Ipv4RoutingTableEntry * ns3::Ipv4GlobalRouting::GetRoute(uint32_t i) const [member function]': {<\exit>
'params': {'return': { 'caller_owns_return': 'false',}},<\exit>
},<\exit>
'::ns3::TestCase': {<\exit>
'ignore': 'true',<\exit>
},<\exit>
'::ns3::TestRunner': {<\exit>
'ignore': 'true',<\exit>
},<\exit>
'::ns3::TestSuite': {<\exit>
'ignore': 'true',<\exit>
},<\exit>
}<\exit>
def get_ns3_relative_path(path):<\exit>
l = []<\exit>
head = path<\exit>
while head:<\exit>
head, tail = os.path.split(head)<\exit>
if tail == 'ns3':<\exit>
return os.path.join(*l)<\exit>
l.insert(0, tail)<\exit>
raise AssertionError("is the path %r inside ns3?!" % path)<\exit>
def pre_scan_hook(dummy_module_parser,<\exit>
pygccxml_definition,<\exit>
global_annotations,<\exit>
parameter_annotations):<\exit>
ns3_header = get_ns3_relative_path(pygccxml_definition.location.file_name)<\exit>
global_annotations['pygen_comment'] = "%s: %s" % \<\exit>
(ns3_header, pygccxml_definition)<\exit>
if isinstance(pygccxml_definition, member_function_t) \<\exit>
and pygccxml_definition.parent.name == 'Object' \<\exit>
and pygccxml_definition.name == 'GetObject':<\exit>
template_args = templates.args(pygccxml_definition.demangled_name)<\exit>
if template_args == ['ns3::Object']:<\exit>
global_annotations['template_instance_names'] = 'ns3::Object=>GetObject'<\exit>
if isinstance(pygccxml_definition, member_function_t) \<\exit>
and pygccxml_definition.parent.name == 'Simulator' \<\exit>
and pygccxml_definition.name.startswith('Schedule'):<\exit>
global_annotations['ignore'] = None<\exit>
if isinstance(pygccxml_definition, member_function_t) \<\exit>
and pygccxml_definition.parent.name == 'Simulator' \<\exit>
and pygccxml_definition.name == 'Run':<\exit>
global_annotations['ignore'] = True<\exit>
if isinstance(pygccxml_definition, calldef_t):<\exit>
for arg in pygccxml_definition.arguments:<\exit>
if arg.default_value is None:<\exit>
continue<\exit>
if "ns3::MilliSeconds( )" == arg.default_value:<\exit>
arg.default_value = "ns3::MilliSeconds(0)"<\exit>
if "ns3::Seconds( )" == arg.default_value:<\exit>
arg.default_value = "ns3::Seconds(0)"<\exit>
if isinstance(pygccxml_definition, class_t):<\exit>
if pygccxml_definition.decl_string.startswith('::ns3::SimpleRefCount<'):<\exit>
global_annotations['incref_method'] = 'Ref'<\exit>
global_annotations['decref_method'] = 'Unref'<\exit>
global_annotations['peekref_method'] = 'GetReferenceCount'<\exit>
global_annotations['automatic_type_narrowing'] = 'true'<\exit>
return<\exit>
if pygccxml_definition.decl_string.startswith('::ns3::Callback<'):<\exit>
global_annotations['ignore'] = None<\exit>
return<\exit>
if pygccxml_definition.decl_string.startswith('::ns3::TracedCallback<'):<\exit>
global_annotations['ignore'] = None<\exit>
return<\exit>
if pygccxml_definition.decl_string.startswith('::ns3::Ptr<'):<\exit>
global_annotations['ignore'] = None<\exit>
return<\exit>
try:<\exit>
annotations = type_annotations[pygccxml_definition.decl_string]<\exit>
except KeyError:<\exit>
pass<\exit>
else:<\exit>
global_annotations.update(annotations)<\exit>
if isinstance(pygccxml_definition, free_function_t):<\exit>
if pygccxml_definition.name == 'PeekPointer':<\exit>
global_annotations['ignore'] = None<\exit>
return<\exit>
if isinstance(pygccxml_definition, (free_function_t, member_function_t, constructor_t)):<\exit>
try:<\exit>
annotations = type_annotations[str(pygccxml_definition)]<\exit>
except KeyError:<\exit>
pass<\exit>
else:<\exit>
for key,value in annotations.items():<\exit>
if key == 'params':<\exit>
parameter_annotations.update (value)<\exit>
del annotations['params']<\exit>
global_annotations.update(annotations)<\exit>
def scan_callback_classes(module_parser, callback_classes_file):<\exit>
callback_classes_file.write("callback_classes = [\n")<\exit>
for cls in module_parser.module_namespace.classes(function=module_parser.location_filter,<\exit>
recursive=False):<\exit>
if not cls.name.startswith("Callback<"):<\exit>
continue<\exit>
assert templates.is_instantiation(cls.decl_string), "%s is not a template instantiation" % cls<\exit>
dummy_cls_name, template_parameters = templates.split(cls.decl_string)<\exit>
callback_classes_file.write("    %r,\n" % template_parameters)<\exit>
callback_classes_file.write("]\n")<\exit>
class MyPygenClassifier(PygenClassifier):<\exit>
def __init__(self, headers_map, section_precendences):<\exit>
self.headers_map = headers_map<\exit>
self.section_precendences = section_precendences<\exit>
def classify(self, pygccxml_definition):<\exit>
name = os.path.basename(pygccxml_definition.location.file_name)<\exit>
try:<\exit>
return self.headers_map[name]<\exit>
except KeyError:<\exit>
return '__main__'<\exit>
def get_section_precedence(self, section_name):<\exit>
if section_name == '__main__':<\exit>
return -1<\exit>
return self.section_precendences[section_name]<\exit>
def ns3_module_scan(top_builddir, pygen_file_name, everything_h, cflags):<\exit>
ns3_modules = eval(sys.stdin.readline())<\exit>
from topsort import topsort<\exit>
graph = []<\exit>
module_names = ns3_modules.keys()<\exit>
module_names.sort()<\exit>
for ns3_module_name in module_names:<\exit>
ns3_module_deps = list(ns3_modules[ns3_module_name][0])<\exit>
ns3_module_deps.sort()<\exit>
for dep in ns3_module_deps:<\exit>
graph.append((dep, ns3_module_name))<\exit>
sorted_ns3_modules = topsort(graph)<\exit>
sections = [PygenSection('__main__', FileCodeSink(open(pygen_file_name, "wt")))]<\exit>
headers_map = {}<\exit>
section_precendences = {}<\exit>
for prec, ns3_module in enumerate(sorted_ns3_modules):<\exit>
section_name = "ns3_module_%s" % ns3_module.replace('-', '_')<\exit>
file_name = os.path.join(os.path.dirname(pygen_file_name), "%s.py" % section_name)<\exit>
sections.append(PygenSection(section_name, FileCodeSink(open(file_name, "wt")),<\exit>
section_name + "__local"))<\exit>
for header in ns3_modules[ns3_module][1]:<\exit>
headers_map[header] = section_name<\exit>
section_precendences[section_name] = prec<\exit>
module_parser = ModuleParser('ns3', 'ns3')<\exit>
module_parser.add_pre_scan_hook(pre_scan_hook)<\exit>
gccxml_options = dict(<\exit>
include_paths=[top_builddir],<\exit>
define_symbols={<\exit>
},<\exit>
cflags=('--gccxml-cxxflags "%s -DPYTHON_SCAN"' % cflags)<\exit>
)<\exit>
module_parser.parse_init([everything_h],<\exit>
None, whitelist_paths=[top_builddir, os.path.dirname(everything_h)],<\exit>
pygen_sink=sections,<\exit>
pygen_classifier=MyPygenClassifier(headers_map, section_precendences),<\exit>
gccxml_options=gccxml_options)<\exit>
module_parser.scan_types()<\exit>
callback_classes_file = open(os.path.join(os.path.dirname(pygen_file_name), "callbacks_list.py"), "wt")<\exit>
scan_callback_classes(module_parser, callback_classes_file)<\exit>
callback_classes_file.close()<\exit>
module_parser.scan_methods()<\exit>
module_parser.scan_functions()<\exit>
module_parser.parse_finalize()<\exit>
for section in sections:<\exit>
section.code_sink.file.close()<\exit>
if __name__ == '__main__':<\exit>
ns3_module_scan(sys.argv[1], sys.argv[3], sys.argv[2], sys.argv[4])<\exit>
from _ns3 import *<\exit>
import atexit<\exit>
atexit.register(Simulator.Destroy)<\exit>
del atexit<\exit>
try:<\exit>
from http.client import HTTPSConnection<\exit>
except ImportError:<\exit>
from httplib import HTTPSConnection<\exit>
from logging import getLogger<\exit>
from ntlm import ntlm<\exit>
from urllib3 import HTTPSConnectionPool<\exit>
log = getLogger(__name__)<\exit>
class NTLMConnectionPool(HTTPSConnectionPool):<\exit>
scheme = 'https'<\exit>
def __init__(self, user, pw, authurl, *args, **kwargs):<\exit>
super(NTLMConnectionPool, self).__init__(*args, **kwargs)<\exit>
self.authurl = authurl<\exit>
self.rawuser = user<\exit>
user_parts = user.split('\\', 1)<\exit>
self.domain = user_parts[0].upper()<\exit>
self.user = user_parts[1]<\exit>
self.pw = pw<\exit>
def _new_conn(self):<\exit>
self.num_connections += 1<\exit>
log.debug('Starting NTLM HTTPS connection no. %d: https://%s%s' %<\exit>
(self.num_connections, self.host, self.authurl))<\exit>
headers = {}<\exit>
headers['Connection'] = 'Keep-Alive'<\exit>
req_header = 'Authorization'<\exit>
resp_header = 'www-authenticate'<\exit>
conn = HTTPSConnection(host=self.host, port=self.port)<\exit>
headers[req_header] = (<\exit>
'NTLM %s' % ntlm.create_NTLM_NEGOTIATE_MESSAGE(self.rawuser))<\exit>
log.debug('Request headers: %s' % headers)<\exit>
conn.request('GET', self.authurl, None, headers)<\exit>
res = conn.getresponse()<\exit>
reshdr = dict(res.getheaders())<\exit>
log.debug('Response status: %s %s' % (res.status, res.reason))<\exit>
log.debug('Response headers: %s' % reshdr)<\exit>
log.debug('Response data: %s [...]' % res.read(100))<\exit>
res.fp = None<\exit>
auth_header_values = reshdr[resp_header].split(', ')<\exit>
auth_header_value = None<\exit>
for s in auth_header_values:<\exit>
if s[:5] == 'NTLM ':<\exit>
auth_header_value = s[5:]<\exit>
if auth_header_value is None:<\exit>
raise Exception('Unexpected %s response header: %s' %<\exit>
(resp_header, reshdr[resp_header]))<\exit>
ServerChallenge, NegotiateFlags = \<\exit>
ntlm.parse_NTLM_CHALLENGE_MESSAGE(auth_header_value)<\exit>
auth_msg = ntlm.create_NTLM_AUTHENTICATE_MESSAGE(ServerChallenge,<\exit>
self.user,<\exit>
self.domain,<\exit>
self.pw,<\exit>
NegotiateFlags)<\exit>
headers[req_header] = 'NTLM %s' % auth_msg<\exit>
log.debug('Request headers: %s' % headers)<\exit>
conn.request('GET', self.authurl, None, headers)<\exit>
res = conn.getresponse()<\exit>
log.debug('Response status: %s %s' % (res.status, res.reason))<\exit>
log.debug('Response headers: %s' % dict(res.getheaders()))<\exit>
log.debug('Response data: %s [...]' % res.read()[:100])<\exit>
if res.status != 200:<\exit>
if res.status == 401:<\exit>
raise Exception('Server rejected request: wrong '<\exit>
'username or password')<\exit>
raise Exception('Wrong server response: %s %s' %<\exit>
(res.status, res.reason))<\exit>
res.fp = None<\exit>
log.debug('Connection established')<\exit>
return conn<\exit>
def urlopen(self, method, url, body=None, headers=None, retries=3,<\exit>
redirect=True, assert_same_host=True):<\exit>
if headers is None:<\exit>
headers = {}<\exit>
headers['Connection'] = 'Keep-Alive'<\exit>
return super(NTLMConnectionPool, self).urlopen(method, url, body,<\exit>
headers, retries,<\exit>
redirect,<\exit>
assert_same_host)<\exit>
class Solution(object):<\exit>
def solve(self, cipher):<\exit>
N, K, A = cipher<\exit>
total = N * (N + 1) / 2<\exit>
total_only_s = 0<\exit>
i = 0<\exit>
while i < N:<\exit>
if A[i] > K:<\exit>
i += 1<\exit>
else:<\exit>
j = i + 1<\exit>
while j < N and A[j] <= K: j += 1<\exit>
l = j - i<\exit>
total_only_s += l * (l + 1) / 2<\exit>
i = j<\exit>
return total - total_only_s<\exit>
if __name__ == "__main__":<\exit>
import sys<\exit>
f = open("0.in", "r")<\exit>
solution = Solution()<\exit>
testcases = int(f.readline().strip())<\exit>
for t in xrange(testcases):<\exit>
N, K = map(int, f.readline().strip().split(' '))<\exit>
A = map(int, f.readline().strip().split(' '))<\exit>
cipher = N, K, A<\exit>
s = "%s\n" % (solution.solve(cipher))<\exit>
print s,<\exit>
class Interval(object):<\exit>
def __init__(self, start, end):<\exit>
self.start = start<\exit>
self.end = end<\exit>
class Solution:<\exit>
@staticmethod<\exit>
def cmp(a, b):<\exit>
if a.start != b.start:<\exit>
return a.start-b.start<\exit>
else:<\exit>
return a.end-b.end<\exit>
def countOfAirplanes(self, airplanes):<\exit>
return self.count_heap(airplanes)<\exit>
def count_heap(self, intervals):<\exit>
import heapq<\exit>
intervals.sort(cmp=Solution.cmp)<\exit>
heap = []<\exit>
cnt = 0<\exit>
for intv in intervals:<\exit>
heapq.heappush(heap, intv.end)<\exit>
while heap[0] <= intv.start:<\exit>
heapq.heappop(heap)<\exit>
cnt = max(cnt, len(heap))<\exit>
return cnt<\exit>
if __name__ == "__main__":<\exit>
assert Solution().countOfAirplanes([Interval(i[0], i[1]) for i in [[1, 10], [2, 3], [5, 8], [4, 7]]]) == 3<\exit>
import random<\exit>
class Point(object):<\exit>
def __init__(self, a=0, b=0):<\exit>
self.x = a<\exit>
self.y = b<\exit>
def __repr__(self):<\exit>
return "[%d, %d]" % (self.x, self.y)<\exit>
class UnionFind(object):<\exit>
def __init__(self, rows, cols):<\exit>
self.pi = [-1 for _ in xrange(rows*cols)]<\exit>
self.sz = [-1 for _ in xrange(rows*cols)]<\exit>
self.count = 0<\exit>
def add(self, item):<\exit>
if self.pi[item] == -1:<\exit>
self.pi[item] = item<\exit>
self.sz[item] = 1<\exit>
self.count += 1<\exit>
def union(self, a, b):<\exit>
pi1 = self._pi(a)<\exit>
pi2 = self._pi(b)<\exit>
if pi1 != pi2:<\exit>
if self.sz[pi1] > self.sz[pi2]:<\exit>
pi1, pi2 = pi2, pi1<\exit>
self.pi[pi1] = pi2<\exit>
self.sz[pi2] += self.sz[pi1]<\exit>
self.count -= 1<\exit>
def _pi(self, item):<\exit>
pi = self.pi[item]<\exit>
if item != pi:<\exit>
self.pi[item] = self._pi(pi)<\exit>
return self.pi[item]<\exit>
class Solution:<\exit>
def __init__(self):<\exit>
self.dirs = ((-1, 0), (1, 0), (0, -1), (0, 1))<\exit>
def numIslands2(self, n, m, operators):<\exit>
rows = n<\exit>
cols = m<\exit>
unroll = lambda x, y: x*cols+y<\exit>
mat = [[0 for _ in xrange(cols)] for _ in xrange(rows)]<\exit>
uf = UnionFind(rows, cols)<\exit>
ret = []<\exit>
for op in operators:<\exit>
uf.add(unroll(op.x, op.y))<\exit>
mat[op.x][op.y] = 1<\exit>
for dir in self.dirs:<\exit>
x1 = op.x+dir[0]<\exit>
y1 = op.y+dir[1]<\exit>
if 0 <= x1 < rows and 0 <= y1 < cols and mat[x1][y1] == 1:<\exit>
uf.union(unroll(op.x, op.y), unroll(x1, y1))<\exit>
ret.append(uf.count)<\exit>
return ret<\exit>
class TestCaseGenerator(object):<\exit>
def _generate(self):<\exit>
dim = 10<\exit>
m = random.randrange(1, dim)<\exit>
n = random.randrange(1, dim)<\exit>
k = random.randrange(1, max(2, m*n/3))<\exit>
operators = []<\exit>
visited = set()<\exit>
while len(operators) < k:<\exit>
p = random.randrange(m*n)<\exit>
if p not in visited:<\exit>
x = p/n<\exit>
y = p%n<\exit>
operators.append(Point(x, y))<\exit>
visited.add(p)<\exit>
print(m)<\exit>
print(n)<\exit>
print(operators)<\exit>
def generate(self, T=50):<\exit>
for _ in xrange(T):<\exit>
self._generate()<\exit>
if __name__ == "__main__":<\exit>
assert Solution().numIslands2(3, 3, map(lambda x: Point(x[0], x[1]), [(0, 0), (0, 1), (2, 2), (2, 1)])) == [1, 1, 2,<\exit>
2]<\exit>
testcase = TestCaseGenerator()<\exit>
testcase.generate()<\exit>
class Solution:<\exit>
def __init__(self):<\exit>
self.dirs = [[0, -1], [0, 1], [1, 0], [-1, 0]]<\exit>
def numIslands(self, grid):<\exit>
if not grid: return 0<\exit>
m = len(grid)<\exit>
if not m: return 0<\exit>
n = len(grid[0])<\exit>
visited = [[False for _ in xrange(n)] for _ in xrange(m)]<\exit>
cnt = 0<\exit>
for i in xrange(m):<\exit>
for j in xrange(n):<\exit>
if not visited[i][j] and grid[i][j]:<\exit>
cnt += 1<\exit>
self.dfs(grid, i, j, visited)<\exit>
return cnt<\exit>
def dfs(self, grid, i, j, visited):<\exit>
m = len(grid)<\exit>
n = len(grid[0])<\exit>
visited[i][j] = True<\exit>
for dir in self.dirs:<\exit>
i1 = i+dir[0]<\exit>
j1 = j+dir[1]<\exit>
if 0 <= i1 < m and 0 <= j1 < n and not visited[i1][j1] and grid[i1][j1]:<\exit>
self.dfs(grid, i1, j1, visited)<\exit>
try:<\exit>
from lintcode import Compare<\exit>
except ImportError:<\exit>
class Compare:<\exit>
@classmethod<\exit>
def cmp(cls, a, b):<\exit>
a = a.lower()<\exit>
b = b.lower()<\exit>
diff = ord(a)-ord(b)<\exit>
if diff < 0:<\exit>
return -1<\exit>
elif diff > 0:<\exit>
return 1<\exit>
else:<\exit>
return 0<\exit>
class Solution:<\exit>
def sortNutsAndBolts(self, nuts, bolts):<\exit>
assert len(nuts) == len(bolts)<\exit>
self.quick_sort(nuts, bolts, 0, len(nuts))<\exit>
def quick_sort(self, nuts, bolts, start, end):<\exit>
if start >= end:<\exit>
return<\exit>
pivot = self.partition(nuts, bolts[start], start, end)<\exit>
self.partition(bolts, nuts[pivot], start, end)<\exit>
self.quick_sort(nuts, bolts, start, pivot)<\exit>
self.quick_sort(nuts, bolts, pivot+1, end)<\exit>
def partition(self, A, pivot, start, end):<\exit>
left = start<\exit>
i = start+1<\exit>
while i < end:<\exit>
if Compare.cmp(A[i], pivot) == -1 or Compare.cmp(pivot, A[i]) == 1:<\exit>
left += 1<\exit>
A[left], A[i] = A[i], A[left]<\exit>
i += 1<\exit>
elif Compare.cmp(A[i], pivot) == 0 or Compare.cmp(pivot, A[i]) == 0:<\exit>
A[start], A[i] = A[i], A[start]<\exit>
else:<\exit>
i += 1<\exit>
A[start], A[left] = A[left], A[start]<\exit>
return left<\exit>
if __name__ == "__main__":<\exit>
nuts = ['a', 'b', 'd', 'g']<\exit>
bolts = ['A', 'G', 'D', 'B']<\exit>
Solution().sortNutsAndBolts(nuts, bolts)<\exit>
assert nuts == ['a', 'b', 'd', 'g']<\exit>
assert bolts == ['A', 'B', 'D', 'G']<\exit>
import sys<\exit>
import re<\exit>
from string import lowercase<\exit>
options = None<\exit>
def case_normalize_initial(s):<\exit>
if re.match(r'^[A-Z][a-z]{2,}', s):<\exit>
return s[0].lower()+s[1:]<\exit>
else:<\exit>
return s<\exit>
def case_normalize_all_words(s):<\exit>
return " ".join([case_normalize_initial(w) for w in s.split(" ")])<\exit>
class Term:<\exit>
def __init__(self, tid, name, synonyms=None, defs=None,<\exit>
is_a=None, part_of=None):<\exit>
self.tid      = tid<\exit>
self.name     = name<\exit>
self.synonyms = synonyms if synonyms is not None else []<\exit>
self.defs     = defs     if defs     is not None else []<\exit>
self.is_a     = is_a     if is_a     is not None else []<\exit>
self.part_of  = part_of  if part_of  is not None else []<\exit>
self.parents  = []<\exit>
self.children = []<\exit>
self.objects    = []<\exit>
self.components = []<\exit>
self.cleanup()<\exit>
def obo_idspace(self):<\exit>
if ":" in self.tid:<\exit>
s = self.tid[:self.tid.index(":")]<\exit>
if len([c for c in s if c in lowercase]) == len(s):<\exit>
return s.upper()<\exit>
else:<\exit>
return s<\exit>
else:<\exit>
m = re.match(r'^(.[A-Za-z_]+)', self.tid)<\exit>
return m.group(1)<\exit>
def resolve_references(self, term_by_id, term_by_name=None):<\exit>
for ptid, pname in self.is_a:<\exit>
if ptid not in term_by_id:<\exit>
print >> sys.stderr, "Warning: is_a term '%s' not found, ignoring" % ptid<\exit>
continue<\exit>
parent = term_by_id[ptid]<\exit>
if pname is not None and term_by_name is not None and term_by_name[pname] is not None:<\exit>
assert parent == term_by_name[pname]<\exit>
if self in parent.children:<\exit>
print >> sys.stderr, "Warning: dup is-a parent %s for %s, ignoring" % (ptid, str(self))<\exit>
else:<\exit>
self.parents.append(parent)<\exit>
parent.children.append(self)<\exit>
for prel, ptid, pname in self.part_of:<\exit>
if ptid not in term_by_id:<\exit>
print >> sys.stderr, "Error: part_of term '%s' not found, ignoring" % ptid<\exit>
continue<\exit>
pobject = term_by_id[ptid]<\exit>
if pname is not None and term_by_name is not None and term_by_name[pname] is not None:<\exit>
assert pobject == term_by_name[pname]<\exit>
if self in pobject.components:<\exit>
print >> sys.stderr, "Warning: dup part-of parent %s for %s, ignoring" % (ptid, str(self))<\exit>
else:<\exit>
self.objects.append((prel, pobject))<\exit>
pobject.components.append((prel, self))<\exit>
def _case_normalize(self, cn_func):<\exit>
self.name = cn_func(self.name)<\exit>
for i in range(len(self.synonyms)):<\exit>
self.synonyms[i] = (cn_func(self.synonyms[i][0]), self.synonyms[i][1])<\exit>
for i in range(len(self.is_a)):<\exit>
if self.is_a[i][1] is not None:<\exit>
self.is_a[i] = (self.is_a[i][0], cn_func(self.is_a[i][1]))<\exit>
def case_normalize_initial(self):<\exit>
global case_normalize_initial<\exit>
self._case_normalize(case_normalize_initial)<\exit>
def case_normalize_all_words(self):<\exit>
global case_normalize_all_words<\exit>
self._case_normalize(case_normalize_all_words)<\exit>
def cleanup(self):<\exit>
for i, s in enumerate(self.synonyms):<\exit>
if s[-1] == ".":<\exit>
if re.search(r'\b[a-z]{2,}\.$', s):<\exit>
c = s[:-1]<\exit>
print >> sys.stderr, "Note: cleanup: '%s' -> '%s'" % (s, c)<\exit>
self.synonyms[i] = c<\exit>
def __str__(self):<\exit>
return "%s (%s)" % (self.name, self.tid)<\exit>
def parse_obo(f, limit_prefixes=None, include_nameless=False):<\exit>
all_terms = []<\exit>
term_by_id = {}<\exit>
skip_block = True<\exit>
tid, prefix, name, synonyms, definitions, is_a, part_of, obsolete = None, None, None, [], [], [], [], False<\exit>
for ln, l in enumerate(f):<\exit>
if l.strip() == "[Term]":<\exit>
assert tid is None<\exit>
assert name is None<\exit>
assert is_a == []<\exit>
skip_block = False<\exit>
if l.strip() == "[Typedef]":<\exit>
skip_block = True<\exit>
elif re.match(r'^id:.*', l) and not skip_block:<\exit>
assert tid is None, str(ln)+' '+tid<\exit>
l = re.sub(r'\s*\!.*', '', l)<\exit>
m = re.match(r'^id: (([A-Za-z](?:\S*(?=:)|[A-Za-z_]*)):?\S+)\s*$', l)<\exit>
if m is None:<\exit>
print >> sys.stderr, "line %d: failed to match id, ignoring: %s" % (ln, l.rstrip())<\exit>
tid, prefix, name, synonyms, is_a, part_of, obsolete = None, None, None, [], [], [], False<\exit>
skip_block = True<\exit>
else:<\exit>
tid, prefix = m.groups()<\exit>
elif re.match(r'^name:.*', l) and not skip_block:<\exit>
assert tid is not None<\exit>
assert name is None<\exit>
m = re.match(r'^name: (.*?)\s*$', l)<\exit>
assert m is not None<\exit>
name = m.group(1)<\exit>
elif re.match(r'^is_a:.*', l) and not skip_block:<\exit>
assert tid is not None<\exit>
m = re.match(r'^is_a: (\S+) *(?:\{[^{}]*\} *)?(?:\!.*?)?\! *(.*?)\s*$', l)<\exit>
if m:<\exit>
is_a.append(m.groups())<\exit>
else:<\exit>
m = re.match(r'^is_a: (\S+)\s*$', l)<\exit>
if m is not None:<\exit>
is_a.append((m.group(1), None))<\exit>
else:<\exit>
print >> sys.stderr, "Error: failed to parse '%s'; ignoring is_a" % l<\exit>
elif re.match(r'^relationship:\s*\S*part_of', l) and not skip_block:<\exit>
assert tid is not None<\exit>
assert name is not None<\exit>
m = re.match(r'^relationship: +(?:OBO_REL:)?(\S+) +(\S+) *(?:\{[^{}]*\} *)?\! *(.*?)\s*$', l)<\exit>
if m:<\exit>
part_of.append(m.groups())<\exit>
else:<\exit>
m = re.match(r'^relationship: +(?:OBO_REL:)?(\S+) +(\S+)\s*$', l)<\exit>
if m is not None:<\exit>
part_of.append((m.group(1), m.group(2), None))<\exit>
else:<\exit>
print >> sys.stderr, "Error: failed to parse '%s'; ignoring part_of" % l<\exit>
elif re.match(r'^synonym:.*', l) and not skip_block:<\exit>
assert tid is not None<\exit>
assert name is not None<\exit>
m = re.match(r'^synonym: "(.*)" ([A-Za-z_ ]*?) *\[.*\]\s*$', l)<\exit>
assert m is not None, "Error: failed to parse '%s'" % l<\exit>
synstr, syntype = m.groups()<\exit>
if synstr == "":<\exit>
print >> sys.stderr, "Note: ignoring empty synonym on line %d: %s" % (ln, l.strip())<\exit>
else:<\exit>
synonyms.append((synstr,syntype))<\exit>
elif re.match(r'^def:.*', l) and not skip_block:<\exit>
assert tid is not None<\exit>
assert name is not None<\exit>
m = re.match(r'^def: "(.*)" *\[.*\]\s*$', l)<\exit>
assert m is not None, "Error: failed to parse '%s'" % l<\exit>
definition = m.group(1)<\exit>
if definition == "":<\exit>
print >> sys.stderr, "Note: ignoring empty def on line %d: %s" % (ln, l.strip())<\exit>
else:<\exit>
definitions.append(definition)<\exit>
elif re.match(r'^is_obsolete:', l):<\exit>
m = re.match(r'^is_obsolete:\s*true', l)<\exit>
if m:<\exit>
obsolete = True<\exit>
elif re.match(r'^\s*$', l):<\exit>
if (tid is None and prefix is None and name is None and<\exit>
synonyms == [] and definitions == [] and<\exit>
is_a == [] and part_of == []):<\exit>
continue<\exit>
if (obsolete or<\exit>
(limit_prefixes is not None and prefix not in limit_prefixes)):<\exit>
tid, prefix, name, synonyms, definitions, is_a, part_of, obsolete = None, None, None, [], [], [], [], False<\exit>
elif not skip_block:<\exit>
assert tid is not None, "line %d: no ID for '%s'!" % (ln, name)<\exit>
if name is None and not include_nameless:<\exit>
print >> sys.stderr, "Note: ignoring term without name (%s) on line %d" % (tid, ln)<\exit>
else:<\exit>
if tid not in term_by_id:<\exit>
t = Term(tid, name, synonyms, definitions,<\exit>
is_a, part_of)<\exit>
all_terms.append(t)<\exit>
term_by_id[tid] = t<\exit>
else:<\exit>
print >> sys.stderr, "Error: duplicate ID '%s'; discarding all but first definition" % tid<\exit>
tid, prefix, name, synonyms, definitions, is_a, part_of, obsolete = None, None, None, [], [], [], [], False<\exit>
else:<\exit>
pass<\exit>
else:<\exit>
pass<\exit>
assert tid is None<\exit>
assert name is None<\exit>
assert is_a == []<\exit>
return all_terms, term_by_id<\exit>
def argparser():<\exit>
import argparse<\exit>
ap=argparse.ArgumentParser(description="Extract terms from OBO ontology.")<\exit>
ap.add_argument("-l", "--limit", default=None, metavar="PREFIX", help="Limit processing to given ontology prefix or prefixes (multiple separated by \"|\").")<\exit>
ap.add_argument("-d", "--depth", default=None, metavar="INT", help="Limit extraction to given depth from initial nodes.")<\exit>
ap.add_argument("-nc", "--no-case-normalization", default=False, action="store_true", help="Skip heuristic case normalization of ontology terms.")<\exit>
ap.add_argument("-nm", "--no-multiple-inheritance", default=False, action="store_true", help="Exclude subtrees involving multiple inheritance.")<\exit>
ap.add_argument("-ns", "--no-synonyms", default=False, action="store_true", help="Do not extract synonyms.")<\exit>
ap.add_argument("-nd", "--no-definitions", default=False, action="store_true", help="Do not extract definitions.")<\exit>
ap.add_argument("-e", "--exclude", default=[], metavar="TERM", nargs="+", help="Exclude subtrees rooted at given TERMs.")<\exit>
ap.add_argument("-s", "--separate-children", default=[], default=False, action="store_true", help="Separate subontologies found as children of the given term.")<\exit>
ap.add_argument("file", metavar="OBO-FILE", help="Source ontology.")<\exit>
ap.add_argument("-p", "--separate-parents", default=[], default=False, action="store_true", help="Separate subontologies of parents of the given terms.")<\exit>
ap.add_argument("terms", default=[], metavar="TERM", nargs="*", help="Root terms from which to extract.")<\exit>
return ap<\exit>
multiple_parent_skip_count = 0<\exit>
def get_subtree_terms(root, collection=None, depth=0):<\exit>
global options<\exit>
global multiple_parent_skip_count<\exit>
if collection is None:<\exit>
collection = []<\exit>
if root.traversed or root.excluded:<\exit>
return False<\exit>
if options.depth is not None and depth > options.depth:<\exit>
return False<\exit>
if options.no_multiple_inheritance and len(root.parents) > 1:<\exit>
if multiple_parent_skip_count < 10:<\exit>
print >> sys.stderr, "Note: not traversing subtree at %s %s: %d parents" % (root.tid, root.name, len(root.parents))<\exit>
elif multiple_parent_skip_count == 10:<\exit>
print >> sys.stderr, "(further 'not traversing subtree; multiple parents' notes suppressed)"<\exit>
multiple_parent_skip_count += 1<\exit>
return False<\exit>
root.traversed = True<\exit>
collection.append(root)<\exit>
for child in root.children:<\exit>
get_subtree_terms(child, collection, depth+1)<\exit>
return collection<\exit>
def exclude_subtree(root):<\exit>
if root.traversed:<\exit>
return False<\exit>
root.traversed = True<\exit>
root.excluded = True<\exit>
for child in root.children:<\exit>
exclude_subtree(child)<\exit>
def main(argv=None):<\exit>
global options<\exit>
arg = argparser().parse_args(argv[1:])<\exit>
options = arg<\exit>
if arg.depth is not None:<\exit>
arg.depth = int(arg.depth)<\exit>
assert arg.depth > 0, "Depth limit cannot be less than or equal to zero"<\exit>
limit_prefix = arg.limit<\exit>
if limit_prefix is None:<\exit>
limit_prefixes = None<\exit>
else:<\exit>
limit_prefixes = limit_prefix.split("|")<\exit>
fn = arg.file<\exit>
if not arg.no_case_normalization:<\exit>
for i in range(len(arg.terms)):<\exit>
arg.terms[i] = case_normalize_initial(arg.terms[i])<\exit>
f = open(fn)<\exit>
all_terms, term_by_id = parse_obo(f, limit_prefixes)<\exit>
for t in all_terms:<\exit>
t.resolve_references(term_by_id)<\exit>
if not arg.no_case_normalization:<\exit>
for t in all_terms:<\exit>
if t.obo_idspace() in ("FMA", "WBbt"):<\exit>
t.case_normalize_initial()<\exit>
elif t.obo_idspace() == "SAO":<\exit>
t.case_normalize_all_words()<\exit>
print >> sys.stderr, "OK, parsed %d (non-obsolete) terms." % len(all_terms)<\exit>
term_by_name = {}<\exit>
for t in all_terms:<\exit>
if t.name not in term_by_name:<\exit>
term_by_name[t.name] = t<\exit>
else:<\exit>
print >> sys.stderr, "Warning: duplicate name '%s'; no name->ID mapping possible" % t.name<\exit>
term_by_name[t.name] = None<\exit>
for rootterm in arg.terms:<\exit>
assert arg.separate_parents or rootterm in term_by_name, "Error: given term '%s' not found (or obsolete) in ontology!" % rootterm<\exit>
for t in all_terms:<\exit>
t.children = []<\exit>
t.parents  = []<\exit>
for t in all_terms:<\exit>
for ptid, pname in t.is_a:<\exit>
if ptid not in term_by_id:<\exit>
print >> sys.stderr, "Error: is_a term '%s' not found, removing" % ptid<\exit>
continue<\exit>
parent = term_by_id[ptid]<\exit>
if pname is not None and pname in term_by_name and term_by_name[pname] is not None:<\exit>
if parent != term_by_name[pname]:<\exit>
print >> sys.stderr, "Warning: given parent name '%s' mismatches parent term name (via ID) '%s'" % (parent.name, pname)<\exit>
if t in parent.children:<\exit>
print >> sys.stderr, "Warning: ignoring dup parent %s for %s" % (ptid, str(t))<\exit>
else:<\exit>
t.parents.append(parent)<\exit>
parent.children.append(t)<\exit>
for t in all_terms:<\exit>
t.traversed = False<\exit>
t.excluded  = False<\exit>
for excludeterm in arg.exclude:<\exit>
assert excludeterm in term_by_name, "Error: exclude term '%s' not found (or obsolete) in ontology!" % excludeterm<\exit>
exclude_subtree(term_by_name[excludeterm])<\exit>
for t in all_terms:<\exit>
t.traversed = False<\exit>
rootterms = []<\exit>
if not arg.separate_parents:<\exit>
for t in arg.terms:<\exit>
if t not in term_by_name:<\exit>
print >> sys.stderr, "Error: given term '%s' not found!" % t<\exit>
return 1<\exit>
else:<\exit>
rootterms.append(term_by_name[t])<\exit>
if len(rootterms) == 0:<\exit>
for t in all_terms:<\exit>
if len(t.parents) == 0:<\exit>
rootterms.append(t)<\exit>
print >> sys.stderr, "Extracting from %d root terms." % len(rootterms)<\exit>
else:<\exit>
assert not arg.separate_children, "Incompatible arguments"<\exit>
unique_parents = {}<\exit>
for t in arg.terms:<\exit>
if t in term_by_name:<\exit>
for p in term_by_name[t].parents:<\exit>
unique_parents[p] = True<\exit>
assert len(unique_parents) != 0, "Failed to find any of given terms"<\exit>
for p in unique_parents:<\exit>
p.excluded = True<\exit>
rootterms = [p for p in unique_parents]<\exit>
rootterms.sort(lambda a,b: cmp(a.name,b.name))<\exit>
arg.separate_children = True<\exit>
print >> sys.stderr, "Splitting at the following:", ",".join(rootterms)<\exit>
for rootterm in rootterms:<\exit>
if not arg.separate_children:<\exit>
for t in get_subtree_terms(rootterm):<\exit>
strs = []<\exit>
strs.append("name:Name:"+t.name)<\exit>
if not arg.no_synonyms:<\exit>
for synstr, syntype in t.synonyms:<\exit>
strs.append("name:Synonym:"+synstr)<\exit>
if not arg.no_definitions:<\exit>
for d in t.defs:<\exit>
strs.append("info:Definition:"+d)<\exit>
id_ = t.tid.replace(t.obo_idspace()+':', '', 1)<\exit>
print id_ + '\t' + '\t'.join(strs)<\exit>
else:<\exit>
for c in rootterm.children:<\exit>
stt = []<\exit>
get_subtree_terms(c, stt)<\exit>
for n, tid, ntype in stt:<\exit>
print "%s\t%s\t%s\t%s" % (c.name, n, tid, ntype)<\exit>
if __name__ == "__main__":<\exit>
sys.exit(main(sys.argv))<\exit>
import sys<\exit>
from urlparse import urlparse, urljoin<\exit>
from os.path import dirname, join as joinpath<\exit>
from os import makedirs<\exit>
from urllib import urlopen<\exit>
from simplejson import loads<\exit>
try:<\exit>
base_url = sys.argv[1]<\exit>
url = urlparse(base_url)<\exit>
except:<\exit>
print sys.argv[1]<\exit>
print "Syntax: %s <url>" % sys.argv[0]<\exit>
sys.exit(1)<\exit>
this_dir = dirname(sys.argv[0])<\exit>
datadir = joinpath(this_dir, '../offline_data')<\exit>
coll_and_doc = url.fragment<\exit>
coll = dirname(coll_and_doc)[1:]<\exit>
def convert_coll(coll):<\exit>
if coll == '':<\exit>
ajax_coll = '/'<\exit>
else:<\exit>
ajax_coll = '/%s/' % coll<\exit>
coll_query_url = urljoin(base_url, 'ajax.cgi?action=getCollectionInformation&collection=%s' % ajax_coll)<\exit>
coll_dir = joinpath(datadir, coll)<\exit>
try:<\exit>
makedirs(coll_dir)<\exit>
except:<\exit>
pass<\exit>
print ajax_coll<\exit>
conn = urlopen(coll_query_url)<\exit>
jsonp = conn.read()<\exit>
conn.close<\exit>
with open(joinpath(coll_dir, 'collection.js'), 'w') as f:<\exit>
f.write("jsonp=")<\exit>
f.write(jsonp)<\exit>
coll_data = loads(jsonp)<\exit>
for item in coll_data['items']:<\exit>
if item[0] == 'd':<\exit>
doc = item[2]<\exit>
print "  %s" % doc<\exit>
doc_query_url = urljoin(base_url, 'ajax.cgi?action=getDocument&collection=%s&document=%s' % (ajax_coll, doc))<\exit>
conn = urlopen(doc_query_url)<\exit>
jsonp = conn.read()<\exit>
conn.close<\exit>
with open(joinpath(coll_dir, '%s.data.js' % doc), 'w') as f:<\exit>
f.write("jsonp=")<\exit>
f.write(jsonp)<\exit>
elif item[0] == 'c' and item[2] != '..':<\exit>
convert_coll(item[2])<\exit>
convert_coll(coll)<\exit>
import gtk<\exit>
import ns.core<\exit>
import ns.network<\exit>
import ns.internet<\exit>
import ns.olsr<\exit>
from visualizer.base import InformationWindow<\exit>
class ShowOlsrRoutingTable(InformationWindow):<\exit>
(<\exit>
COLUMN_DESTINATION,<\exit>
COLUMN_NEXT_HOP,<\exit>
COLUMN_INTERFACE,<\exit>
COLUMN_NUM_HOPS,<\exit>
) = range(4)<\exit>
def __init__(self, visualizer, node_index):<\exit>
InformationWindow.__init__(self)<\exit>
self.win = gtk.Dialog(parent=visualizer.window,<\exit>
flags=gtk.DIALOG_DESTROY_WITH_PARENT|gtk.DIALOG_NO_SEPARATOR,<\exit>
buttons=(gtk.STOCK_CLOSE, gtk.RESPONSE_CLOSE))<\exit>
self.win.set_default_size(gtk.gdk.screen_width()/2, gtk.gdk.screen_height()/2)<\exit>
self.win.connect("response", self._response_cb)<\exit>
self.win.set_title("OLSR routing table for node %i" % node_index)<\exit>
self.visualizer = visualizer<\exit>
self.node_index = node_index<\exit>
self.table_model = gtk.ListStore(str, str, str, int)<\exit>
treeview = gtk.TreeView(self.table_model)<\exit>
treeview.show()<\exit>
sw = gtk.ScrolledWindow()<\exit>
sw.set_properties(hscrollbar_policy=gtk.POLICY_AUTOMATIC,<\exit>
vscrollbar_policy=gtk.POLICY_AUTOMATIC)<\exit>
sw.show()<\exit>
sw.add(treeview)<\exit>
self.win.vbox.add(sw)<\exit>
column = gtk.TreeViewColumn('Destination', gtk.CellRendererText(),<\exit>
text=self.COLUMN_DESTINATION)<\exit>
treeview.append_column(column)<\exit>
column = gtk.TreeViewColumn('Next hop', gtk.CellRendererText(),<\exit>
text=self.COLUMN_NEXT_HOP)<\exit>
treeview.append_column(column)<\exit>
column = gtk.TreeViewColumn('Interface', gtk.CellRendererText(),<\exit>
text=self.COLUMN_INTERFACE)<\exit>
treeview.append_column(column)<\exit>
column = gtk.TreeViewColumn('Num. Hops', gtk.CellRendererText(),<\exit>
text=self.COLUMN_NUM_HOPS)<\exit>
treeview.append_column(column)<\exit>
self.visualizer.add_information_window(self)<\exit>
self.win.show()<\exit>
def _response_cb(self, win, response):<\exit>
self.win.destroy()<\exit>
self.visualizer.remove_information_window(self)<\exit>
def update(self):<\exit>
node = ns.network.NodeList.GetNode(self.node_index)<\exit>
olsr = node.GetObject(ns.olsr.olsr.RoutingProtocol.GetTypeId())<\exit>
ipv4 = node.GetObject(ns.internet.Ipv4.GetTypeId())<\exit>
if olsr is None:<\exit>
return<\exit>
self.table_model.clear()<\exit>
for route in olsr.GetRoutingTableEntries():<\exit>
tree_iter = self.table_model.append()<\exit>
netdevice = ipv4.GetNetDevice(route.interface)<\exit>
if netdevice is None:<\exit>
interface_name = 'lo'<\exit>
else:<\exit>
interface_name = ns.core.Names.FindName(netdevice)<\exit>
if not interface_name:<\exit>
interface_name = "(interface %i)" % route.interface<\exit>
self.table_model.set(tree_iter,<\exit>
self.COLUMN_DESTINATION, str(route.destAddr),<\exit>
self.COLUMN_NEXT_HOP, str(route.nextAddr),<\exit>
self.COLUMN_INTERFACE, interface_name,<\exit>
self.COLUMN_NUM_HOPS, route.distance)<\exit>
def populate_node_menu(viz, node, menu):<\exit>
ns3_node = ns.network.NodeList.GetNode(node.node_index)<\exit>
olsr = ns3_node.GetObject(ns.olsr.olsr.RoutingProtocol.GetTypeId())<\exit>
if olsr is None:<\exit>
print "No OLSR"<\exit>
return<\exit>
menu_item = gtk.MenuItem("Show OLSR Routing Table")<\exit>
menu_item.show()<\exit>
def _show_ipv4_routing_table(dummy_menu_item):<\exit>
ShowOlsrRoutingTable(viz, node.node_index)<\exit>
menu_item.connect("activate", _show_ipv4_routing_table)<\exit>
menu.add(menu_item)<\exit>
def register(viz):<\exit>
viz.connect("populate-node-menu", populate_node_menu)<\exit>
from facerec_py.facerec.feature import AbstractFeature<\exit>
import numpy as np<\exit>
class FeatureOperator(AbstractFeature):<\exit>
def __init__(self, model1, model2):<\exit>
if (not isinstance(model1, AbstractFeature)) or (not isinstance(model2, AbstractFeature)):<\exit>
raise Exception("A FeatureOperator only works on classes implementing an AbstractFeature!")<\exit>
self.model1 = model1<\exit>
self.model2 = model2<\exit>
def __repr__(self):<\exit>
return "FeatureOperator(" + repr(self.model1) + "," + repr(self.model2) + ")"<\exit>
class ChainOperator(FeatureOperator):<\exit>
def __init__(self, model1, model2):<\exit>
FeatureOperator.__init__(self, model1, model2)<\exit>
def compute(self, X, y):<\exit>
X = self.model1.compute(X, y)<\exit>
return self.model2.compute(X, y)<\exit>
def extract(self, X):<\exit>
X = self.model1.extract(X)<\exit>
return self.model2.extract(X)<\exit>
def __repr__(self):<\exit>
return "ChainOperator(" + repr(self.model1) + "," + repr(self.model2) + ")"<\exit>
class CombineOperator(FeatureOperator):<\exit>
def __init__(self, model1, model2):<\exit>
FeatureOperator.__init__(self, model1, model2)<\exit>
def compute(self, X, y):<\exit>
A = self.model1.compute(X, y)<\exit>
B = self.model2.compute(X, y)<\exit>
C = []<\exit>
for i in range(0, len(A)):<\exit>
ai = np.asarray(A[i]).reshape(1, -1)<\exit>
bi = np.asarray(B[i]).reshape(1, -1)<\exit>
C.append(np.hstack((ai, bi)))<\exit>
return C<\exit>
def extract(self, X):<\exit>
ai = self.model1.extract(X)<\exit>
bi = self.model2.extract(X)<\exit>
ai = np.asarray(ai).reshape(1, -1)<\exit>
bi = np.asarray(bi).reshape(1, -1)<\exit>
return np.hstack((ai, bi))<\exit>
def __repr__(self):<\exit>
return "CombineOperator(" + repr(self.model1) + "," + repr(self.model2) + ")"<\exit>
class CombineOperatorND(FeatureOperator):<\exit>
def __init__(self, model1, model2, hstack=True):<\exit>
FeatureOperator.__init__(self, model1, model2)<\exit>
self._hstack = hstack<\exit>
def compute(self, X, y):<\exit>
A = self.model1.compute(X, y)<\exit>
B = self.model2.compute(X, y)<\exit>
C = []<\exit>
for i in range(0, len(A)):<\exit>
if self._hstack:<\exit>
C.append(np.hstack((A[i], B[i])))<\exit>
else:<\exit>
C.append(np.vstack((A[i], B[i])))<\exit>
return C<\exit>
def extract(self, X):<\exit>
ai = self.model1.extract(X)<\exit>
bi = self.model2.extract(X)<\exit>
if self._hstack:<\exit>
return np.hstack((ai, bi))<\exit>
return np.vstack((ai, bi))<\exit>
def __repr__(self):<\exit>
return "CombineOperatorND(" + repr(self.model1) + "," + repr(self.model2) + ", hstack=" + str(<\exit>
self._hstack) + ")"<\exit>
try:<\exit>
from thread import get_ident as _get_ident<\exit>
except ImportError:<\exit>
from dummy_thread import get_ident as _get_ident<\exit>
try:<\exit>
from _abcoll import KeysView, ValuesView, ItemsView<\exit>
except ImportError:<\exit>
pass<\exit>
class OrderedDict(dict):<\exit>
'Dictionary that remembers insertion order'<\exit>
def __init__(self, *args, **kwds):<\exit>
if len(args) > 1:<\exit>
raise TypeError('expected at most 1 arguments, got %d' % len(args))<\exit>
try:<\exit>
self.__root<\exit>
except AttributeError:<\exit>
self.__root = root = []<\exit>
root[:] = [root, root, None]<\exit>
self.__map = {}<\exit>
self.__update(*args, **kwds)<\exit>
def __setitem__(self, key, value, dict_setitem=dict.__setitem__):<\exit>
'od.__setitem__(i, y) <==> od[i]=y'<\exit>
if key not in self:<\exit>
root = self.__root<\exit>
last = root[0]<\exit>
last[1] = root[0] = self.__map[key] = [last, root, key]<\exit>
dict_setitem(self, key, value)<\exit>
def __delitem__(self, key, dict_delitem=dict.__delitem__):<\exit>
'od.__delitem__(y) <==> del od[y]'<\exit>
dict_delitem(self, key)<\exit>
link_prev, link_next, key = self.__map.pop(key)<\exit>
link_prev[1] = link_next<\exit>
link_next[0] = link_prev<\exit>
def __iter__(self):<\exit>
'od.__iter__() <==> iter(od)'<\exit>
root = self.__root<\exit>
curr = root[1]<\exit>
while curr is not root:<\exit>
yield curr[2]<\exit>
curr = curr[1]<\exit>
def __reversed__(self):<\exit>
'od.__reversed__() <==> reversed(od)'<\exit>
root = self.__root<\exit>
curr = root[0]<\exit>
while curr is not root:<\exit>
yield curr[2]<\exit>
curr = curr[0]<\exit>
def clear(self):<\exit>
'od.clear() -> None.  Remove all items from od.'<\exit>
try:<\exit>
for node in self.__map.itervalues():<\exit>
del node[:]<\exit>
root = self.__root<\exit>
root[:] = [root, root, None]<\exit>
self.__map.clear()<\exit>
except AttributeError:<\exit>
pass<\exit>
dict.clear(self)<\exit>
def popitem(self, last=True):<\exit>
if not self:<\exit>
raise KeyError('dictionary is empty')<\exit>
root = self.__root<\exit>
if last:<\exit>
link = root[0]<\exit>
link_prev = link[0]<\exit>
link_prev[1] = root<\exit>
root[0] = link_prev<\exit>
else:<\exit>
link = root[1]<\exit>
link_next = link[1]<\exit>
root[1] = link_next<\exit>
link_next[0] = root<\exit>
key = link[2]<\exit>
del self.__map[key]<\exit>
value = dict.pop(self, key)<\exit>
return key, value<\exit>
def keys(self):<\exit>
'od.keys() -> list of keys in od'<\exit>
return list(self)<\exit>
def values(self):<\exit>
'od.values() -> list of values in od'<\exit>
return [self[key] for key in self]<\exit>
def items(self):<\exit>
'od.items() -> list of (key, value) pairs in od'<\exit>
return [(key, self[key]) for key in self]<\exit>
def iterkeys(self):<\exit>
'od.iterkeys() -> an iterator over the keys in od'<\exit>
return iter(self)<\exit>
def itervalues(self):<\exit>
'od.itervalues -> an iterator over the values in od'<\exit>
for k in self:<\exit>
yield self[k]<\exit>
def iteritems(self):<\exit>
'od.iteritems -> an iterator over the (key, value) items in od'<\exit>
for k in self:<\exit>
yield (k, self[k])<\exit>
def update(*args, **kwds):<\exit>
if len(args) > 2:<\exit>
raise TypeError('update() takes at most 2 positional '<\exit>
'arguments (%d given)' % (len(args),))<\exit>
elif not args:<\exit>
raise TypeError('update() takes at least 1 argument (0 given)')<\exit>
self = args[0]<\exit>
other = ()<\exit>
if len(args) == 2:<\exit>
other = args[1]<\exit>
if isinstance(other, dict):<\exit>
for key in other:<\exit>
self[key] = other[key]<\exit>
elif hasattr(other, 'keys'):<\exit>
for key in other.keys():<\exit>
self[key] = other[key]<\exit>
else:<\exit>
for key, value in other:<\exit>
self[key] = value<\exit>
for key, value in kwds.items():<\exit>
self[key] = value<\exit>
__update = update<\exit>
__marker = object()<\exit>
def pop(self, key, default=__marker):<\exit>
if key in self:<\exit>
result = self[key]<\exit>
del self[key]<\exit>
return result<\exit>
if default is self.__marker:<\exit>
raise KeyError(key)<\exit>
return default<\exit>
def setdefault(self, key, default=None):<\exit>
'od.setdefault(k[,d]) -> od.get(k,d), also set od[k]=d if k not in od'<\exit>
if key in self:<\exit>
return self[key]<\exit>
self[key] = default<\exit>
return default<\exit>
def __repr__(self, _repr_running={}):<\exit>
'od.__repr__() <==> repr(od)'<\exit>
call_key = id(self), _get_ident()<\exit>
if call_key in _repr_running:<\exit>
return '...'<\exit>
_repr_running[call_key] = 1<\exit>
try:<\exit>
if not self:<\exit>
return '%s()' % (self.__class__.__name__,)<\exit>
return '%s(%r)' % (self.__class__.__name__, self.items())<\exit>
finally:<\exit>
del _repr_running[call_key]<\exit>
def __reduce__(self):<\exit>
'Return state information for pickling'<\exit>
items = [[k, self[k]] for k in self]<\exit>
inst_dict = vars(self).copy()<\exit>
for k in vars(OrderedDict()):<\exit>
inst_dict.pop(k, None)<\exit>
if inst_dict:<\exit>
return (self.__class__, (items,), inst_dict)<\exit>
return self.__class__, (items,)<\exit>
def copy(self):<\exit>
'od.copy() -> a shallow copy of od'<\exit>
return self.__class__(self)<\exit>
@classmethod<\exit>
def fromkeys(cls, iterable, value=None):<\exit>
d = cls()<\exit>
for key in iterable:<\exit>
d[key] = value<\exit>
return d<\exit>
def __eq__(self, other):<\exit>
if isinstance(other, OrderedDict):<\exit>
return len(self)==len(other) and self.items() == other.items()<\exit>
return dict.__eq__(self, other)<\exit>
def __ne__(self, other):<\exit>
return not self == other<\exit>
def viewkeys(self):<\exit>
"od.viewkeys() -> a set-like object providing a view on od's keys"<\exit>
return KeysView(self)<\exit>
def viewvalues(self):<\exit>
"od.viewvalues() -> an object providing a view on od's values"<\exit>
return ValuesView(self)<\exit>
def viewitems(self):<\exit>
"od.viewitems() -> a set-like object providing a view on od's items"<\exit>
return ItemsView(self)<\exit>
class Solution(object):<\exit>
def solve(self, cipher):<\exit>
N, K, lst = cipher<\exit>
hm = {}<\exit>
for val in lst:<\exit>
if val in hm:<\exit>
hm[val] += 1<\exit>
else:<\exit>
hm[val] = 1<\exit>
cnt = 0<\exit>
for val in lst:<\exit>
target = val + K<\exit>
if target in hm:<\exit>
cnt += hm[target]<\exit>
return cnt<\exit>
if __name__ == "__main__":<\exit>
import sys<\exit>
f = open("1.in", "r")<\exit>
N, K = map(int, f.readline().strip().split(' '))<\exit>
lst = map(int, f.readline().strip().split(' '))<\exit>
cipher = N, K, lst<\exit>
s = "%s\n" % (Solution().solve(cipher))<\exit>
print s,<\exit>
class Solution_TLE(object):<\exit>
def solve(self, cipher):<\exit>
for i in xrange(len(cipher)):<\exit>
if self.__is_palindrome(cipher[:i] + cipher[i + 1:]):<\exit>
return i<\exit>
return -1<\exit>
def __is_palindrome(self, s):<\exit>
return s == s[::-1]<\exit>
class Solution(object):<\exit>
def solve(self, cipher):<\exit>
l = len(cipher)<\exit>
start = 0<\exit>
end = l - 1<\exit>
while start < end and cipher[start] == cipher[end]:<\exit>
start += 1<\exit>
end -= 1<\exit>
if self.__is_palindrome(cipher[:start] + cipher[start + 1:]):<\exit>
return start<\exit>
if self.__is_palindrome(cipher[:end] + cipher[end + 1:]):<\exit>
return end<\exit>
if start >= end:<\exit>
return -1<\exit>
def __is_palindrome(self, s):<\exit>
return s == s[::-1]<\exit>
if __name__ == "__main__":<\exit>
import sys<\exit>
f = open("1.in", "r")<\exit>
testcases = int(f.readline().strip())<\exit>
for t in xrange(testcases):<\exit>
cipher = f.readline().strip()<\exit>
s = "%s\n" % (Solution().solve(cipher))<\exit>
print s,<\exit>
class Solution:<\exit>
def partition(self, s):<\exit>
ret = []<\exit>
self.backtrack(s, [], ret)<\exit>
return ret<\exit>
def backtrack(self, s, cur_lvl, ret):<\exit>
if not s:<\exit>
ret.append(list(cur_lvl))<\exit>
for i in xrange(1, len(s)+1):<\exit>
if self.predicate(s[:i]):<\exit>
cur_lvl.append(s[:i])<\exit>
self.backtrack(s[i:], cur_lvl, ret)<\exit>
cur_lvl.pop()<\exit>
def predicate(self, s):<\exit>
return s == s[::-1]<\exit>
if __name__ == "__main__":<\exit>
assert Solution().partition("aabbc") == [['a', 'a', 'b', 'b', 'c'], ['a', 'a', 'bb', 'c'], ['aa', 'b', 'b', 'c'], ['aa', 'bb', 'c']]<\exit>
class Solution(object):<\exit>
def solve(self, cipher):<\exit>
bucket = [False for _ in xrange(26)]<\exit>
for char in cipher:<\exit>
char = char.lower()<\exit>
ind = ord(char) - ord('a')<\exit>
try:<\exit>
bucket[ind] = True<\exit>
except IndexError:<\exit>
pass<\exit>
is_pangram = all(bucket)<\exit>
if is_pangram:<\exit>
return "pangram"<\exit>
else:<\exit>
return "not pangram"<\exit>
if __name__ == "__main__":<\exit>
import sys<\exit>
f = open("1.in", "r")<\exit>
testcases = 1<\exit>
for t in xrange(testcases):<\exit>
cipher = f.readline().strip()<\exit>
s = "%s\n" % (Solution().solve(cipher))<\exit>
print s,<\exit>
import numpy as np<\exit>
def parzen_estimation(x_samples, point_x, h):<\exit>
k_n = 0<\exit>
for row in x_samples:<\exit>
x_i = (point_x - row[:, np.newaxis]) / h<\exit>
for row in x_i:<\exit>
if np.abs(row) > 1/2:<\exit>
break<\exit>
else:<\exit>
k_n += 1<\exit>
return (k_n / len(x_samples)) / (h**point_x.shape[1])<\exit>
class Image(object):<\exit>
def __init__(self, id, caption, url):<\exit>
self.id = id<\exit>
self.caption = caption<\exit>
self.url = url<\exit>
class Image(object):<\exit>
__slots__ = ['id', 'caption', 'url']<\exit>
def __init__(self, id, caption, url):<\exit>
self.id = id<\exit>
self.caption = caption<\exit>
self.url = url<\exit>
from collections import defaultdict<\exit>
class Solution(object):<\exit>
def permutationIndexII(self, A):<\exit>
idx = 0<\exit>
factor = 1<\exit>
cnt = defaultdict(int)<\exit>
cnt[A[-1]] += 1<\exit>
n = len(A)<\exit>
for i in xrange(n-2, -1, -1):<\exit>
cnt[A[i]] += 1<\exit>
for k, v in cnt.items():<\exit>
if k < A[i]:<\exit>
idx += v * factor / cnt[A[i]]<\exit>
factor = factor * (n-i) / cnt[A[i]]<\exit>
return idx+1<\exit>
if __name__ == "__main__":<\exit>
print Solution().permutationIndexII([1, 4, 2, 2])<\exit>
import math<\exit>
class Solution:<\exit>
def permutationIndex(self, A):<\exit>
n = len(A)<\exit>
idx = 0<\exit>
for i, v in enumerate(A):<\exit>
inv = 0<\exit>
for j in xrange(i+1, n):<\exit>
if A[i] > A[j]:<\exit>
inv += 1<\exit>
idx += inv * math.factorial(n-1-i)<\exit>
return idx+1<\exit>
import math<\exit>
class Solution:<\exit>
def getPermutation(self, n, k):<\exit>
k -= 1<\exit>
array = range(1, n+1)<\exit>
k %= math.factorial(n)<\exit>
ret = []<\exit>
for i in xrange(n-1, -1, -1):<\exit>
idx, k = divmod(k, math.factorial(i))<\exit>
ret.append(array.pop(idx))<\exit>
return "".join(map(str, ret))<\exit>
MOD = 1000000007<\exit>
class Solution(object):<\exit>
def solve(self, cipher):<\exit>
N, A = cipher<\exit>
cnts = [0 for _ in xrange(N + 1)]<\exit>
for num in A:<\exit>
cnts[num] += 1<\exit>
if 0 not in cnts:<\exit>
return 0<\exit>
result = 1<\exit>
paths = cnts[0]<\exit>
for i in xrange(1, N):<\exit>
if paths <= 0:<\exit>
return 0<\exit>
result *= paths<\exit>
result %= MOD<\exit>
paths += cnts[i]<\exit>
paths -= 1<\exit>
return result<\exit>
if __name__ == "__main__":<\exit>
import sys<\exit>
f = open("1.in", "r")<\exit>
solution = Solution()<\exit>
testcases = int(f.readline().strip())<\exit>
for t in xrange(testcases):<\exit>
N = int(f.readline().strip())<\exit>
A = map(int, f.readline().strip().split(' '))<\exit>
cipher = N, A<\exit>
s = "%s\n" % (solution.solve(cipher))<\exit>
print s,<\exit>
import pickle<\exit>
import os<\exit>
import codecs<\exit>
def dump_pickles(out, dirname, filename, path):<\exit>
f = open(os.path.join(dirname, filename), 'r')<\exit>
data = pickle.load(f)<\exit>
fragment_file = codecs.open(data['current_page_name'] + '.frag', mode='w', encoding='utf-8')<\exit>
fragment_file.write(data['body'])<\exit>
fragment_file.close()<\exit>
out.write('  <page url="%s">\n' % path)<\exit>
out.write('    <fragment>%s.frag</fragment>\n' % data['current_page_name'])<\exit>
if data['prev'] is not None:<\exit>
out.write('    <prev url="%s">%s</prev>\n' %<\exit>
(os.path.normpath(os.path.join(path, data['prev']['link'])),<\exit>
data['prev']['title']))<\exit>
if data['next'] is not None:<\exit>
out.write('    <next url="%s">%s</next>\n' %<\exit>
(os.path.normpath(os.path.join(path, data['next']['link'])),<\exit>
data['next']['title']))<\exit>
out.write('  </page>\n')<\exit>
f.close()<\exit>
if data['next'] is not None:<\exit>
next_path = os.path.normpath(os.path.join(path, data['next']['link']))<\exit>
next_filename = os.path.basename(next_path) + '.fpickle'<\exit>
dump_pickles(out, dirname, next_filename, next_path)<\exit>
return<\exit>
import sys<\exit>
sys.stdout.write('<pages>\n')<\exit>
dump_pickles(sys.stdout, os.path.dirname(sys.argv[1]), os.path.basename(sys.argv[1]), '/')<\exit>
sys.stdout.write('</pages>')<\exit>
import Options<\exit>
import Configure<\exit>
import subprocess<\exit>
import config_c<\exit>
import sys<\exit>
def configure(conf):<\exit>
pkg_config = conf.find_program('pkg-config', var='PKG_CONFIG')<\exit>
if not pkg_config: return<\exit>
@Configure.conf<\exit>
def pkg_check_modules(conf, uselib_name, expression, mandatory=True):<\exit>
pkg_config = conf.env['PKG_CONFIG']<\exit>
if not pkg_config:<\exit>
if mandatory:<\exit>
conf.fatal("pkg-config is not available")<\exit>
else:<\exit>
return False<\exit>
if Options.options.verbose:<\exit>
extra_msg = ' (%s)' % expression<\exit>
else:<\exit>
extra_msg = ''<\exit>
conf.start_msg('Checking for pkg-config flags for %s%s' % (uselib_name, extra_msg))<\exit>
argv = [pkg_config, '--cflags', '--libs', expression]<\exit>
cmd = subprocess.Popen(argv, stdout=subprocess.PIPE, stderr=subprocess.PIPE)<\exit>
out, err = cmd.communicate()<\exit>
retval = cmd.wait()<\exit>
conf.to_log('%r: %r (exit code %i)\n%s' % (argv, out, retval, err))<\exit>
if retval != 0:<\exit>
conf.end_msg(False)<\exit>
sys.stderr.write(err)<\exit>
else:<\exit>
if Options.options.verbose:<\exit>
conf.end_msg(out)<\exit>
else:<\exit>
conf.end_msg(True)<\exit>
if retval == 0:<\exit>
conf.parse_flags(out, uselib_name, conf.env)<\exit>
conf.env[uselib_name] = True<\exit>
return True<\exit>
else:<\exit>
conf.env[uselib_name] = False<\exit>
if mandatory:<\exit>
raise Configure.ConfigurationError('pkg-config check failed')<\exit>
else:<\exit>
return False<\exit>
@Configure.conf<\exit>
def pkg_check_module_variable(conf, module, variable):<\exit>
pkg_config = conf.env['PKG_CONFIG']<\exit>
if not pkg_config:<\exit>
conf.fatal("pkg-config is not available")<\exit>
argv = [pkg_config, '--variable', variable, module]<\exit>
cmd = subprocess.Popen(argv, stdout=subprocess.PIPE)<\exit>
out, dummy = cmd.communicate()<\exit>
retval = cmd.wait()<\exit>
out = out.rstrip()<\exit>
msg_checking = ("Checking for pkg-config variable %r in %s" % (variable, module,))<\exit>
conf.check_message_custom(msg_checking, '', out)<\exit>
conf.log.write('%r: %r (exit code %i)\n' % (argv, out, retval))<\exit>
if retval == 0:<\exit>
return out<\exit>
else:<\exit>
raise Configure.ConfigurationError('pkg-config check failed')<\exit>
class Solution(object):<\exit>
def solve(self, cipher):<\exit>
N, v = cipher<\exit>
v.reverse()<\exit>
s = [0 for _ in xrange(N + 1)]<\exit>
for i in xrange(1, N + 1):<\exit>
s[i] = s[i - 1] + v[i - 1]<\exit>
f = [[0, 0] for _ in xrange(N + 1)]<\exit>
for i in xrange(1, N + 1):<\exit>
local_max = 0<\exit>
for k in xrange(1, 4):<\exit>
if i - k >= 0:<\exit>
local_max = max(local_max, s[i] - s[i - k] + s[i - k] - f[i - k][1])<\exit>
f[i][0] = local_max<\exit>
local_max = 0<\exit>
for k in xrange(1, 4):<\exit>
if i - k >= 0:<\exit>
local_max = max(local_max, s[i] - s[i - k] + s[i - k] - f[i - k][0])<\exit>
f[i][1] = local_max<\exit>
return f[-1][0]<\exit>
if __name__ == "__main__":<\exit>
import sys<\exit>
f = open("1.in", "r")<\exit>
testcases = int(f.readline().strip())<\exit>
for t in xrange(testcases):<\exit>
N = int(f.readline().strip())<\exit>
lst = map(lambda x: int(x), f.readline().strip().split(" "))<\exit>
cipher = [N, lst]<\exit>
s = "%s\n" % (Solution().solve(cipher))<\exit>
print s,<\exit>
import matplotlib.pyplot as plt<\exit>
class Plotter(object):<\exit>
def plot(self, L_lst):<\exit>
plt.figure("Log_likelihood")<\exit>
plt.ylabel("L: Log-likelihood")<\exit>
plt.xlabel("N: number of iterations")<\exit>
plt.plot([i+1 for i in xrange(len(L_lst))], L_lst)<\exit>
plt.show()<\exit>
class Plotter2D(object):<\exit>
def label(self, name, x_label, y_label):<\exit>
plt.figure(name)<\exit>
plt.xlabel(x_label)<\exit>
plt.ylabel(y_label)<\exit>
def plot_line(self, x1, y1, x2, y2):<\exit>
plt.plot([x1, x2], [y1, y2])<\exit>
def plot_scatter(self, X, Y, color="b"):<\exit>
plt.scatter(X, Y, c=color)<\exit>
def show(self):<\exit>
plt.show()<\exit>
import math<\exit>
class Solution(object):<\exit>
def solve(self, cipher):<\exit>
cipher.sort(cmp=self.cmp)<\exit>
def cmp_polar(self, a, b):<\exit>
x1 = a[0]<\exit>
y1 = a[1]<\exit>
x2 = b[0]<\exit>
y2 = b[1]<\exit>
cross_product = x1 * y2 - x2 * y1<\exit>
if cross_product > 0:<\exit>
return -1<\exit>
elif cross_product < 0:<\exit>
return 1<\exit>
else:<\exit>
if x1 * x1 >= 0 and y1 * y1 >= 0:<\exit>
return x1 * x1 + y1 * y1 - x2 * x2 - y2 * y2<\exit>
else:<\exit>
if y1 > 0:<\exit>
return -1<\exit>
if y2 > 0:<\exit>
return 1<\exit>
if y1 == 0 and x1 > 0:<\exit>
return -1<\exit>
else:<\exit>
return 1<\exit>
def cmp(self, a, b):<\exit>
x1 = a[0]<\exit>
y1 = a[1]<\exit>
x2 = b[0]<\exit>
y2 = b[1]<\exit>
r1 = x1 * x1 + y1 * y1<\exit>
r2 = x2 * x2 + y2 * y2<\exit>
phi1 = math.atan2(y1, x1)<\exit>
phi2 = math.atan2(y2, x2)<\exit>
if phi1 < 0:<\exit>
phi1 += math.pi * 2<\exit>
if phi2 < 0:<\exit>
phi2 += math.pi * 2<\exit>
if phi1 < phi2:<\exit>
return -1<\exit>
elif phi1 > phi2:<\exit>
return 1<\exit>
else:<\exit>
return r1 - r2<\exit>
if __name__ == "__main__":<\exit>
import sys<\exit>
f = open("1.in", "r")<\exit>
N = int(f.readline().strip())<\exit>
cipher = []<\exit>
for t in xrange(N):<\exit>
cipher.append(map(int, f.readline().strip().split(' ')))<\exit>
Solution().solve(cipher)<\exit>
for point in cipher:<\exit>
print "%d %d" % (point[0], point[1])<\exit>
import logging<\exit>
from ._collections import RecentlyUsedContainer<\exit>
from .connectionpool import HTTPConnectionPool, HTTPSConnectionPool<\exit>
from .connectionpool import connection_from_url, port_by_scheme<\exit>
from .request import RequestMethods<\exit>
from .util import parse_url<\exit>
__all__ = ['PoolManager', 'ProxyManager', 'proxy_from_url']<\exit>
pool_classes_by_scheme = {<\exit>
'http': HTTPConnectionPool,<\exit>
'https': HTTPSConnectionPool,<\exit>
}<\exit>
log = logging.getLogger(__name__)<\exit>
class PoolManager(RequestMethods):<\exit>
def __init__(self, num_pools=10, headers=None, **connection_pool_kw):<\exit>
RequestMethods.__init__(self, headers)<\exit>
self.connection_pool_kw = connection_pool_kw<\exit>
self.pools = RecentlyUsedContainer(num_pools,<\exit>
dispose_func=lambda p: p.close())<\exit>
def clear(self):<\exit>
self.pools.clear()<\exit>
def connection_from_host(self, host, port=None, scheme='http'):<\exit>
port = port or port_by_scheme.get(scheme, 80)<\exit>
pool_key = (scheme, host, port)<\exit>
pool = self.pools.get(pool_key)<\exit>
if pool:<\exit>
return pool<\exit>
pool_cls = pool_classes_by_scheme[scheme]<\exit>
pool = pool_cls(host, port, **self.connection_pool_kw)<\exit>
self.pools[pool_key] = pool<\exit>
return pool<\exit>
def connection_from_url(self, url):<\exit>
u = parse_url(url)<\exit>
return self.connection_from_host(u.host, port=u.port, scheme=u.scheme)<\exit>
def urlopen(self, method, url, redirect=True, **kw):<\exit>
u = parse_url(url)<\exit>
conn = self.connection_from_host(u.host, port=u.port, scheme=u.scheme)<\exit>
kw['assert_same_host'] = False<\exit>
kw['redirect'] = False<\exit>
if 'headers' not in kw:<\exit>
kw['headers'] = self.headers<\exit>
response = conn.urlopen(method, u.request_uri, **kw)<\exit>
redirect_location = redirect and response.get_redirect_location()<\exit>
if not redirect_location:<\exit>
return response<\exit>
if response.status == 303:<\exit>
method = 'GET'<\exit>
log.info("Redirecting %s -> %s" % (url, redirect_location))<\exit>
kw['retries'] = kw.get('retries', 3) - 1<\exit>
return self.urlopen(method, redirect_location, **kw)<\exit>
class ProxyManager(RequestMethods):<\exit>
def __init__(self, proxy_pool):<\exit>
self.proxy_pool = proxy_pool<\exit>
def _set_proxy_headers(self, headers=None):<\exit>
headers_ = {'Accept': '*/*'}<\exit>
if headers:<\exit>
headers_.update(headers)<\exit>
return headers_<\exit>
def urlopen(self, method, url, **kw):<\exit>
"Same as HTTP(S)ConnectionPool.urlopen, ``url`` must be absolute."<\exit>
kw['assert_same_host'] = False<\exit>
kw['headers'] = self._set_proxy_headers(kw.get('headers'))<\exit>
return self.proxy_pool.urlopen(method, url, **kw)<\exit>
def proxy_from_url(url, **pool_kw):<\exit>
proxy_pool = connection_from_url(url, **pool_kw)<\exit>
return ProxyManager(proxy_pool)<\exit>
class Solution(object):<\exit>
def solve(self, cipher):<\exit>
a, b, x, y = cipher<\exit>
if self.gcd(a, b) == self.gcd(x, y):<\exit>
return "YES"<\exit>
else:<\exit>
return "NO"<\exit>
def gcd(self, a, b):<\exit>
while b:<\exit>
a, b = b, a % b<\exit>
return a<\exit>
if __name__ == "__main__":<\exit>
import sys<\exit>
f = open("1.in", "r")<\exit>
testcases = int(f.readline().strip())<\exit>
for t in xrange(testcases):<\exit>
cipher = map(int, f.readline().strip().split(' '))<\exit>
s = "%s\n" % (Solution().solve(cipher))<\exit>
print s,<\exit>
class Solution:<\exit>
def postOffice_TLE(self, A, K):<\exit>
A.sort()<\exit>
N = len(A)<\exit>
F = [[0 for _ in xrange(K+1)] for _ in xrange(N+1)]<\exit>
c = [[0 for _ in xrange(N+1)] for _ in xrange(N+1)]<\exit>
for i in xrange(N):<\exit>
for j in xrange(i+1, N+1):<\exit>
m = (i+j)/2<\exit>
for l in xrange(i, j):<\exit>
c[i][j] += abs(A[m]-A[l])<\exit>
for n in xrange(1, N+1):<\exit>
F[n][1] = c[0][n]<\exit>
for n in xrange(1, N+1):<\exit>
for k in xrange(2, K+1):<\exit>
F[n][k] = min(<\exit>
F[l][k-1]+c[l][n] for l in xrange(n)<\exit>
)<\exit>
return F[N][K]<\exit>
def postOffice_TLE(self, A, K):<\exit>
if __name__ == "__main__":<\exit>
assert Solution().postOffice([112,122,360,311,85,225,405,53,405,43,342,13,588,424,299,37,104,289,404,414], 3) == 673<\exit>
from multiprocessing import Process<\exit>
import requests<\exit>
from docopt import docopt<\exit>
N = 100<\exit>
class Poster(Process):<\exit>
def __init__(self, url, data=None):<\exit>
self.client = requests.session()<\exit>
self.common_headers = {<\exit>
"Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",<\exit>
"Accept-Encoding": "gzip,deflate,sdch",<\exit>
"Accept-Language": "en-US,en;q=0.8,zh;q=0.6,zh-CN;q=0.4",<\exit>
"Cache-Control": "max-age=0",<\exit>
"Content-Type": "application/json",<\exit>
"Connection": "keep-alive",<\exit>
"User-Agent": "Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/38.0.2125.122 Safari/537.36"<\exit>
}<\exit>
self.url = url<\exit>
self.data = data<\exit>
super(Poster, self).__init__()<\exit>
def post(self):<\exit>
response = self.client.post(self.url, json=self.data,<\exit>
headers=self.common_headers)<\exit>
return response<\exit>
def run(self):<\exit>
while True:<\exit>
response = self.post()<\exit>
print response.text<\exit>
if __name__ == "__main__":<\exit>
options = docopt(__doc__, version='poster 0.0.1')<\exit>
url = options['<url>']<\exit>
data = options['<post_data>']<\exit>
n = N<\exit>
if options['--num_process']:<\exit>
n = int(options['<num>'])<\exit>
print "running with number of processes: %d" % n<\exit>
for i in xrange(n):<\exit>
Poster(url, data).start()<\exit>
import numpy as np<\exit>
from facerec_py.facerec.feature import AbstractFeature<\exit>
from facerec_py.facerec.util import asColumnMatrix<\exit>
from scipy import ndimage<\exit>
from scipy.misc import imresize<\exit>
class Resize(AbstractFeature):<\exit>
def __init__(self, size):<\exit>
AbstractFeature.__init__(self)<\exit>
self._size = size<\exit>
def compute(self, X, y):<\exit>
Xp = []<\exit>
for xi in X:<\exit>
Xp.append(self.extract(xi))<\exit>
return Xp<\exit>
def extract(self, X):<\exit>
return imresize(X, self._size)<\exit>
def __repr__(self):<\exit>
return "Resize (size=%s)" % (self._size,)<\exit>
class HistogramEqualization(AbstractFeature):<\exit>
def __init__(self, num_bins=256):<\exit>
AbstractFeature.__init__(self)<\exit>
self._num_bins = num_bins<\exit>
def compute(self, X, y):<\exit>
Xp = []<\exit>
for xi in X:<\exit>
Xp.append(self.extract(xi))<\exit>
return Xp<\exit>
def extract(self, X):<\exit>
h, b = np.histogram(X.flatten(), self._num_bins, normed=True)<\exit>
cdf = h.cumsum()<\exit>
cdf = 255 * cdf / cdf[-1]<\exit>
return np.interp(X.flatten(), b[:-1], cdf).reshape(X.shape)<\exit>
def __repr__(self):<\exit>
return "HistogramEqualization (num_bins=%s)" % (self._num_bins)<\exit>
class TanTriggsPreprocessing(AbstractFeature):<\exit>
def __init__(self, alpha=0.1, tau=10.0, gamma=0.2, sigma0=1.0, sigma1=2.0):<\exit>
AbstractFeature.__init__(self)<\exit>
self._alpha = float(alpha)<\exit>
self._tau = float(tau)<\exit>
self._gamma = float(gamma)<\exit>
self._sigma0 = float(sigma0)<\exit>
self._sigma1 = float(sigma1)<\exit>
def compute(self, X, y):<\exit>
Xp = []<\exit>
for xi in X:<\exit>
Xp.append(self.extract(xi))<\exit>
return Xp<\exit>
def extract(self, X):<\exit>
X = np.array(X, dtype=np.float32)<\exit>
X = np.power(X, self._gamma)<\exit>
X = np.asarray(ndimage.gaussian_filter(X, self._sigma1) - ndimage.gaussian_filter(X, self._sigma0))<\exit>
X = X / np.power(np.mean(np.power(np.abs(X), self._alpha)), 1.0 / self._alpha)<\exit>
X = X / np.power(np.mean(np.power(np.minimum(np.abs(X), self._tau), self._alpha)), 1.0 / self._alpha)<\exit>
X = self._tau * np.tanh(X / self._tau)<\exit>
return X<\exit>
def __repr__(self):<\exit>
return "TanTriggsPreprocessing (alpha=%.3f,tau=%.3f,gamma=%.3f,sigma0=%.3f,sigma1=%.3f)" % (<\exit>
self._alpha, self._tau, self._gamma, self._sigma0, self._sigma1)<\exit>
from facerec_py.facerec.lbp import ExtendedLBP<\exit>
class LBPPreprocessing(AbstractFeature):<\exit>
def __init__(self, lbp_operator=ExtendedLBP(radius=1, neighbors=8)):<\exit>
AbstractFeature.__init__(self)<\exit>
self._lbp_operator = lbp_operator<\exit>
def compute(self, X, y):<\exit>
Xp = []<\exit>
for xi in X:<\exit>
Xp.append(self.extract(xi))<\exit>
return Xp<\exit>
def extract(self, X):<\exit>
return self._lbp_operator(X)<\exit>
def __repr__(self):<\exit>
return "LBPPreprocessing (lbp_operator=%s)" % (repr(self._lbp_operator))<\exit>
from facerec_py.facerec.normalization import zscore, minmax<\exit>
class MinMaxNormalizePreprocessing(AbstractFeature):<\exit>
def __init__(self, low=0, high=1):<\exit>
AbstractFeature.__init__(self)<\exit>
self._low = low<\exit>
self._high = high<\exit>
def compute(self, X, y):<\exit>
Xp = []<\exit>
XC = asColumnMatrix(X)<\exit>
self._min = np.min(XC)<\exit>
self._max = np.max(XC)<\exit>
for xi in X:<\exit>
Xp.append(self.extract(xi))<\exit>
return Xp<\exit>
def extract(self, X):<\exit>
return minmax(X, self._low, self._high, self._min, self._max)<\exit>
def __repr__(self):<\exit>
return "MinMaxNormalizePreprocessing (low=%s, high=%s)" % (self._low, self._high)<\exit>
class ZScoreNormalizePreprocessing(AbstractFeature):<\exit>
def __init__(self):<\exit>
AbstractFeature.__init__(self)<\exit>
self._mean = 0.0<\exit>
self._std = 1.0<\exit>
def compute(self, X, y):<\exit>
XC = asColumnMatrix(X)<\exit>
self._mean = XC.mean()<\exit>
self._std = XC.std()<\exit>
Xp = []<\exit>
for xi in X:<\exit>
Xp.append(self.extract(xi))<\exit>
return Xp<\exit>
def extract(self, X):<\exit>
return zscore(X, self._mean, self._std)<\exit>
def __repr__(self):<\exit>
return "ZScoreNormalizePreprocessing (mean=%s, std=%s)" % (self._mean, self._std)<\exit>
import sys, os<\exit>
sys.path.append("../..")<\exit>
from facerec.feature import Fisherfaces, PCA, SpatialHistogram, Identity<\exit>
from facerec.distance import EuclideanDistance, ChiSquareDistance<\exit>
from facerec.classifier import NearestNeighbor<\exit>
from facerec.model import PredictableModel<\exit>
from facerec.validation import KFoldCrossValidation<\exit>
from facerec.visual import subplot<\exit>
from facerec.util import minmax_normalize<\exit>
from facerec.serialization import save_model, load_model<\exit>
import numpy as np<\exit>
try:<\exit>
from PIL import Image<\exit>
except ImportError:<\exit>
import Image<\exit>
import matplotlib.cm as cm<\exit>
import logging<\exit>
import matplotlib.pyplot as plt<\exit>
import matplotlib.cm as cm<\exit>
from facerec.lbp import LPQ, ExtendedLBP<\exit>
class FileNameFilter:<\exit>
def __init__(self, name):<\exit>
self._name = name<\exit>
def __call__(self, filename):<\exit>
return True<\exit>
def __repr__(self):<\exit>
return "FileNameFilter (name=%s)" % (self._name)<\exit>
class YaleBaseFilter(FileNameFilter):<\exit>
def __init__(self, min_azimuth, max_azimuth, min_elevation, max_elevation):<\exit>
FileNameFilter.__init__(self, "Filter YaleFDB Subset1")<\exit>
self._min_azimuth = min_azimuth<\exit>
self._max_azimuth = max_azimuth<\exit>
self._min_elevation = min_elevation<\exit>
self._max_elevation = max_elevation<\exit>
def __call__(self, filename):<\exit>
filetype = filename[-4:]<\exit>
if filetype != ".pgm":<\exit>
return False<\exit>
if "Ambient" in filename:<\exit>
return False<\exit>
azimuth = int(filename[12:16])<\exit>
elevation = int(filename[17:20])<\exit>
if azimuth < self._min_azimuth or azimuth > self._max_azimuth:<\exit>
return False<\exit>
if elevation < self._min_elevation or elevation > self._max_elevation:<\exit>
return False<\exit>
return True<\exit>
def read_images(path, fileNameFilter=FileNameFilter("None"), sz=None):<\exit>
c = 0<\exit>
X,y = [], []<\exit>
for dirname, dirnames, filenames in os.walk(path):<\exit>
for subdirname in dirnames:<\exit>
subject_path = os.path.join(dirname, subdirname)<\exit>
for filename in os.listdir(subject_path):<\exit>
if fileNameFilter(filename):<\exit>
print filename<\exit>
try:<\exit>
im = Image.open(os.path.join(subject_path, filename))<\exit>
im = im.convert("L")<\exit>
if (sz is not None):<\exit>
im = im.resize(self.sz, Image.ANTIALIAS)<\exit>
X.append(np.asarray(im, dtype=np.uint8))<\exit>
y.append(c)<\exit>
except IOError, (errno, strerror):<\exit>
print "I/O error({0}): {1}".format(errno, strerror)<\exit>
except:<\exit>
print "Unexpected error:", sys.exc_info()[0]<\exit>
raise<\exit>
c = c+1<\exit>
return [X,y]<\exit>
if __name__ == "__main__":<\exit>
out_dir = None<\exit>
if len(sys.argv) < 2:<\exit>
print "USAGE: facerec_demo.py </path/to/images>"<\exit>
sys.exit()<\exit>
yale_filter = YaleBaseFilter(-25, 25, -25, 25)<\exit>
[X,y] = read_images(sys.argv[1], yale_filter)<\exit>
handler = logging.StreamHandler(sys.stdout)<\exit>
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')<\exit>
handler.setFormatter(formatter)<\exit>
logger = logging.getLogger("facerec")<\exit>
logger.addHandler(handler)<\exit>
logger.setLevel(logging.DEBUG)<\exit>
feature = PCA()<\exit>
classifier = NearestNeighbor(dist_metric=EuclideanDistance(), k=1)<\exit>
model = PredictableModel(feature=feature, classifier=classifier)<\exit>
model.compute(X, y)<\exit>
E = []<\exit>
for i in xrange(min(model.feature.eigenvectors.shape[1], 16)):<\exit>
e = model.feature.eigenvectors[:,i].reshape(X[0].shape)<\exit>
E.append(minmax_normalize(e,0,255, dtype=np.uint8))<\exit>
subplot(title="Fisherfaces", images=E, rows=4, cols=4, sptitle="Fisherface", colormap=cm.jet, filename="fisherfaces.png")<\exit>
cv = KFoldCrossValidation(model, k=10)<\exit>
cv.validate(X, y)<\exit>
cv.print_results()<\exit>
class Solution:<\exit>
def previousPermuation(self, num):<\exit>
n = len(num)<\exit>
partition = n-2<\exit>
while partition >= 0 and num[partition] <= num[partition+1]:<\exit>
partition -= 1<\exit>
if partition < 0:<\exit>
return num[::-1]<\exit>
change = n-1<\exit>
while change >= 0 and num[change] >= num[partition]:<\exit>
change -= 1<\exit>
num[partition], num[change] = num[change], num[partition]<\exit>
num[partition+1:] = reversed(num[partition+1:])<\exit>
return num<\exit>
if __name__ == "__main__":<\exit>
print Solution().previousPermuation([1, 3, 2, 3])<\exit>
class Solution(object):<\exit>
def numbersByRecursion(self, n):<\exit>
return self.rec(n)<\exit>
def rec(self, n):<\exit>
if n == 0:<\exit>
return []<\exit>
if n == 1:<\exit>
return [i+1 for i in xrange(9)]<\exit>
else:<\exit>
lst = self.rec(n-1)<\exit>
l = len(lst)<\exit>
cur = []<\exit>
prev = lst[-1]+1<\exit>
for i in xrange(prev-prev/10):<\exit>
for j in xrange(10):<\exit>
cur.append(lst[prev/10-1+i]*10+j)<\exit>
lst.extend(cur)<\exit>
return lst<\exit>
if __name__ == "__main__":<\exit>
print Solution().numbersByRecursion(2)<\exit>
assert Solution().numbersByRecursion(2) == [i+1 for i in xrange(99)]<\exit>
class Solution(object):<\exit>
def solve(self, cipher):<\exit>
A = sorted(cipher)<\exit>
cur = -5<\exit>
cnt = 0<\exit>
for a in A:<\exit>
if cur + 4 < a:<\exit>
cur = a<\exit>
cnt += 1<\exit>
return cnt<\exit>
if __name__ == "__main__":<\exit>
import sys<\exit>
f = open("0.in", "r")<\exit>
solution = Solution()<\exit>
n = int(f.readline().strip())<\exit>
cipher = map(int, f.readline().strip().split(' '))<\exit>
s = "%s\n" % (solution.solve(cipher))<\exit>
print s,<\exit>
from celery import Celery<\exit>
import consumer<\exit>
app_name = 'consumer'<\exit>
app = Celery(app_name, broker=consumer.redis_url)<\exit>
for i in range(100):<\exit>
a = 1<\exit>
b = 2<\exit>
consumer.consume.delay(a, b)<\exit>
from Queue import Queue<\exit>
from threading import Thread<\exit>
import time<\exit>
class SimpleProducerConsumer(object):<\exit>
def __init__(self):<\exit>
self.queue = Queue(1)<\exit>
def consumer(self):<\exit>
time.sleep(0.1)<\exit>
self.queue.get()<\exit>
print('Consumer got 1')<\exit>
self.queue.get()<\exit>
print('Consumer got 2')<\exit>
def run(self):<\exit>
thread = Thread(target=self.consumer)<\exit>
thread.start()<\exit>
self.queue.put(object())<\exit>
print('Producer put 1')<\exit>
self.queue.put(object())<\exit>
print('Producer put 2')<\exit>
thread.join()<\exit>
print('Producer done')<\exit>
def consumer_queue_join(self):<\exit>
time.sleep(0.1)<\exit>
self.queue.get()<\exit>
print('Consumer got 1')<\exit>
self.queue.get()<\exit>
print('Consumer got 2')<\exit>
self.queue.task_done()<\exit>
def run_queue_join(self):<\exit>
thread = Thread(target=self.consumer_queue_join())<\exit>
thread.start()<\exit>
self.queue.put(object())<\exit>
print('Producer put 1')<\exit>
self.queue.put(object())<\exit>
print('Producer put 2')<\exit>
self.queue.join()<\exit>
print('Producer done')<\exit>
class ClosableQueue(Queue):<\exit>
STOP = object()<\exit>
def close(self):<\exit>
self.put(self.STOP)<\exit>
def __iter__(self):<\exit>
while True:<\exit>
item = self.get()<\exit>
try:<\exit>
if item is self.STOP: return<\exit>
yield item<\exit>
finally:<\exit>
self.task_done()<\exit>
class StoppableWorker(Thread):<\exit>
def __init__(self, func, in_queue, out_queue):<\exit>
self.func = func<\exit>
self.in_queue = in_queue<\exit>
self.out_queue = out_queue<\exit>
def run(self):<\exit>
for item in self.in_queue:<\exit>
result = self.func(item)<\exit>
self.out_queue.put(result)<\exit>
@staticmethod<\exit>
def test():<\exit>
download_queue = ClosableQueue()<\exit>
resize_queue = ClosableQueue()<\exit>
upload_queue = ClosableQueue()<\exit>
done_queue = ClosableQueue()<\exit>
threads = [<\exit>
StoppableWorker(lambda x: x, download_queue, resize_queue),<\exit>
StoppableWorker(lambda x: x, resize_queue, upload_queue),<\exit>
StoppableWorker(lambda x: x, upload_queue, download_queue)<\exit>
]<\exit>
for thread in threads:<\exit>
thread.start()<\exit>
N = 1000<\exit>
for _ in xrange(N):<\exit>
download_queue.put(object())<\exit>
download_queue.close()<\exit>
download_queue.join()<\exit>
resize_queue.close()<\exit>
resize_queue.join()<\exit>
upload_queue.close()<\exit>
upload_queue.join()<\exit>
assert done_queue.qsize() == N<\exit>
class Solution:<\exit>
def productExcludeItself(self, A):<\exit>
n = len(A)<\exit>
if n == 1:<\exit>
return []<\exit>
dp = [[1, 1] for _ in xrange(n)]<\exit>
for i in xrange(1, n):<\exit>
dp[i][0] = A[i-1]*dp[i-1][0]<\exit>
dp[n-i-1][1] = A[n-i]*dp[n-i][1]<\exit>
B = [dp[i][0]*dp[i][1] for i in xrange(n)]<\exit>
return B<\exit>
if __name__=="__main__":<\exit>
assert Solution().productExcludeItself([1, 2, 3]) == [6, 3, 2]<\exit>
from cProfile import Profile<\exit>
from pstats import Stats<\exit>
def demo():<\exit>
f = lambda x: x<\exit>
profiler = Profile()<\exit>
profiler.runcall(f)<\exit>
stats = Stats(profiler)<\exit>
stats.strip_dirs()<\exit>
stats.sort_stats('cumulative')<\exit>
stats.print_stats()<\exit>
stats.print_callers()<\exit>
stats.print_callees()<\exit>
from argparse import ArgumentParser<\exit>
from cgi import FieldStorage<\exit>
try:<\exit>
from json import dumps<\exit>
except ImportError:<\exit>
from sys import path as sys_path<\exit>
from os.path import join as path_join<\exit>
from os.path import dirname<\exit>
sys_path.append(path_join(dirname(__file__), '../server/lib/ujson'))<\exit>
from ujson import dumps<\exit>
from random import choice, randint<\exit>
from sys import stderr<\exit>
from urlparse import urlparse<\exit>
try:<\exit>
from urlparse import parse_qs<\exit>
except ImportError:<\exit>
from cgi import parse_qs<\exit>
from BaseHTTPServer import HTTPServer, BaseHTTPRequestHandler<\exit>
import json<\exit>
import urllib<\exit>
import urllib2<\exit>
import base64<\exit>
ARGPARSER = ArgumentParser(description='An example HTTP tagging service, '<\exit>
'tagging Confuse-a-Cat **AND** Dead-parrot mentions!')<\exit>
ARGPARSER.add_argument('-p', '--port', type=int, default=56789,<\exit>
help='port to run the HTTP service on (default: 56789)')<\exit>
def build_headers(email="", password=""):<\exit>
headers = {<\exit>
'Content-Type': 'application/json',<\exit>
'Accept': 'application/json',<\exit>
'Authorization': b'Basic ' + base64.b64encode(email + b':' + password),<\exit>
}<\exit>
return headers<\exit>
def build_data(text):<\exit>
return json.dumps({'text': text}).encode('utf-8')<\exit>
def convert_for_brat(pubdic_result, text):<\exit>
anns = {}<\exit>
for idx, entity in enumerate(pubdic_result):<\exit>
ann_id = 'T%d' % idx<\exit>
anns[ann_id] = {<\exit>
'type': entity['obj'],<\exit>
'offsets': ((entity['begin'], entity['end']), ),<\exit>
'texts': (text[entity['begin']:entity['end']], ),<\exit>
}<\exit>
return anns<\exit>
class RandomTaggerHandler(BaseHTTPRequestHandler):<\exit>
def do_POST(self):<\exit>
field_storage = FieldStorage(<\exit>
headers=self.headers,<\exit>
environ={<\exit>
'REQUEST_METHOD':'POST',<\exit>
'CONTENT_TYPE':self.headers['Content-type'],<\exit>
},<\exit>
fp=self.rfile)<\exit>
try:<\exit>
headers = build_headers("", "")<\exit>
text    = field_storage.value.decode('utf-8')<\exit>
data    = build_data(text)<\exit>
annotator_url = "http://pubdictionaries.dbcls.jp:80/dictionaries/EntrezGene%20-%20Homo%20Sapiens/text_annotation?matching_method=approximate&max_tokens=6&min_tokens=1&threshold=0.8&top_n=0"<\exit>
request = urllib2.Request(annotator_url, data=data, headers=headers)<\exit>
f   = urllib2.urlopen(request)<\exit>
res = f.read()<\exit>
f.close()<\exit>
json_dic = convert_for_brat(json.loads(res), text)<\exit>
except KeyError:<\exit>
json_dic = {}<\exit>
self.send_response(200)<\exit>
self.send_header('Content-type', 'application/json; charset=utf-8')<\exit>
self.end_headers()<\exit>
self.wfile.write(dumps(json_dic))<\exit>
print >> stderr, ('Generated %d annotations' % len(json_dic))<\exit>
def log_message(self, format, *args):<\exit>
return<\exit>
def main(args):<\exit>
argp = ARGPARSER.parse_args(args[1:])<\exit>
server_class = HTTPServer<\exit>
httpd = server_class(('localhost', argp.port), RandomTaggerHandler)<\exit>
print >> stderr, 'PubDictionary NER tagger service started on port %s' % (argp.port)<\exit>
try:<\exit>
httpd.serve_forever()<\exit>
except KeyboardInterrupt:<\exit>
pass<\exit>
httpd.server_close()<\exit>
print >> stderr, 'PubDictionary tagger service stopped'<\exit>
if __name__ == '__main__':<\exit>
from sys import argv<\exit>
exit(main(argv))<\exit>
import unittest<\exit>
from ns.core import Simulator, Seconds, Config, int64x64_t<\exit>
import ns.core<\exit>
import ns.network<\exit>
import ns.internet<\exit>
import ns.mobility<\exit>
import ns.csma<\exit>
class TestSimulator(unittest.TestCase):<\exit>
def testScheduleNow(self):<\exit>
def callback(args):<\exit>
self._args_received = args<\exit>
self._cb_time = Simulator.Now()<\exit>
Simulator.Destroy()<\exit>
self._args_received = None<\exit>
self._cb_time = None<\exit>
Simulator.ScheduleNow(callback, "args")<\exit>
Simulator.Run()<\exit>
self.assertEqual(self._args_received, "args")<\exit>
self.assertEqual(self._cb_time.GetSeconds(), 0.0)<\exit>
def testSchedule(self):<\exit>
def callback(args):<\exit>
self._args_received = args<\exit>
self._cb_time = Simulator.Now()<\exit>
Simulator.Destroy()<\exit>
self._args_received = None<\exit>
self._cb_time = None<\exit>
Simulator.Schedule(Seconds(123), callback, "args")<\exit>
Simulator.Run()<\exit>
self.assertEqual(self._args_received, "args")<\exit>
self.assertEqual(self._cb_time.GetSeconds(), 123.0)<\exit>
def testScheduleDestroy(self):<\exit>
def callback(args):<\exit>
self._args_received = args<\exit>
self._cb_time = Simulator.Now()<\exit>
Simulator.Destroy()<\exit>
self._args_received = None<\exit>
self._cb_time = None<\exit>
def null(): pass<\exit>
Simulator.Schedule(Seconds(123), null)<\exit>
Simulator.ScheduleDestroy(callback, "args")<\exit>
Simulator.Run()<\exit>
Simulator.Destroy()<\exit>
self.assertEqual(self._args_received, "args")<\exit>
self.assertEqual(self._cb_time.GetSeconds(), 123.0)<\exit>
def testTimeComparison(self):<\exit>
self.assert_(Seconds(123) == Seconds(123))<\exit>
self.assert_(Seconds(123) >= Seconds(123))<\exit>
self.assert_(Seconds(123) <= Seconds(123))<\exit>
self.assert_(Seconds(124) > Seconds(123))<\exit>
self.assert_(Seconds(123) < Seconds(124))<\exit>
def testTimeNumericOperations(self):<\exit>
self.assertEqual(Seconds(10) + Seconds(5), Seconds(15))<\exit>
self.assertEqual(Seconds(10) - Seconds(5), Seconds(5))<\exit>
v1 = int64x64_t(5.0)*int64x64_t(10)<\exit>
self.assertEqual(v1, int64x64_t(50))<\exit>
def testConfig(self):<\exit>
Config.SetDefault("ns3::OnOffApplication::PacketSize", ns.core.UintegerValue(123))<\exit>
def testSocket(self):<\exit>
node = ns.network.Node()<\exit>
internet = ns.internet.InternetStackHelper()<\exit>
internet.Install(node)<\exit>
self._received_packet = None<\exit>
def rx_callback(socket):<\exit>
assert self._received_packet is None<\exit>
self._received_packet = socket.Recv()<\exit>
sink = ns.network.Socket.CreateSocket(node, ns.core.TypeId.LookupByName("ns3::UdpSocketFactory"))<\exit>
sink.Bind(ns.network.InetSocketAddress(ns.network.Ipv4Address.GetAny(), 80))<\exit>
sink.SetRecvCallback(rx_callback)<\exit>
source = ns.network.Socket.CreateSocket(node, ns.core.TypeId.LookupByName("ns3::UdpSocketFactory"))<\exit>
source.SendTo(ns.network.Packet(19), 0, ns.network.InetSocketAddress(ns.network.Ipv4Address("127.0.0.1"), 80))<\exit>
Simulator.Run()<\exit>
self.assert_(self._received_packet is not None)<\exit>
self.assertEqual(self._received_packet.GetSize(), 19)<\exit>
def testAttributes(self):<\exit>
queue = ns.network.DropTailQueue()<\exit>
queue.SetAttribute("MaxPackets", ns.core.UintegerValue(123456))<\exit>
limit = ns.core.UintegerValue()<\exit>
queue.GetAttribute("MaxPackets", limit)<\exit>
self.assertEqual(limit.Get(), 123456)<\exit>
mobility = ns.mobility.RandomWaypointMobilityModel()<\exit>
ptr = ns.core.PointerValue()<\exit>
mobility.GetAttribute("PositionAllocator", ptr)<\exit>
self.assertEqual(ptr.GetObject(), None)<\exit>
pos = ns.mobility.ListPositionAllocator()<\exit>
mobility.SetAttribute("PositionAllocator", ns.core.PointerValue(pos))<\exit>
ptr = ns.core.PointerValue()<\exit>
mobility.GetAttribute("PositionAllocator", ptr)<\exit>
self.assert_(ptr.GetObject() is not None)<\exit>
def testIdentity(self):<\exit>
csma = ns.csma.CsmaNetDevice()<\exit>
channel = ns.csma.CsmaChannel()<\exit>
csma.Attach(channel)<\exit>
c1 = csma.GetChannel()<\exit>
c2 = csma.GetChannel()<\exit>
self.assert_(c1 is c2)<\exit>
def testTypeId(self):<\exit>
typeId1 = ns.core.TypeId.LookupByNameFailSafe("ns3::UdpSocketFactory")<\exit>
self.assertEqual(typeId1.GetName (), "ns3::UdpSocketFactory")<\exit>
self.assertRaises(KeyError, ns.core.TypeId.LookupByNameFailSafe, "__InvalidTypeName__")<\exit>
def testCommandLine(self):<\exit>
cmd = ns.core.CommandLine()<\exit>
cmd.AddValue("Test1", "this is a test option")<\exit>
cmd.AddValue("Test2", "this is a test option")<\exit>
cmd.AddValue("Test3", "this is a test option", variable="test_xxx")<\exit>
cmd.Test1 = None<\exit>
cmd.Test2 = None<\exit>
cmd.test_xxx = None<\exit>
class Foo:<\exit>
pass<\exit>
foo = Foo()<\exit>
foo.test_foo = None<\exit>
cmd.AddValue("Test4", "this is a test option", variable="test_foo", namespace=foo)<\exit>
cmd.Parse(["python", "--Test1=value1", "--Test2=value2", "--Test3=123", "--Test4=xpto"])<\exit>
self.assertEqual(cmd.Test1, "value1")<\exit>
self.assertEqual(cmd.Test2, "value2")<\exit>
self.assertEqual(cmd.test_xxx, "123")<\exit>
self.assertEqual(foo.test_foo, "xpto")<\exit>
def testSubclass(self):<\exit>
class MyNode(ns.network.Node):<\exit>
def __init__(self):<\exit>
super(MyNode, self).__init__()<\exit>
node = MyNode()<\exit>
if __name__ == '__main__':<\exit>
unittest.main()<\exit>
import os, sys<\exit>
from waflib import Utils, Options, Errors<\exit>
from waflib.Logs import debug, warn, info, error<\exit>
from waflib.TaskGen import extension, before_method, after_method, feature<\exit>
from waflib.Configure import conf<\exit>
FRAG =<\exit>
INST =<\exit>
@extension('.py')<\exit>
def process_py(self, node):<\exit>
try:<\exit>
if not self.bld.is_install:<\exit>
return<\exit>
except:<\exit>
return<\exit>
try:<\exit>
if not self.install_path:<\exit>
return<\exit>
except AttributeError:<\exit>
self.install_path = '${PYTHONDIR}'<\exit>
def inst_py(ctx):<\exit>
install_from = getattr(self, 'install_from', None)<\exit>
if install_from:<\exit>
install_from = self.path.find_dir(install_from)<\exit>
install_pyfile(self, node, install_from)<\exit>
self.bld.add_post_fun(inst_py)<\exit>
def install_pyfile(self, node, install_from=None):<\exit>
from_node = install_from or node.parent<\exit>
tsk = self.bld.install_as(self.install_path + '/' + node.path_from(from_node), node, postpone=False)<\exit>
path = tsk.get_install_path()<\exit>
if self.bld.is_install < 0:<\exit>
info("+ removing byte compiled python files")<\exit>
for x in 'co':<\exit>
try:<\exit>
os.remove(path + x)<\exit>
except OSError:<\exit>
pass<\exit>
if self.bld.is_install > 0:<\exit>
try:<\exit>
st1 = os.stat(path)<\exit>
except:<\exit>
error('The python file is missing, this should not happen')<\exit>
for x in ['c', 'o']:<\exit>
do_inst = self.env['PY' + x.upper()]<\exit>
try:<\exit>
st2 = os.stat(path + x)<\exit>
except OSError:<\exit>
pass<\exit>
else:<\exit>
if st1.st_mtime <= st2.st_mtime:<\exit>
do_inst = False<\exit>
if do_inst:<\exit>
lst = (x == 'o') and [self.env['PYFLAGS_OPT']] or []<\exit>
(a, b, c) = (path, path + x, tsk.get_install_path(destdir=False) + x)<\exit>
argv = self.env['PYTHON'] + lst + ['-c', INST, a, b, c]<\exit>
info('+ byte compiling %r' % (path + x))<\exit>
ret = Utils.subprocess.Popen(argv).wait()<\exit>
if ret:<\exit>
raise Errors.WafError('py%s compilation failed %r' % (x, path))<\exit>
@feature('py')<\exit>
def feature_py(self):<\exit>
pass<\exit>
@feature('pyext')<\exit>
@before_method('propagate_uselib_vars', 'apply_link')<\exit>
@after_method('apply_bundle')<\exit>
def init_pyext(self):<\exit>
try:<\exit>
if not self.install_path:<\exit>
return<\exit>
except AttributeError:<\exit>
self.install_path = '${PYTHONARCHDIR}'<\exit>
self.uselib = self.to_list(getattr(self, 'uselib', []))<\exit>
if not 'PYEXT' in self.uselib:<\exit>
self.uselib.append('PYEXT')<\exit>
self.env['cshlib_PATTERN'] = self.env['cxxshlib_PATTERN'] = self.env['macbundle_PATTERN'] = self.env['pyext_PATTERN']<\exit>
@feature('pyext')<\exit>
@before_method('apply_link', 'apply_bundle')<\exit>
def set_bundle(self):<\exit>
if sys.platform.startswith('darwin'):<\exit>
self.mac_bundle = True<\exit>
@before_method('propagate_uselib_vars')<\exit>
@feature('pyembed')<\exit>
def init_pyembed(self):<\exit>
self.uselib = self.to_list(getattr(self, 'uselib', []))<\exit>
if not 'PYEMBED' in self.uselib:<\exit>
self.uselib.append('PYEMBED')<\exit>
@conf<\exit>
def get_python_variables(conf, variables, imports=['import sys']):<\exit>
program = list(imports)<\exit>
program.append('')<\exit>
for v in variables:<\exit>
program.append("print(repr(%s))" % v)<\exit>
os_env = dict(os.environ)<\exit>
try:<\exit>
del os_env['MACOSX_DEPLOYMENT_TARGET']<\exit>
except KeyError:<\exit>
pass<\exit>
try:<\exit>
out = conf.cmd_and_log(conf.env.PYTHON + ['-c', '\n'.join(program)], env=os_env)<\exit>
except Errors.WafError:<\exit>
conf.fatal('The distutils module is unusable: install "python-devel"?')<\exit>
return_values = []<\exit>
for s in out.split('\n'):<\exit>
s = s.strip()<\exit>
if not s:<\exit>
continue<\exit>
if s == 'None':<\exit>
return_values.append(None)<\exit>
elif s[0] == "'" and s[-1] == "'":<\exit>
return_values.append(s[1:-1])<\exit>
elif s[0].isdigit():<\exit>
return_values.append(int(s))<\exit>
else: break<\exit>
return return_values<\exit>
@conf<\exit>
def check_python_headers(conf):<\exit>
if not conf.env['CC_NAME'] and not conf.env['CXX_NAME']:<\exit>
conf.fatal('load a compiler first (gcc, g++, ..)')<\exit>
if not conf.env['PYTHON_VERSION']:<\exit>
conf.check_python_version()<\exit>
env = conf.env<\exit>
pybin = conf.env.PYTHON<\exit>
if not pybin:<\exit>
conf.fatal('could not find the python executable')<\exit>
v = 'prefix SO LDFLAGS LIBDIR LIBPL INCLUDEPY Py_ENABLE_SHARED MACOSX_DEPLOYMENT_TARGET LDSHARED CFLAGS'.split()<\exit>
try:<\exit>
lst = conf.get_python_variables(["get_config_var('%s') or ''" % x for x in v],<\exit>
['from distutils.sysconfig import get_config_var'])<\exit>
except RuntimeError:<\exit>
conf.fatal("Python development headers not found (-v for details).")<\exit>
vals = ['%s = %r' % (x, y) for (x, y) in zip(v, lst)]<\exit>
conf.to_log("Configuration returned from %r:\n%r\n" % (pybin, '\n'.join(vals)))<\exit>
dct = dict(zip(v, lst))<\exit>
x = 'MACOSX_DEPLOYMENT_TARGET'<\exit>
if dct[x]:<\exit>
conf.env[x] = conf.environ[x] = dct[x]<\exit>
env['pyext_PATTERN'] = '%s' + dct['SO']<\exit>
all_flags = dct['LDFLAGS'] + ' ' + dct['CFLAGS']<\exit>
conf.parse_flags(all_flags, 'PYEMBED')<\exit>
all_flags = dct['LDFLAGS'] + ' ' + dct['LDSHARED'] + ' ' + dct['CFLAGS']<\exit>
conf.parse_flags(all_flags, 'PYEXT')<\exit>
result = None<\exit>
for name in ('python' + env['PYTHON_VERSION'], 'python' + env['PYTHON_VERSION'].replace('.', '')):<\exit>
if not result and env['LIBPATH_PYEMBED']:<\exit>
path = env['LIBPATH_PYEMBED']<\exit>
conf.to_log("\n\n<\exit>
result = conf.check(lib=name, uselib='PYEMBED', libpath=path, mandatory=False, msg='Checking for library %s in LIBPATH_PYEMBED' % name)<\exit>
if not result and dct['LIBDIR']:<\exit>
path = [dct['LIBDIR']]<\exit>
conf.to_log("\n\n<\exit>
result = conf.check(lib=name, uselib='PYEMBED', libpath=path, mandatory=False, msg='Checking for library %s in LIBDIR' % name)<\exit>
if not result and dct['LIBPL']:<\exit>
path = [dct['LIBPL']]<\exit>
conf.to_log("\n\n<\exit>
result = conf.check(lib=name, uselib='PYEMBED', libpath=path, mandatory=False, msg='Checking for library %s in python_LIBPL' % name)<\exit>
if not result:<\exit>
path = [os.path.join(dct['prefix'], "libs")]<\exit>
conf.to_log("\n\n<\exit>
result = conf.check(lib=name, uselib='PYEMBED', libpath=path, mandatory=False, msg='Checking for library %s in $prefix/libs' % name)<\exit>
if result:<\exit>
break<\exit>
if result:<\exit>
env['LIBPATH_PYEMBED'] = path<\exit>
env.append_value('LIB_PYEMBED', [name])<\exit>
else:<\exit>
conf.to_log("\n\n<\exit>
if (Utils.is_win32 or sys.platform.startswith('os2')<\exit>
or dct['Py_ENABLE_SHARED']):<\exit>
env['LIBPATH_PYEXT'] = env['LIBPATH_PYEMBED']<\exit>
env['LIB_PYEXT'] = env['LIB_PYEMBED']<\exit>
num = '.'.join(env['PYTHON_VERSION'].split('.')[:2])<\exit>
conf.find_program(['python%s-config' % num, 'python-config-%s' % num, 'python%sm-config' % num], var='PYTHON_CONFIG', mandatory=False)<\exit>
includes = []<\exit>
if conf.env.PYTHON_CONFIG:<\exit>
for incstr in conf.cmd_and_log([ conf.env.PYTHON_CONFIG, '--includes']).strip().split():<\exit>
if (incstr.startswith('-I') or incstr.startswith('/I')):<\exit>
incstr = incstr[2:]<\exit>
if incstr not in includes:<\exit>
includes.append(incstr)<\exit>
conf.to_log("Include path for Python extensions "<\exit>
"(found via python-config --includes): %r\n" % (includes,))<\exit>
env['INCLUDES_PYEXT'] = includes<\exit>
env['INCLUDES_PYEMBED'] = includes<\exit>
else:<\exit>
conf.to_log("Include path for Python extensions "<\exit>
"(found via distutils module): %r\n" % (dct['INCLUDEPY'],))<\exit>
env['INCLUDES_PYEXT'] = [dct['INCLUDEPY']]<\exit>
env['INCLUDES_PYEMBED'] = [dct['INCLUDEPY']]<\exit>
if env['CC_NAME'] == 'gcc':<\exit>
env.append_value('CFLAGS_PYEMBED', ['-fno-strict-aliasing'])<\exit>
env.append_value('CFLAGS_PYEXT', ['-fno-strict-aliasing'])<\exit>
if env['CXX_NAME'] == 'gcc':<\exit>
env.append_value('CXXFLAGS_PYEMBED', ['-fno-strict-aliasing'])<\exit>
env.append_value('CXXFLAGS_PYEXT', ['-fno-strict-aliasing'])<\exit>
if env.CC_NAME == "msvc":<\exit>
from distutils.msvccompiler import MSVCCompiler<\exit>
dist_compiler = MSVCCompiler()<\exit>
dist_compiler.initialize()<\exit>
env.append_value('CFLAGS_PYEXT', dist_compiler.compile_options)<\exit>
env.append_value('CXXFLAGS_PYEXT', dist_compiler.compile_options)<\exit>
env.append_value('LINKFLAGS_PYEXT', dist_compiler.ldflags_shared)<\exit>
try:<\exit>
conf.check(header_name='Python.h', define_name='HAVE_PYTHON_H',<\exit>
uselib='PYEMBED', fragment=FRAG,<\exit>
errmsg='Could not find the python development headers')<\exit>
except conf.errors.ConfigurationError:<\exit>
conf.check_cfg(path=conf.env.PYTHON_CONFIG, package='', uselib_store='PYEMBED', args=['--cflags', '--libs'])<\exit>
conf.check(header_name='Python.h', define_name='HAVE_PYTHON_H', msg='Getting the python flags from python-config',<\exit>
uselib='PYEMBED', fragment=FRAG,<\exit>
errmsg='Could not find the python development headers elsewhere')<\exit>
@conf<\exit>
def check_python_version(conf, minver=None):<\exit>
assert minver is None or isinstance(minver, tuple)<\exit>
pybin = conf.env['PYTHON']<\exit>
if not pybin:<\exit>
conf.fatal('could not find the python executable')<\exit>
cmd = pybin + ['-c', 'import sys\nfor x in sys.version_info: print(str(x))']<\exit>
debug('python: Running python command %r' % cmd)<\exit>
lines = conf.cmd_and_log(cmd).split()<\exit>
assert len(lines) == 5, "found %i lines, expected 5: %r" % (len(lines), lines)<\exit>
pyver_tuple = (int(lines[0]), int(lines[1]), int(lines[2]), lines[3], int(lines[4]))<\exit>
result = (minver is None) or (pyver_tuple >= minver)<\exit>
if result:<\exit>
pyver = '.'.join([str(x) for x in pyver_tuple[:2]])<\exit>
conf.env['PYTHON_VERSION'] = pyver<\exit>
if 'PYTHONDIR' in conf.environ:<\exit>
pydir = conf.environ['PYTHONDIR']<\exit>
else:<\exit>
if Utils.is_win32:<\exit>
(python_LIBDEST, pydir) = \<\exit>
conf.get_python_variables(<\exit>
["get_config_var('LIBDEST') or ''",<\exit>
"get_python_lib(standard_lib=0, prefix=%r) or ''" % conf.env['PREFIX']],<\exit>
['from distutils.sysconfig import get_config_var, get_python_lib'])<\exit>
else:<\exit>
python_LIBDEST = None<\exit>
(pydir,) = \<\exit>
conf.get_python_variables(<\exit>
["get_python_lib(standard_lib=0, prefix=%r) or ''" % conf.env['PREFIX']],<\exit>
['from distutils.sysconfig import get_python_lib'])<\exit>
if python_LIBDEST is None:<\exit>
if conf.env['LIBDIR']:<\exit>
python_LIBDEST = os.path.join(conf.env['LIBDIR'], "python" + pyver)<\exit>
else:<\exit>
python_LIBDEST = os.path.join(conf.env['PREFIX'], "lib", "python" + pyver)<\exit>
if 'PYTHONARCHDIR' in conf.environ:<\exit>
pyarchdir = conf.environ['PYTHONARCHDIR']<\exit>
else:<\exit>
(pyarchdir, ) = conf.get_python_variables(<\exit>
["get_python_lib(plat_specific=1, standard_lib=0, prefix=%r) or ''" % conf.env['PREFIX']],<\exit>
['from distutils.sysconfig import get_python_lib'])<\exit>
if not pyarchdir:<\exit>
pyarchdir = pydir<\exit>
if hasattr(conf, 'define'):<\exit>
conf.define('PYTHONDIR', pydir)<\exit>
conf.define('PYTHONARCHDIR', pyarchdir)<\exit>
conf.env['PYTHONDIR'] = pydir<\exit>
conf.env['PYTHONARCHDIR'] = pyarchdir<\exit>
pyver_full = '.'.join(map(str, pyver_tuple[:3]))<\exit>
if minver is None:<\exit>
conf.msg('Checking for python version', pyver_full)<\exit>
else:<\exit>
minver_str = '.'.join(map(str, minver))<\exit>
conf.msg('Checking for python version', pyver_tuple, ">= %s" % (minver_str,) and 'GREEN' or 'YELLOW')<\exit>
if not result:<\exit>
conf.fatal('The python version is too old, expecting %r' % (minver,))<\exit>
PYTHON_MODULE_TEMPLATE =<\exit>
@conf<\exit>
def check_python_module(conf, module_name):<\exit>
conf.start_msg('Python module %s' % module_name)<\exit>
try:<\exit>
conf.cmd_and_log(conf.env['PYTHON'] + ['-c', PYTHON_MODULE_TEMPLATE % module_name])<\exit>
except:<\exit>
conf.end_msg(False)<\exit>
conf.fatal('Could not find the python module %r' % module_name)<\exit>
conf.end_msg(True)<\exit>
def configure(conf):<\exit>
try:<\exit>
conf.find_program('python', var='PYTHON')<\exit>
except conf.errors.ConfigurationError:<\exit>
warn("could not find a python executable, setting to sys.executable '%s'" % sys.executable)<\exit>
conf.env.PYTHON = sys.executable<\exit>
if conf.env.PYTHON != sys.executable:<\exit>
warn("python executable '%s' different from sys.executable '%s'" % (conf.env.PYTHON, sys.executable))<\exit>
conf.env.PYTHON = conf.cmd_to_list(conf.env.PYTHON)<\exit>
v = conf.env<\exit>
v['PYCMD'] = '"import sys, py_compile;py_compile.compile(sys.argv[1], sys.argv[2])"'<\exit>
v['PYFLAGS'] = ''<\exit>
v['PYFLAGS_OPT'] = '-O'<\exit>
v['PYC'] = getattr(Options.options, 'pyc', 1)<\exit>
v['PYO'] = getattr(Options.options, 'pyo', 1)<\exit>
def options(opt):<\exit>
opt.add_option('--nopyc',<\exit>
action='store_false',<\exit>
default=1,<\exit>
help = 'Do not install bytecode compiled .pyc files (configuration) [Default:install]',<\exit>
dest = 'pyc')<\exit>
opt.add_option('--nopyo',<\exit>
action='store_false',<\exit>
default=1,<\exit>
help='Do not install optimised compiled .pyo files (configuration) [Default:install]',<\exit>
dest='pyo')<\exit>
__date__ = '$Date: 2007/03/27 03:15:06 $'<\exit>
__version__ = '$Revision: 0.45 $'<\exit>
__credits__ =<\exit>
import re<\exit>
import sys<\exit>
import time<\exit>
import random<\exit>
try:<\exit>
True, False<\exit>
except NameError:<\exit>
True, False = (1==1, 0==1)<\exit>
def int2bin(i, n):<\exit>
hex2bin = {'0': '0000', '1': '0001', '2': '0010', '3': '0011',<\exit>
'4': '0100', '5': '0101', '6': '0110', '7': '0111',<\exit>
'8': '1000', '9': '1001', 'a': '1010', 'b': '1011',<\exit>
'c': '1100', 'd': '1101', 'e': '1110', 'f': '1111'}<\exit>
result = ''.join([hex2bin[x] for x in hex(i).lower().replace('l','')[2:]])<\exit>
if '1' in result[:-n]:<\exit>
raise ValueError("Value too large for given number of bits.")<\exit>
result = result[-n:]<\exit>
result = '0'*(n-len(result)) + result<\exit>
return result<\exit>
def bin2int(bin_string):<\exit>
return int(bin_string, 2)<\exit>
def reverse(input_string):<\exit>
str_list = list(input_string)<\exit>
str_list.reverse()<\exit>
return ''.join(str_list)<\exit>
def transpose(matrix):<\exit>
result = zip(*matrix)<\exit>
result = map(list, result)<\exit>
return result<\exit>
def polygon_area(points_list, precision=100):<\exit>
for i in range(len(points_list)):<\exit>
points_list[i] = (int(points_list[i][0] * precision),<\exit>
int(points_list[i][1] * precision))<\exit>
if points_list[-1] != points_list[0]:<\exit>
points_list.append(points_list[0])<\exit>
area = 0<\exit>
for i in range(len(points_list)-1):<\exit>
(x_i, y_i) = points_list[i]<\exit>
(x_i_plus_1, y_i_plus_1) = points_list[i+1]<\exit>
area = area + (x_i_plus_1 * y_i) - (y_i_plus_1 * x_i)<\exit>
area = abs(area / 2)<\exit>
area = float(area)/(precision**2)<\exit>
return area<\exit>
def timestamp():<\exit>
return time.asctime()<\exit>
def pt2str(point):<\exit>
return "(%s, %s)" % (str(point[0]), str(point[1]))<\exit>
def gcf(a, b, epsilon=1e-16):<\exit>
result = max(a, b)<\exit>
remainder = min(a, b)<\exit>
while remainder and abs(remainder) > epsilon:<\exit>
new_remainder = result % remainder<\exit>
result = remainder<\exit>
remainder = new_remainder<\exit>
return abs(result)<\exit>
def lcm(a, b, precision=None):<\exit>
denom = gcf(a, b)<\exit>
if denom == 0:<\exit>
result = 0<\exit>
else:<\exit>
result = a * (b / denom)<\exit>
return result<\exit>
def permutations(input_list):<\exit>
out_lists = []<\exit>
if len(input_list) > 1:<\exit>
item = input_list[0]<\exit>
sub_lists = permutations(input_list[1:])<\exit>
for sub_list in sub_lists:<\exit>
for i in range(len(input_list)):<\exit>
new_list = sub_list[:]<\exit>
new_list.insert(i, item)<\exit>
out_lists.append(new_list)<\exit>
else:<\exit>
out_lists = [input_list]<\exit>
return out_lists<\exit>
def reduce_fraction(fraction):<\exit>
(numerator, denominator) = fraction<\exit>
common_factor = abs(gcf(numerator, denominator))<\exit>
result = (numerator/common_factor, denominator/common_factor)<\exit>
return result<\exit>
def quantile(l, p):<\exit>
l_sort = l[:]<\exit>
l_sort.sort()<\exit>
n = len(l)<\exit>
r = 1 + ((n - 1) * p)<\exit>
i = int(r)<\exit>
f = r - i<\exit>
if i < n:<\exit>
result =  (1-f)*l_sort[i-1] + f*l_sort[i]<\exit>
else:<\exit>
result = l_sort[i-1]<\exit>
return result<\exit>
def trim(l):<\exit>
l_sort = l[:]<\exit>
l_sort.sort()<\exit>
if len(l_sort) % 2 == 0:<\exit>
index = int(len(l_sort) / 2)<\exit>
median = float(l_sort[index] + l_sort[index-1]) / 2<\exit>
else:<\exit>
index = int(len(l_sort) / 2)<\exit>
median = l_sort[index]<\exit>
q1 = quantile(l_sort, 0.25)<\exit>
q3 = quantile(l_sort, 0.75)<\exit>
iqr = q3 - q1<\exit>
iqr_extra = iqr * 1.5<\exit>
def in_interval(x, i=iqr_extra, q1=q1, q3=q3):<\exit>
return (x >= q1-i and x <= q3+i)<\exit>
l_trimmed = [x for x in l_sort if in_interval(x)]<\exit>
return l_trimmed<\exit>
def nice_units(value, dp=0, sigfigs=None, suffix='', space=' ',<\exit>
use_extra_prefixes=False, use_full_name=False, mode='si'):<\exit>
si_prefixes = {1e24:  ('Y', 'yotta'),<\exit>
1e21:  ('Z', 'zetta'),<\exit>
1e18:  ('E', 'exa'),<\exit>
1e15:  ('P', 'peta'),<\exit>
1e12:  ('T', 'tera'),<\exit>
1e9:   ('G', 'giga'),<\exit>
1e6:   ('M', 'mega'),<\exit>
1e3:   ('k', 'kilo'),<\exit>
1e-3:  ('m', 'milli'),<\exit>
1e-6:  ('u', 'micro'),<\exit>
1e-9:  ('n', 'nano'),<\exit>
1e-12: ('p', 'pico'),<\exit>
1e-15: ('f', 'femto'),<\exit>
1e-18: ('a', 'atto'),<\exit>
1e-21: ('z', 'zepto'),<\exit>
1e-24: ('y', 'yocto')<\exit>
}<\exit>
if use_extra_prefixes:<\exit>
si_prefixes.update({1e2:  ('h', 'hecto'),<\exit>
1e1:  ('da', 'deka'),<\exit>
1e-1: ('d', 'deci'),<\exit>
1e-2: ('c', 'centi')<\exit>
})<\exit>
bin_prefixes = {2**10: ('K', 'kilo'),<\exit>
2**20: ('M', 'mega'),<\exit>
2**30: ('G', 'mega'),<\exit>
2**40: ('T', 'tera'),<\exit>
2**50: ('P', 'peta'),<\exit>
2**60: ('E', 'exa')<\exit>
}<\exit>
if mode == 'bin':<\exit>
prefixes = bin_prefixes<\exit>
else:<\exit>
prefixes = si_prefixes<\exit>
prefixes[1] = ('', '')<\exit>
multipliers = prefixes.keys()<\exit>
multipliers.sort()<\exit>
mult = None<\exit>
for i in range(len(multipliers) - 1):<\exit>
lower_mult = multipliers[i]<\exit>
upper_mult = multipliers[i+1]<\exit>
if lower_mult <= value < upper_mult:<\exit>
mult_i = i<\exit>
break<\exit>
if mult is None:<\exit>
if value < multipliers[0]:<\exit>
mult_i = 0<\exit>
elif value >= multipliers[-1]:<\exit>
mult_i = len(multipliers) - 1<\exit>
mult = multipliers[mult_i]<\exit>
new_value = value / mult<\exit>
if sigfigs is None:<\exit>
if mult_i < (len(multipliers) - 1) and \<\exit>
round(new_value, dp) == \<\exit>
round((multipliers[mult_i+1] / mult), dp):<\exit>
mult = multipliers[mult_i + 1]<\exit>
new_value = value / mult<\exit>
if use_full_name:<\exit>
label_type = 1<\exit>
else:<\exit>
label_type = 0<\exit>
if sigfigs is None:<\exit>
str_value = eval('"%.'+str(dp)+'f" % new_value', locals(), {})<\exit>
else:<\exit>
str_value = eval('"%.'+str(sigfigs)+'g" % new_value', locals(), {})<\exit>
return str_value + space + prefixes[mult][label_type] + suffix<\exit>
def uniquify(seq, preserve_order=False):<\exit>
try:<\exit>
d = {}<\exit>
if preserve_order:<\exit>
return [x for x in seq if (x not in d) and not d.__setitem__(x, 0)]<\exit>
else:<\exit>
for x in seq:<\exit>
d[x] = 0<\exit>
return d.keys()<\exit>
except TypeError:<\exit>
result = []<\exit>
app = result.append<\exit>
for x in seq:<\exit>
if x not in result:<\exit>
app(x)<\exit>
return result<\exit>
unique = uniquify<\exit>
def reverse_dict(d):<\exit>
result = {}<\exit>
for key, value in d.items():<\exit>
result[value] = key<\exit>
return result<\exit>
def lsb(x, n):<\exit>
return x & ((2 ** n) - 1)<\exit>
def gray_encode(i):<\exit>
return i ^ (i >> 1)<\exit>
def random_vec(bits, max_value=None):<\exit>
vector = ""<\exit>
for _ in range(int(bits / 10) + 1):<\exit>
i = int((2**10) * random.random())<\exit>
vector += int2bin(i, 10)<\exit>
if max_value and (max_value < 2 ** bits - 1):<\exit>
vector = int2bin((int(vector, 2) / (2 ** bits - 1)) * max_value, bits)<\exit>
return vector[0:bits]<\exit>
def binary_range(bits):<\exit>
l = []<\exit>
v = ['0'] * bits<\exit>
toggle = [1] + [0] * bits<\exit>
while toggle[bits] != 1:<\exit>
v_copy = v[:]<\exit>
v_copy.reverse()<\exit>
l.append(''.join(v_copy))<\exit>
toggle = [1] + [0]*bits<\exit>
i = 0<\exit>
while i < bits and toggle[i] == 1:<\exit>
if toggle[i]:<\exit>
if v[i] == '0':<\exit>
v[i] = '1'<\exit>
toggle[i+1] = 0<\exit>
else:<\exit>
v[i] = '0'<\exit>
toggle[i+1] = 1<\exit>
i += 1<\exit>
return l<\exit>
def float_range(start, stop=None, step=None):<\exit>
if stop is None:<\exit>
stop = float(start)<\exit>
start = 0.0<\exit>
if step is None:<\exit>
step = 1.0<\exit>
cur = float(start)<\exit>
l = []<\exit>
while cur < stop:<\exit>
l.append(cur)<\exit>
cur += step<\exit>
return l<\exit>
def find_common_fixes(s1, s2):<\exit>
prefix = []<\exit>
suffix = []<\exit>
i = 0<\exit>
common_len = min(len(s1), len(s2))<\exit>
while i < common_len:<\exit>
if s1[i] != s2[i]:<\exit>
break<\exit>
prefix.append(s1[i])<\exit>
i += 1<\exit>
i = 1<\exit>
while i < (common_len + 1):<\exit>
if s1[-i] != s2[-i]:<\exit>
break<\exit>
suffix.append(s1[-i])<\exit>
i += 1<\exit>
suffix.reverse()<\exit>
prefix = ''.join(prefix)<\exit>
suffix = ''.join(suffix)<\exit>
return (prefix, suffix)<\exit>
def is_rotated(seq1, seq2):<\exit>
if len(seq1) != len(seq2):<\exit>
return False<\exit>
start_indexes = []<\exit>
head_item = seq2[0]<\exit>
for index1 in range(len(seq1)):<\exit>
if seq1[index1] == head_item:<\exit>
start_indexes.append(index1)<\exit>
double_seq1 = seq1 + seq1<\exit>
for index1 in start_indexes:<\exit>
if double_seq1[index1:index1+len(seq1)] == seq2:<\exit>
return True<\exit>
return False<\exit>
def getmodule(obj):<\exit>
if hasattr(obj, 'func_globals'):<\exit>
func = obj<\exit>
else:<\exit>
func = None<\exit>
for item in obj.__dict__.values():<\exit>
if hasattr(item, 'func_globals'):<\exit>
func = item<\exit>
break<\exit>
if func is None:<\exit>
raise ValueError("No functions attached to object: %r" % obj)<\exit>
module_name = func.func_globals['__name__']<\exit>
module = sys.modules[module_name]<\exit>
return module<\exit>
def round_grid(value, grid, mode=0):<\exit>
off_grid = value % grid<\exit>
if mode == 0:<\exit>
add_one = int(off_grid >= (grid / 2.0))<\exit>
elif mode == 1 and off_grid:<\exit>
add_one = 1<\exit>
elif mode == -1 and off_grid:<\exit>
add_one = 0<\exit>
result = ((int(value / grid) + add_one) * grid)<\exit>
return result<\exit>
def get_args(argv):<\exit>
d = {}<\exit>
args = []<\exit>
for arg in argv:<\exit>
if arg.startswith('-'):<\exit>
parts = re.sub(r'^-+', '', arg).split('=')<\exit>
if len(parts) == 2:<\exit>
d[parts[0]] = parts[1]<\exit>
else:<\exit>
d[parts[0]] = None<\exit>
else:<\exit>
args.append(arg)<\exit>
d['args'] = args<\exit>
return d<\exit>
if __name__ == '__main__':<\exit>
import doctest<\exit>
doctest.testmod(sys.modules['__main__'])<\exit>
import re<\exit>
import operator<\exit>
import os<\exit>
BASE_DIR = (os.path.dirname(os.path.abspath(__file__)))<\exit>
debug = False<\exit>
def is_number(s):<\exit>
try:<\exit>
float(s) if '.' in s else int(s)<\exit>
return True<\exit>
except ValueError:<\exit>
return False<\exit>
def load_stop_words(stop_word_file):<\exit>
stop_words = []<\exit>
for line in open(stop_word_file):<\exit>
if line.strip()[0:1] != "#":<\exit>
for word in line.split():<\exit>
stop_words.append(word)<\exit>
return stop_words<\exit>
def separate_words(text, min_word_return_size):<\exit>
splitter = re.compile(r'[^a-zA-Z0-9_\+\-/]')<\exit>
words = []<\exit>
for single_word in splitter.split(text):<\exit>
current_word = single_word.strip().lower()<\exit>
if len(current_word) > min_word_return_size and current_word != '' and not is_number(current_word):<\exit>
words.append(current_word)<\exit>
return words<\exit>
def split_sentences(text):<\exit>
sentence_delimiters = re.compile(r'[!\?;:\[\]\t\"\(\)]|\s\-\s|[^0-9],[^a-zA-Z0-9]|\.[^a-zA-Z0-9]|\.$')<\exit>
sentences = sentence_delimiters.split(text)<\exit>
return sentences<\exit>
def build_stop_word_regex(stop_word_file_path):<\exit>
stop_word_list = load_stop_words(stop_word_file_path)<\exit>
stop_word_regex_list = []<\exit>
for word in stop_word_list:<\exit>
word_regex = r'\b'+word+r'(?![\w-])'<\exit>
stop_word_regex_list.append(word_regex)<\exit>
stop_word_pattern = re.compile('|'.join(stop_word_regex_list), re.IGNORECASE)<\exit>
return stop_word_pattern<\exit>
def generate_candidate_keywords(sentence_list, stopword_pattern):<\exit>
phrase_list = []<\exit>
for s in sentence_list:<\exit>
tmp = re.sub(stopword_pattern, '|', s.strip())<\exit>
phrases = tmp.split("|")<\exit>
for phrase in phrases:<\exit>
phrase = phrase.strip().lower()<\exit>
if phrase != "":<\exit>
phrase_list.append(phrase)<\exit>
return phrase_list<\exit>
def calculate_word_scores(phraseList):<\exit>
word_frequency = {}<\exit>
word_degree = {}<\exit>
for phrase in phraseList:<\exit>
word_list = separate_words(phrase, 0)<\exit>
word_list_length = len(word_list)<\exit>
word_list_degree = word_list_length-1<\exit>
for word in word_list:<\exit>
word_frequency.setdefault(word, 0)<\exit>
word_frequency[word] += 1<\exit>
word_degree.setdefault(word, 0)<\exit>
word_degree[word] += word_list_degree<\exit>
for item in word_frequency:<\exit>
word_degree[item] = word_degree[item]+word_frequency[item]<\exit>
word_score = {}<\exit>
for item in word_frequency:<\exit>
word_score.setdefault(item, 0)<\exit>
word_score[item] = word_degree[item]/(word_frequency[item]*1.0)<\exit>
return word_score<\exit>
def generate_candidate_keyword_scores(phrase_list, word_score):<\exit>
keyword_candidates = {}<\exit>
for phrase in phrase_list:<\exit>
keyword_candidates.setdefault(phrase, 0)<\exit>
word_list = separate_words(phrase, 0)<\exit>
candidate_score = 0<\exit>
for word in word_list:<\exit>
candidate_score += word_score[word]<\exit>
keyword_candidates[phrase] = candidate_score<\exit>
return keyword_candidates<\exit>
class Rake(object):<\exit>
def __init__(self, stop_words_path=os.path.join(BASE_DIR, "SmartStoplist.txt")):<\exit>
self.stop_words_path = stop_words_path<\exit>
self.__stop_words_pattern = build_stop_word_regex(stop_words_path)<\exit>
def run(self, text):<\exit>
sentence_list = split_sentences(text)<\exit>
phrase_list = generate_candidate_keywords(sentence_list, self.__stop_words_pattern)<\exit>
word_scores = calculate_word_scores(phrase_list)<\exit>
keyword_candidates = generate_candidate_keyword_scores(phrase_list, word_scores)<\exit>
sorted_keywords = sorted(keyword_candidates.iteritems(), key=operator.itemgetter(1), reverse=True)<\exit>
return sorted_keywords<\exit>
if __name__ == "__main__":<\exit>
text = "Compatibility of systems of linear constraints over the set of natural numbers. Criteria of compatibility of a system of linear Diophantine equations, strict inequations, and nonstrict inequations are considered. Upper bounds for components of a minimal set of solutions and algorithms of construction of minimal generating sets of solutions for all types of systems are given. These criteria and the corresponding algorithms for constructing a minimal supporting set of solutions can be used in solving all the considered types of systems and systems of mixed types."<\exit>
sentenceList = split_sentences(text)<\exit>
stoppath = os.path.join(BASE_DIR, "SmartStoplist.txt")<\exit>
stopwordpattern = build_stop_word_regex(stoppath)<\exit>
phraseList = generate_candidate_keywords(sentenceList, stopwordpattern)<\exit>
wordscores = calculate_word_scores(phraseList)<\exit>
keywordcandidates = generate_candidate_keyword_scores(phraseList, wordscores)<\exit>
if debug: print keywordcandidates<\exit>
sortedKeywords = sorted(keywordcandidates.iteritems(), key=operator.itemgetter(1), reverse=True)<\exit>
if debug: print sortedKeywords<\exit>
totalKeywords = len(sortedKeywords)<\exit>
if debug: print totalKeywords<\exit>
print sortedKeywords[0:(totalKeywords/3)]<\exit>
rake = Rake(stoppath)<\exit>
keywords = rake.run(text)<\exit>
print keywords<\exit>
class Solution(object):<\exit>
def solve(self, cipher):<\exit>
if __name__ == "__main__":<\exit>
import sys<\exit>
f = open("0.in", "r")<\exit>
solution = Solution()<\exit>
n, a, b = map(int, f.readline().strip().split(' '))<\exit>
D = map(int, f.readline().strip().split(' '))<\exit>
cipher = n, a, b, D<\exit>
s = "%s\n" % (solution.solve(cipher))<\exit>
print s,<\exit>
from argparse import ArgumentParser<\exit>
from cgi import FieldStorage<\exit>
try:<\exit>
from json import dumps<\exit>
except ImportError:<\exit>
from sys import path as sys_path<\exit>
from os.path import join as path_join<\exit>
from os.path import dirname<\exit>
sys_path.append(path_join(dirname(__file__), '../server/lib/ujson'))<\exit>
from ujson import dumps<\exit>
from random import choice, randint<\exit>
from sys import stderr<\exit>
from urlparse import urlparse<\exit>
try:<\exit>
from urlparse import parse_qs<\exit>
except ImportError:<\exit>
from cgi import parse_qs<\exit>
from BaseHTTPServer import HTTPServer, BaseHTTPRequestHandler<\exit>
ARGPARSER = ArgumentParser(description='An example HTTP tagging service, '<\exit>
'tagging Confuse-a-Cat **AND** Dead-parrot mentions!')<\exit>
ARGPARSER.add_argument('-p', '--port', type=int, default=47111,<\exit>
help='port to run the HTTP service on (default: 47111)')<\exit>
def _random_span(text):<\exit>
attempt = 1<\exit>
while True:<\exit>
start = randint(0, len(text))<\exit>
end = randint(start + 3, start + 25)<\exit>
if (<\exit>
end > len(text) or<\exit>
'\n' in text[start:end] or<\exit>
(text[start:end][-1] == ' ' or text[start:end][0] == ' ')<\exit>
):<\exit>
if attempt >= 100:<\exit>
return None, None, None<\exit>
attempt += 1<\exit>
continue<\exit>
else:<\exit>
return start, end, text[start:end]<\exit>
def _random_tagger(text):<\exit>
anns = {}<\exit>
if not text:<\exit>
return anns<\exit>
num_anns = randint(1, len(text) / 100)<\exit>
for ann_num in xrange(num_anns):<\exit>
ann_id = 'T%d' % ann_num<\exit>
_type = choice(('Confuse-a-Cat', 'Dead-parrot', ))<\exit>
start, end, span_text = _random_span(text)<\exit>
if start is None:<\exit>
continue<\exit>
anns[ann_id] = {<\exit>
'type': _type,<\exit>
'offsets': ((start, end), ),<\exit>
'texts': (span_text, ),<\exit>
}<\exit>
return anns<\exit>
class RandomTaggerHandler(BaseHTTPRequestHandler):<\exit>
def do_POST(self):<\exit>
field_storage = FieldStorage(<\exit>
headers=self.headers,<\exit>
environ={<\exit>
'REQUEST_METHOD':'POST',<\exit>
'CONTENT_TYPE':self.headers['Content-type'],<\exit>
},<\exit>
fp=self.rfile)<\exit>
try:<\exit>
json_dic = _random_tagger(field_storage.value.decode('utf-8'))<\exit>
except KeyError:<\exit>
json_dic = {}<\exit>
self.send_response(200)<\exit>
self.send_header('Content-type', 'application/json; charset=utf-8')<\exit>
self.end_headers()<\exit>
self.wfile.write(dumps(json_dic))<\exit>
print >> stderr, ('Generated %d random annotations' % len(json_dic))<\exit>
def log_message(self, format, *args):<\exit>
return<\exit>
def main(args):<\exit>
argp = ARGPARSER.parse_args(args[1:])<\exit>
server_class = HTTPServer<\exit>
httpd = server_class(('localhost', argp.port), RandomTaggerHandler)<\exit>
print >> stderr, 'Random tagger service started on port %s' % (argp.port)<\exit>
try:<\exit>
httpd.serve_forever()<\exit>
except KeyboardInterrupt:<\exit>
pass<\exit>
httpd.server_close()<\exit>
print >> stderr, 'Random tagger service stopped'<\exit>
if __name__ == '__main__':<\exit>
from sys import argv<\exit>
exit(main(argv))<\exit>
percol.import_keymap({<\exit>
"C-h" : lambda percol: percol.command.delete_backward_char(),<\exit>
"C-d" : lambda percol: percol.command.delete_forward_char(),<\exit>
"C-k" : lambda percol: percol.command.kill_end_of_line(),<\exit>
"C-y" : lambda percol: percol.command.yank(),<\exit>
"C-t" : lambda percol: percol.command.transpose_chars(),<\exit>
"C-a" : lambda percol: percol.command.beginning_of_line(),<\exit>
"C-e" : lambda percol: percol.command.end_of_line(),<\exit>
"C-b" : lambda percol: percol.command.backward_char(),<\exit>
"C-f" : lambda percol: percol.command.forward_char(),<\exit>
"M-f" : lambda percol: percol.command.forward_word(),<\exit>
"M-b" : lambda percol: percol.command.backward_word(),<\exit>
"M-d" : lambda percol: percol.command.delete_forward_word(),<\exit>
"M-h" : lambda percol: percol.command.delete_backward_word(),<\exit>
"C-n" : lambda percol: percol.command.select_next(),<\exit>
"C-p" : lambda percol: percol.command.select_previous(),<\exit>
"C-v" : lambda percol: percol.command.select_next_page(),<\exit>
"M-v" : lambda percol: percol.command.select_previous_page(),<\exit>
"M-<" : lambda percol: percol.command.select_top(),<\exit>
"M->" : lambda percol: percol.command.select_bottom(),<\exit>
"C-m" : lambda percol: percol.finish(),<\exit>
"C-j" : lambda percol: percol.finish(),<\exit>
"C-g" : lambda percol: percol.cancel(),<\exit>
})<\exit>
import sys<\exit>
import tty<\exit>
import termios<\exit>
import fcntl<\exit>
import os<\exit>
from . import keys<\exit>
def get_symbol():<\exit>
ch = read_char()<\exit>
ch_code = ord(ch)<\exit>
if ch_code == keys.ESC:<\exit>
ch = read_char_no_blocking()<\exit>
if ch == '':<\exit>
return keys.ESC<\exit>
elif ch != 'O' and ch != '[':<\exit>
return ord(ch)<\exit>
else:<\exit>
ch = read_char_no_blocking()<\exit>
if ch == 'A':<\exit>
return keys.UP<\exit>
elif ch == 'B':<\exit>
return keys.DOWN<\exit>
elif ch == 'C':<\exit>
return keys.RIGHT<\exit>
elif ch == 'D':<\exit>
return keys.LEFT<\exit>
elif ch == 'Z':<\exit>
return keys.SHIFTTAB<\exit>
return ch_code<\exit>
def read_char():<\exit>
fd = sys.stdin.fileno()<\exit>
old_settings = termios.tcgetattr(fd)<\exit>
try:<\exit>
tty.setraw(fd, termios.TCSADRAIN)<\exit>
ch = sys.stdin.read(1)<\exit>
finally:<\exit>
termios.tcsetattr(fd, termios.TCSADRAIN, old_settings)<\exit>
return ch<\exit>
def read_char_no_blocking():<\exit>
fd = sys.stdin.fileno()<\exit>
old_settings = termios.tcgetattr(fd)<\exit>
old_flags = fcntl.fcntl(fd, fcntl.F_GETFL)<\exit>
try:<\exit>
tty.setraw(fd, termios.TCSADRAIN)<\exit>
fcntl.fcntl(fd, fcntl.F_SETFL, old_flags | os.O_NONBLOCK)<\exit>
return sys.stdin.read(1)<\exit>
except IOError as e:<\exit>
ErrorNumber = e[0]<\exit>
if (sys.platform.startswith("linux") and ErrorNumber != 11) or (sys.platform == "darwin" and ErrorNumber != 35):<\exit>
raise<\exit>
return ""<\exit>
finally:<\exit>
fcntl.fcntl(fd, fcntl.F_SETFL, old_flags)<\exit>
termios.tcsetattr(fd, termios.TCSADRAIN, old_settings)<\exit>
import linecache<\exit>
import random<\exit>
class ReadFile(object):<\exit>
def __init__(self, pth1, num=None):<\exit>
self.pth1 = pth1<\exit>
self.num = num<\exit>
linecache.clearcache()<\exit>
self.total = int(linecache.getline(pth1, 1))<\exit>
if num == None:<\exit>
self.num = self.total<\exit>
def __get_line_label(self, tmp, rand):<\exit>
if rand:<\exit>
line_label = random.sample(tmp, self.num)<\exit>
else:<\exit>
line_label = tmp[:self.num]<\exit>
return line_label<\exit>
def person_pair(self):<\exit>
person = []<\exit>
tmp = range(2, self.total + 2)<\exit>
if self.num != self.total:<\exit>
line_label = self.__get_line_label(tmp, False)<\exit>
for i in line_label:<\exit>
person.append(self.__extract_flnm(i))<\exit>
else:<\exit>
for i in tmp:<\exit>
person.append(self.__extract_flnm(i))<\exit>
return person<\exit>
def person_mispair(self):<\exit>
person = []<\exit>
tmp = range(self.total + 2, self.total * 2 + 2)<\exit>
if self.num != self.total:<\exit>
line_label = random.sample(tmp, self.num)<\exit>
for i in range(len(line_label)):<\exit>
person.append(self.__extract_flnm(line_label[i]))<\exit>
else:<\exit>
for i in tmp:<\exit>
person.append(self.__extract_flnm(i))<\exit>
return person<\exit>
def __extract_flnm(self, line_label):<\exit>
tmp = linecache.getline(self.pth1, line_label)<\exit>
tmp = tmp.split()<\exit>
suffix = '.txt'<\exit>
if len(tmp) == 3:<\exit>
flag = 1<\exit>
fl_nm1 = tmp[0] + '_' + '0'*(4 - len(tmp[1])) + tmp[1] + suffix<\exit>
fl_nm2 = tmp[0] + '_' + '0'*(4 - len(tmp[2])) + tmp[2] + suffix<\exit>
else:<\exit>
flag = -1<\exit>
fl_nm1 = tmp[0] + '_' + '0'*(4 - len(tmp[1])) + tmp[1] + suffix<\exit>
fl_nm2 = tmp[2] + '_' + '0'*(4 - len(tmp[3])) + tmp[3] + suffix<\exit>
pair_info = [fl_nm1, fl_nm2, flag]<\exit>
return pair_info<\exit>
import sys<\exit>
import os<\exit>
import numpy as np<\exit>
from PIL import Image<\exit>
import re<\exit>
def read_images(path, sz=None):<\exit>
c = 0<\exit>
X, y = [], []<\exit>
for dirname, dirnames, filenames in os.walk(path):<\exit>
for subdirname in dirnames:<\exit>
subject_path = os.path.join(dirname, subdirname)<\exit>
for filename in os.listdir(subject_path):<\exit>
try:<\exit>
if not re.search(r"\.pgm$|\.jpg$", filename):<\exit>
continue<\exit>
if re.search(r"P00_Ambient\.pgm", filename):<\exit>
continue<\exit>
im = Image.open(os.path.join(subject_path, filename))<\exit>
im = im.convert("L")<\exit>
if sz is not None:<\exit>
im = im.resize(sz, Image.ANTIALIAS)<\exit>
X.append(np.asarray(im, dtype=np.uint8))<\exit>
y.append(c)<\exit>
except IOError, (errno, strerror):<\exit>
print "I/O error({0}): {1}".format(errno, strerror)<\exit>
except:<\exit>
print "Unexpected error:", sys.exc_info()[0]<\exit>
raise<\exit>
c += 1<\exit>
return [X, y]<\exit>
import ns.applications<\exit>
import ns.core<\exit>
import ns.csma<\exit>
import ns.internet<\exit>
import ns.network<\exit>
def main(argv):<\exit>
cmd = ns.core.CommandLine()<\exit>
cmd.Parse(argv)<\exit>
ns.core.GlobalValue.Bind("SimulatorImplementationType", ns.core.StringValue("ns3::RealtimeSimulatorImpl"))<\exit>
print "Create nodes."<\exit>
n = ns.network.NodeContainer()<\exit>
n.Create(4)<\exit>
internet = ns.internet.InternetStackHelper()<\exit>
internet.Install(n)<\exit>
print ("Create channels.")<\exit>
csma = ns.csma.CsmaHelper()<\exit>
csma.SetChannelAttribute("DataRate", ns.network.DataRateValue(ns.network.DataRate(5000000)))<\exit>
csma.SetChannelAttribute("Delay", ns.core.TimeValue(ns.core.MilliSeconds(2)));<\exit>
csma.SetDeviceAttribute("Mtu", ns.core.UintegerValue(1400))<\exit>
d = csma.Install(n)<\exit>
print ("Assign IP Addresses.")<\exit>
ipv4 = ns.internet.Ipv4AddressHelper()<\exit>
ipv4.SetBase(ns.network.Ipv4Address("10.1.1.0"), ns.network.Ipv4Mask("255.255.255.0"))<\exit>
i = ipv4.Assign(d)<\exit>
print ("Create Applications.")<\exit>
port = 9<\exit>
server = ns.applications.UdpEchoServerHelper(port)<\exit>
apps = server.Install(n.Get(1))<\exit>
apps.Start(ns.core.Seconds(1.0))<\exit>
apps.Stop(ns.core.Seconds(10.0))<\exit>
packetSize = 1024<\exit>
maxPacketCount = 500<\exit>
interPacketInterval = ns.core.Seconds(0.01)<\exit>
client = ns.applications.UdpEchoClientHelper(i.GetAddress (1), port)<\exit>
client.SetAttribute("MaxPackets", ns.core.UintegerValue(maxPacketCount))<\exit>
client.SetAttribute("Interval", ns.core.TimeValue(interPacketInterval))<\exit>
client.SetAttribute("PacketSize", ns.core.UintegerValue(packetSize))<\exit>
apps = client.Install(n.Get(0))<\exit>
apps.Start(ns.core.Seconds(2.0))<\exit>
apps.Stop(ns.core.Seconds(10.0))<\exit>
ascii = ns.network.AsciiTraceHelper()<\exit>
csma.EnableAsciiAll(ascii.CreateFileStream("realtime-udp-echo.tr"))<\exit>
csma.EnablePcapAll("realtime-udp-echo", False)<\exit>
print ("Run Simulation.")<\exit>
ns.core.Simulator.Run()<\exit>
ns.core.Simulator.Destroy()<\exit>
print ("Done.")<\exit>
if __name__ == '__main__':<\exit>
import sys<\exit>
main(sys.argv)<\exit>
import csv, os, sys<\exit>
try:<\exit>
from PIL import Image<\exit>
except ImportError:<\exit>
import Image<\exit>
import numpy as np<\exit>
from facerec.feature import ChainOperator, Fisherfaces<\exit>
from facerec.preprocessing import Resize<\exit>
from facerec.dataset import NumericDataSet<\exit>
from facerec.distance import EuclideanDistance<\exit>
from facerec.classifier import NearestNeighbor<\exit>
from facerec.model import PredictableModel<\exit>
from facerec.validation import KFoldCrossValidation<\exit>
from facerec.serialization import save_model, load_model<\exit>
class PredictableModelWrapper(object):<\exit>
def __init__(self, model):<\exit>
self.model = model<\exit>
self.numeric_dataset = NumericDataSet()<\exit>
def compute(self):<\exit>
X,y = self.numeric_dataset.get()<\exit>
self.model.compute(X,y)<\exit>
def set_data(self, numeric_dataset):<\exit>
self.numeric_dataset = numeric_dataset<\exit>
def predict(self, image):<\exit>
prediction_result = self.model.predict(image)<\exit>
num_label = prediction_result[0]<\exit>
str_label = self.numeric_dataset.resolve_by_num(num_label)<\exit>
return str_label<\exit>
def update(self, name, image):<\exit>
self.numeric_dataset.add(name, image)<\exit>
class_label = self.numeric_dataset.resolve_by_str(name)<\exit>
extracted_feature = self.feature.extract(image)<\exit>
self.classifier.update(extracted_feature, class_label)<\exit>
def __repr__(self):<\exit>
return "PredictableModelWrapper (Inner Model=%s)" % (str(self.model))<\exit>
def get_model(numeric_dataset, model_filename=None):<\exit>
feature = ChainOperator(Resize((128,128)), Fisherfaces())<\exit>
classifier = NearestNeighbor(dist_metric=EuclideanDistance(), k=1)<\exit>
inner_model = PredictableModel(feature=feature, classifier=classifier)<\exit>
model = PredictableModelWrapper(inner_model)<\exit>
model.set_data(numeric_dataset)<\exit>
model.compute()<\exit>
if not model_filename is None:<\exit>
save_model(model_filename, model)<\exit>
return model<\exit>
def read_images(path, identifier, numeric_dataset):<\exit>
for filename in os.listdir(path):<\exit>
try:<\exit>
img = Image.open(os.path.join(path, filename))<\exit>
img = img.convert("L")<\exit>
img = np.asarray(img, dtype=np.uint8)<\exit>
numeric_dataset.add(identifier, img)<\exit>
except IOError, (errno, strerror):<\exit>
print "I/O error({0}): {1}".format(errno, strerror)<\exit>
except:<\exit>
print "Unexpected error:", sys.exc_info()[0]<\exit>
raise<\exit>
def read_from_csv(filename):<\exit>
numeric_dataset = NumericDataSet()<\exit>
with open(filename, 'rb') as csvfile:<\exit>
reader = csv.reader(csvfile, delimiter=';', quotechar='#')<\exit>
for row in reader:<\exit>
identifier = row[0]<\exit>
path = row[1]<\exit>
read_images(path, identifier, numeric_dataset)<\exit>
return numeric_dataset<\exit>
def get_model_from_csv(filename, out_model_filename):<\exit>
numeric_dataset = read_from_csv(filename)<\exit>
model = get_model(numeric_dataset, out_model_filename)<\exit>
return model<\exit>
def load_model_file(model_filename):<\exit>
load_model(model_filename)<\exit>
import math<\exit>
class Solution(object):<\exit>
def solve(self, cipher):<\exit>
return self.sum_prime(self.get_configs(cipher))<\exit>
def get_configs(self, N):<\exit>
if N < 4:<\exit>
return 1<\exit>
F = [0 for _ in xrange(N + 1)]<\exit>
for i in xrange(1, 4):<\exit>
F[i] = 1<\exit>
F[4] = 2<\exit>
for i in xrange(5, N + 1):<\exit>
F[i] = F[i - 4] + F[i - 1]<\exit>
return F[N]<\exit>
def prime(self, n):<\exit>
is_prime = [1 for _ in xrange(n + 1)]<\exit>
for i in xrange(2):<\exit>
is_prime[i] = 0<\exit>
n_max = int(math.sqrt(len(is_prime)))<\exit>
for i in xrange(2, n_max + 1):<\exit>
for j in xrange(2 * i, len(is_prime), i):<\exit>
is_prime[j] = 0<\exit>
return sum(is_prime)<\exit>
def sum_prime(self, n):<\exit>
import numpy as np<\exit>
is_prime = np.ones((n + 1,), dtype=bool)<\exit>
is_prime[:2] = 0<\exit>
N_max = int(np.sqrt(len(is_prime)))<\exit>
for j in xrange(2, N_max):<\exit>
is_prime[2 * j::j] = False<\exit>
return np.sum(is_prime)<\exit>
if __name__ == "__main__":<\exit>
import sys<\exit>
f = open("1.in", "r")<\exit>
solution = Solution()<\exit>
testcases = int(f.readline().strip())<\exit>
for t in xrange(testcases):<\exit>
cipher = int(f.readline().strip())<\exit>
s = "%s\n" % (solution.solve(cipher))<\exit>
print s,<\exit>
class ListNode(object):<\exit>
def __init__(self, val, next=None):<\exit>
self.val = val<\exit>
self.next = next<\exit>
def __repr__(self):<\exit>
return repr(self.val)<\exit>
class Solution:<\exit>
def rehashing(self, hashTable):<\exit>
cap = len(hashTable)<\exit>
cap *= 2<\exit>
ht = [None for _ in xrange(cap)]<\exit>
for node in hashTable:<\exit>
while node:<\exit>
self.__rehash(ht, ListNode(node.val))<\exit>
node = node.next<\exit>
return ht<\exit>
def __rehash(self, ht, node):<\exit>
code = self.__hashcode(node.val, len(ht))<\exit>
if ht[code] is None:<\exit>
ht[code] = node<\exit>
else:<\exit>
cur = ht[code]<\exit>
while cur.next:<\exit>
cur = cur.next<\exit>
cur.next = node<\exit>
def __hashcode(self, key, capacity):<\exit>
return key%capacity<\exit>
if __name__ == "__main__":<\exit>
hashTable = [None for _ in xrange(3)]<\exit>
n0 = ListNode(29)<\exit>
n1 = ListNode(5)<\exit>
n0.next = n1<\exit>
hashTable[2] = n0<\exit>
print Solution().rehashing(hashTable)<\exit>
import ann_to_xml<\exit>
import info_extraction<\exit>
import os<\exit>
import sys<\exit>
def relation_evaluate(file_path):<\exit>
global tp, fp, fn<\exit>
set_original = ann_to_xml.get_relation_set(file_path+".ann")<\exit>
extract_engine = info_extraction.InfoExtraction()<\exit>
set_extracted = extract_engine.extract_file(file_path+"-tagged.xml", "relation")<\exit>
tp += len(set_original.intersection(set_original, set_extracted))<\exit>
fp += len(set_extracted - set_original)<\exit>
fn += len(set_original - set_extracted)<\exit>
if __name__ == '__main__':<\exit>
if len(sys.argv)==1:<\exit>
print "usage: python relation_evaluate.py [data_folder relative name]"<\exit>
print "example: python relative_evaluate.py non-auto"<\exit>
sys.exit(0)<\exit>
else:<\exit>
folder_name = sys.argv[1]<\exit>
tp = fp = fn = 0<\exit>
current_directory = os.path.dirname(os.path.realpath(__file__))<\exit>
for i in range(1,33):<\exit>
relation_evaluate(os.path.join(current_directory, folder_name, str(i)))<\exit>
print "******summary*********"<\exit>
print "tp: %d\nfp: %d\nfn: %d" % (tp, fp, fn)<\exit>
print "f1: %f" % (float(2*tp)/(2*tp+fp+fn))<\exit>
print "recall: %f" % (float(tp)/(tp+fn))<\exit>
import os<\exit>
from waflib import Build, ConfigSet, Task, Utils, Errors<\exit>
from waflib.TaskGen import feature, before_method, after_method<\exit>
EXTRA_LOCK = '.old_srcdir'<\exit>
old1 = Build.BuildContext.store<\exit>
def store(self):<\exit>
old1(self)<\exit>
db = os.path.join(self.variant_dir, EXTRA_LOCK)<\exit>
env = ConfigSet.ConfigSet()<\exit>
env.SRCDIR = self.srcnode.abspath()<\exit>
env.store(db)<\exit>
Build.BuildContext.store = store<\exit>
old2 = Build.BuildContext.init_dirs<\exit>
def init_dirs(self):<\exit>
if not (os.path.isabs(self.top_dir) and os.path.isabs(self.out_dir)):<\exit>
raise Errors.WafError('The project was not configured: run "waf configure" first!')<\exit>
srcdir = None<\exit>
db = os.path.join(self.variant_dir, EXTRA_LOCK)<\exit>
env = ConfigSet.ConfigSet()<\exit>
try:<\exit>
env.load(db)<\exit>
srcdir = env.SRCDIR<\exit>
except:<\exit>
pass<\exit>
if srcdir:<\exit>
d = self.root.find_node(srcdir)<\exit>
if d and srcdir != self.top_dir and getattr(d, 'children', ''):<\exit>
srcnode = self.root.make_node(self.top_dir)<\exit>
print("relocating the source directory %r -> %r" % (srcdir, self.top_dir))<\exit>
srcnode.children = {}<\exit>
for (k, v) in d.children.items():<\exit>
srcnode.children[k] = v<\exit>
v.parent = srcnode<\exit>
d.children = {}<\exit>
old2(self)<\exit>
Build.BuildContext.init_dirs = init_dirs<\exit>
def uid(self):<\exit>
try:<\exit>
return self.uid_<\exit>
except AttributeError:<\exit>
m = Utils.md5()<\exit>
up = m.update<\exit>
up(self.__class__.__name__.encode())<\exit>
for x in self.inputs + self.outputs:<\exit>
up(x.path_from(x.ctx.srcnode).encode())<\exit>
self.uid_ = m.digest()<\exit>
return self.uid_<\exit>
Task.Task.uid = uid<\exit>
@feature('c', 'cxx', 'd', 'go', 'asm', 'fc', 'includes')<\exit>
@after_method('propagate_uselib_vars', 'process_source')<\exit>
def apply_incpaths(self):<\exit>
lst = self.to_incnodes(self.to_list(getattr(self, 'includes', [])) + self.env['INCLUDES'])<\exit>
self.includes_nodes = lst<\exit>
bld = self.bld<\exit>
self.env['INCPATHS'] = [x.is_child_of(bld.srcnode) and x.path_from(bld.srcnode) or x.abspath() for x in lst]<\exit>
class TreeNode:<\exit>
def __init__(self, val):<\exit>
self.val = val<\exit>
self.left, self.right = None, None<\exit>
class Solution:<\exit>
def removeNode(self, root, value):<\exit>
return self.__removeNode(root, None, value)<\exit>
def __removeNode(self, root, parent, value):<\exit>
if not root:<\exit>
return<\exit>
if root.val > value:<\exit>
self.__removeNode(root.left, root, value)<\exit>
elif root.val < value:<\exit>
self.__removeNode(root.right, root, value)<\exit>
else:<\exit>
if not root.left and not root.right:<\exit>
if parent:<\exit>
if parent.left == root:<\exit>
parent.left = None<\exit>
else:<\exit>
parent.right = None<\exit>
else:<\exit>
root = None<\exit>
elif root.left and not root.right or root.right and not root.left:<\exit>
if root.left:<\exit>
if parent:<\exit>
if parent.left == root:<\exit>
parent.left = root.left<\exit>
else:<\exit>
parent.right = root.left<\exit>
else:<\exit>
root = root.left<\exit>
else:<\exit>
if parent:<\exit>
if parent.left == root:<\exit>
parent.left = root.right<\exit>
else:<\exit>
parent.right = root.right<\exit>
else:<\exit>
root = root.right<\exit>
else:<\exit>
cur = root.left<\exit>
while cur.right:<\exit>
cur = cur.right<\exit>
root.val = cur.val<\exit>
self.__removeNode(root.left, root, cur.val)<\exit>
return root<\exit>
import re<\exit>
import os<\exit>
texts = []<\exit>
directory = os.path.dirname(os.path.realpath(__file__))<\exit>
for root, dirs, files in os.walk(directory):<\exit>
for file in files:<\exit>
if file.endswith(".srt"):<\exit>
f=open(os.path.join(root,file), 'r')<\exit>
texts.append((file,f.read()))<\exit>
f.close()<\exit>
p1 = re.compile(('^\d+$'))<\exit>
p2 = re.compile(('\d\d:\d\d:\d\d'))<\exit>
for videoName, videoTexts in texts:<\exit>
transcripts = ''<\exit>
lines = videoTexts.splitlines()<\exit>
for line in lines:<\exit>
if not (p1.search(line) or p2.search(line) or len(line) < 1):<\exit>
transcripts += (line+'\n')<\exit>
f = open(videoName[:len(videoName)-4]+'_cleaned.txt','w')<\exit>
f.write(transcripts)<\exit>
print(videoName + ' has been cleaned.')<\exit>
f.close()<\exit>
try:<\exit>
from urllib.parse import urlencode<\exit>
except ImportError:<\exit>
from urllib import urlencode<\exit>
from .filepost import encode_multipart_formdata<\exit>
__all__ = ['RequestMethods']<\exit>
class RequestMethods(object):<\exit>
_encode_url_methods = set(['DELETE', 'GET', 'HEAD', 'OPTIONS'])<\exit>
_encode_body_methods = set(['PATCH', 'POST', 'PUT', 'TRACE'])<\exit>
def __init__(self, headers=None):<\exit>
self.headers = headers or {}<\exit>
def urlopen(self, method, url, body=None, headers=None,<\exit>
encode_multipart=True, multipart_boundary=None,<\exit>
**kw):<\exit>
raise NotImplemented("Classes extending RequestMethods must implement "<\exit>
"their own ``urlopen`` method.")<\exit>
def request(self, method, url, fields=None, headers=None, **urlopen_kw):<\exit>
method = method.upper()<\exit>
if method in self._encode_url_methods:<\exit>
return self.request_encode_url(method, url, fields=fields,<\exit>
headers=headers,<\exit>
**urlopen_kw)<\exit>
else:<\exit>
return self.request_encode_body(method, url, fields=fields,<\exit>
headers=headers,<\exit>
**urlopen_kw)<\exit>
def request_encode_url(self, method, url, fields=None, **urlopen_kw):<\exit>
if fields:<\exit>
url += '?' + urlencode(fields)<\exit>
return self.urlopen(method, url, **urlopen_kw)<\exit>
def request_encode_body(self, method, url, fields=None, headers=None,<\exit>
encode_multipart=True, multipart_boundary=None,<\exit>
**urlopen_kw):<\exit>
if encode_multipart:<\exit>
body, content_type = encode_multipart_formdata(fields or {},<\exit>
boundary=multipart_boundary)<\exit>
else:<\exit>
body, content_type = (urlencode(fields or {}),<\exit>
'application/x-www-form-urlencoded')<\exit>
if headers is None:<\exit>
headers = self.headers<\exit>
headers_ = {'Content-Type': content_type}<\exit>
headers_.update(headers)<\exit>
return self.urlopen(method, url, body=body, headers=headers_,<\exit>
**urlopen_kw)<\exit>
from __future__ import with_statement<\exit>
import sys<\exit>
import os<\exit>
import re<\exit>
import codecs<\exit>
try:<\exit>
import xml.etree.ElementTree as ET<\exit>
except ImportError:<\exit>
import cElementTree as ET<\exit>
INSERTED_ELEMENT_TAG = "n2t-spc"<\exit>
INPUT_ENCODING="UTF-8"<\exit>
OUTPUT_ENCODING="UTF-8"<\exit>
options = None<\exit>
newline_wrap_element = set([<\exit>
"CURRENT_TITLE",<\exit>
"CURRENT_AUTHORLIST",<\exit>
"ABSTRACT",<\exit>
"P",<\exit>
"TABLE",<\exit>
"FIGURE",<\exit>
"HEADER",<\exit>
"REFERENCE",<\exit>
"article-title",<\exit>
"abstract",<\exit>
"title",<\exit>
"sec",<\exit>
"p",<\exit>
"contrib",<\exit>
"aff",<\exit>
"pub-date",<\exit>
"copyright-statement",<\exit>
"table",<\exit>
"table-wrap",<\exit>
"figure",<\exit>
"fig",<\exit>
"tr",<\exit>
"kwd-group",<\exit>
])<\exit>
space_wrap_element = set([<\exit>
"AUTHOR",<\exit>
"SURNAME",<\exit>
"CURRENT_AUTHOR",<\exit>
"CURRENT_SURNAME",<\exit>
"TITLE",<\exit>
"JOURNAL",<\exit>
"YEAR",<\exit>
"surname",<\exit>
"given-names",<\exit>
"email",<\exit>
"volume",<\exit>
"issue",<\exit>
"year",<\exit>
"month",<\exit>
"day",<\exit>
"fpage",<\exit>
"lpage",<\exit>
"pub-id",<\exit>
"copyright-year",<\exit>
"journal-id",<\exit>
"journal-title",<\exit>
"issn",<\exit>
"publisher-name",<\exit>
"article-id",<\exit>
"kwd",<\exit>
"label",<\exit>
"th",<\exit>
"td",<\exit>
])<\exit>
strip_element = newline_wrap_element | space_wrap_element<\exit>
class Standoff:<\exit>
def __init__(self, element, start, end):<\exit>
self.element = element<\exit>
self.start   = start<\exit>
self.end     = end<\exit>
def txt(s):<\exit>
return s if s is not None else ""<\exit>
def text_and_standoffs(e):<\exit>
strings, standoffs = [], []<\exit>
_text_and_standoffs(e, 0, strings, standoffs)<\exit>
text = "".join(strings)<\exit>
return text, standoffs<\exit>
def _text_and_standoffs(e, curroff, strings, standoffs):<\exit>
startoff = curroff<\exit>
so = Standoff(e, 0, 0)<\exit>
standoffs.append(so)<\exit>
if e.text is not None and e.text != "":<\exit>
strings.append(e.text)<\exit>
curroff += len(e.text)<\exit>
curroff = _subelem_text_and_standoffs(e, curroff, strings, standoffs)<\exit>
so.start = startoff<\exit>
so.end   = curroff<\exit>
return curroff<\exit>
def _subelem_text_and_standoffs(e, curroff, strings, standoffs):<\exit>
startoff = curroff<\exit>
for s in e:<\exit>
curroff = _text_and_standoffs(s, curroff, strings, standoffs)<\exit>
if s.tail is not None and s.tail != "":<\exit>
strings.append(s.tail)<\exit>
curroff += len(s.tail)<\exit>
return curroff<\exit>
def preceding_space(pos, text, rewritten={}):<\exit>
while pos > 0:<\exit>
pos -= 1<\exit>
if pos not in rewritten:<\exit>
return text[pos].isspace()<\exit>
elif rewritten[pos] is not None:<\exit>
return rewritten[pos].isspace()<\exit>
else:<\exit>
pass<\exit>
return True<\exit>
def following_space(pos, text, rewritten={}):<\exit>
while pos < len(text):<\exit>
if pos not in rewritten:<\exit>
return text[pos].isspace()<\exit>
elif rewritten[pos] is not None:<\exit>
return rewritten[pos].isspace()<\exit>
else:<\exit>
pass<\exit>
pos += 1<\exit>
return True<\exit>
def preceding_linebreak(pos, text, rewritten={}):<\exit>
if pos >= len(text):<\exit>
return True<\exit>
while pos > 0:<\exit>
pos -= 1<\exit>
c = rewritten.get(pos, text[pos])<\exit>
if c == "\n":<\exit>
return True<\exit>
elif c is not None and not c.isspace():<\exit>
return False<\exit>
else:<\exit>
pass<\exit>
return True<\exit>
def following_linebreak(pos, text, rewritten={}):<\exit>
while pos < len(text):<\exit>
c = rewritten.get(pos, text[pos])<\exit>
if c == "\n":<\exit>
return True<\exit>
elif c is not None and not c.isspace():<\exit>
return False<\exit>
else:<\exit>
pass<\exit>
pos += 1<\exit>
return True<\exit>
def index_in_parent(e, p):<\exit>
index = None<\exit>
for i in range(len(p)):<\exit>
if p[i] == e:<\exit>
index = i<\exit>
break<\exit>
assert i is not None, "index_in_parent: error: not parent and child"<\exit>
return i<\exit>
def space_normalize(root, text=None, standoffs=None):<\exit>
if text is None or standoffs is None:<\exit>
text, standoffs = text_and_standoffs(root)<\exit>
for so in standoffs:<\exit>
e = so.element<\exit>
if e.text is not None and e.text != "":<\exit>
e.text = re.sub(r'\s+', ' ', e.text)<\exit>
if e.tail is not None and e.tail != "":<\exit>
e.tail = re.sub(r'\s+', ' ', e.tail)<\exit>
def strip_elements(root, elements_to_strip=set(), text=None, standoffs=None):<\exit>
if text is None or standoffs is None:<\exit>
text, standoffs = text_and_standoffs(root)<\exit>
rewritten = {}<\exit>
for so in standoffs:<\exit>
e = so.element<\exit>
if e.tag == INSERTED_ELEMENT_TAG:<\exit>
continue<\exit>
if ((e.text is not None and e.text != "" and e.text[0].isspace()) and<\exit>
(element_in_set(e, elements_to_strip) or<\exit>
preceding_space(so.start, text, rewritten))):<\exit>
l = 0<\exit>
while l < len(e.text) and e.text[l].isspace():<\exit>
l += 1<\exit>
space, end = e.text[:l], e.text[l:]<\exit>
for i in range(l):<\exit>
assert so.start+i not in rewritten, "ERROR: dup remove at %d"  % (so.start+i)<\exit>
rewritten[so.start+i] = None<\exit>
e.text = end<\exit>
if len(e) == 0:<\exit>
if ((e.text is not None and e.text != "" and e.text[-1].isspace()) and<\exit>
(element_in_set(e, elements_to_strip) or<\exit>
following_space(so.end, text, rewritten))):<\exit>
l = 0<\exit>
while l < len(e.text) and e.text[-l-1].isspace():<\exit>
l += 1<\exit>
start, space = e.text[:-l], e.text[-l:]<\exit>
for i in range(l):<\exit>
o = so.end-i-1<\exit>
assert o not in rewritten, "ERROR: dup remove"<\exit>
rewritten[o] = None<\exit>
e.text = start<\exit>
else:<\exit>
c = e[-1]<\exit>
if ((c.tail is not None and c.tail != "" and c.tail[-1].isspace()) and<\exit>
(element_in_set(e, elements_to_strip) or<\exit>
following_space(so.end, text, rewritten))):<\exit>
l = 0<\exit>
while l < len(c.tail) and c.tail[-l-1].isspace():<\exit>
l += 1<\exit>
start, space = c.tail[:-l], c.tail[-l:]<\exit>
for i in range(l):<\exit>
o = so.end-i-1<\exit>
assert o not in rewritten, "ERROR: dup remove"<\exit>
rewritten[o] = None<\exit>
c.tail = start<\exit>
def trim_tails(root):<\exit>
text, standoffs = text_and_standoffs(root)<\exit>
for so in standoffs:<\exit>
e = so.element<\exit>
if (e.tail is not None and e.tail != "" and e.tail[0].isspace() and<\exit>
preceding_space(so.end, text)):<\exit>
l = 0<\exit>
while l < len(e.tail) and e.tail[l].isspace():<\exit>
l += 1<\exit>
space, end = e.tail[:l], e.tail[l:]<\exit>
e.tail = end<\exit>
def reduce_space(root, elements_to_strip=set()):<\exit>
text, standoffs = text_and_standoffs(root)<\exit>
strip_elements(root, elements_to_strip, text, standoffs)<\exit>
trim_tails(root)<\exit>
space_normalize(root, text, standoffs)<\exit>
def element_in_set(e, s):<\exit>
if e.tag[0] == "{":<\exit>
tag = re.sub(r'\{.*?\}', '', e.tag)<\exit>
else:<\exit>
tag = e.tag<\exit>
return tag in s<\exit>
def process(fn):<\exit>
global strip_element<\exit>
global options<\exit>
if fn == "-":<\exit>
fn = "/dev/stdin"<\exit>
try:<\exit>
tree = ET.parse(fn)<\exit>
except:<\exit>
print >> sys.stderr, "Error parsing %s" % fn<\exit>
raise<\exit>
root = tree.getroot()<\exit>
reduce_space(root, strip_element)<\exit>
text, standoffs = text_and_standoffs(root)<\exit>
respace = {}<\exit>
for so in standoffs:<\exit>
e = so.element<\exit>
if element_in_set(e, newline_wrap_element):<\exit>
if not (so.start in respace and (respace[so.start][0] == "\n" and<\exit>
respace[so.start][1] == False)):<\exit>
respace[so.start] = ("\n", True)<\exit>
respace[so.end] = ("\n", False)<\exit>
elif element_in_set(e, space_wrap_element):<\exit>
if not (so.start in respace and (respace[so.start][0] == "\n" or<\exit>
respace[so.start][1] == False)):<\exit>
respace[so.start] = (" ", True)<\exit>
if not (so.end in respace and respace[so.end][0] == "\n"):<\exit>
respace[so.end] = (" ", False)<\exit>
rewritten = {}<\exit>
filtered = {}<\exit>
for pos in sorted(respace.keys()):<\exit>
if respace[pos][0] == " ":<\exit>
if not (preceding_space(pos, text, rewritten) or<\exit>
following_space(pos, text, rewritten)):<\exit>
filtered[pos] = respace[pos]<\exit>
rewritten[pos-1] = " "<\exit>
else:<\exit>
assert respace[pos][0] == "\n", "INTERNAL ERROR"<\exit>
if not (preceding_linebreak(pos, text, rewritten) or<\exit>
following_linebreak(pos, text, rewritten)):<\exit>
filtered[pos] = respace[pos]<\exit>
rewritten[pos-1] = "\n"<\exit>
respace = filtered<\exit>
parent_map = {}<\exit>
for parent in root.getiterator():<\exit>
for child in parent:<\exit>
parent_map[child] = parent<\exit>
end_map = {}<\exit>
for so in standoffs:<\exit>
if so.end not in end_map:<\exit>
end_map[so.end] = []<\exit>
end_map[so.end].append(so)<\exit>
for so in standoffs:<\exit>
if so.start in respace and respace[so.start][1] == True:<\exit>
e = so.element<\exit>
assert e in parent_map, "INTERNAL ERROR: add space before root?"<\exit>
p = parent_map[e]<\exit>
i = index_in_parent(e, p)<\exit>
rse = ET.Element(INSERTED_ELEMENT_TAG)<\exit>
rse.text = respace[so.start][0]<\exit>
p.insert(i, rse)<\exit>
del respace[so.start]<\exit>
if so.end in respace and respace[so.end][1] == False:<\exit>
maxlen = max([s.end-s.start for s in end_map[so.end]])<\exit>
if so.end-so.start != maxlen:<\exit>
continue<\exit>
longest = [s for s in end_map[so.end] if s.end-s.start == maxlen]<\exit>
if so != longest[0]:<\exit>
continue<\exit>
e = so.element<\exit>
assert e in parent_map, "INTERNAL ERROR: add space after root?"<\exit>
p = parent_map[e]<\exit>
i = index_in_parent(e, p)<\exit>
rse = ET.Element(INSERTED_ELEMENT_TAG)<\exit>
rse.text = respace[so.end][0]<\exit>
p.insert(i+1, rse)<\exit>
rse.tail = e.tail<\exit>
e.tail = ""<\exit>
del respace[so.end]<\exit>
assert len(respace) == 0, "INTERNAL ERROR: failed to insert %s" % str(respace)<\exit>
strip_elements(root)<\exit>
trim_tails(root)<\exit>
if options.stdout:<\exit>
tree.write(sys.stdout, encoding=OUTPUT_ENCODING)<\exit>
return True<\exit>
if options is not None and options.directory is not None:<\exit>
output_dir = options.directory<\exit>
else:<\exit>
output_dir = ""<\exit>
output_fn = os.path.join(output_dir, os.path.basename(fn))<\exit>
if output_fn == fn and not options.overwrite:<\exit>
print >> sys.stderr, 'respace: skipping output for %s: file would overwrite input (consider -d and -o options)' % fn<\exit>
else:<\exit>
try:<\exit>
with open(output_fn, 'w') as of:<\exit>
tree.write(of, encoding=OUTPUT_ENCODING)<\exit>
except IOError, ex:<\exit>
print >> sys.stderr, 'respace: failed write: %s' % ex<\exit>
return True<\exit>
def argparser():<\exit>
import argparse<\exit>
ap=argparse.ArgumentParser(description='Revise whitespace content of a PMC NXML file for text extraction.')<\exit>
ap.add_argument('-d', '--directory', default=None, metavar='DIR', help='output directory')<\exit>
ap.add_argument('-o', '--overwrite', default=False, action='store_true', help='allow output to overwrite input files')<\exit>
ap.add_argument('-s', '--stdout', default=False, action='store_true', help='output to stdout')<\exit>
ap.add_argument('file', nargs='+', help='input PubMed Central NXML file')<\exit>
return ap<\exit>
def main(argv):<\exit>
global options<\exit>
options = argparser().parse_args(argv[1:])<\exit>
for fn in options.file:<\exit>
process(fn)<\exit>
return 0<\exit>
if __name__ == "__main__":<\exit>
sys.exit(main(sys.argv))<\exit>
import gzip<\exit>
import logging<\exit>
import zlib<\exit>
from io import BytesIO<\exit>
from .exceptions import DecodeError<\exit>
from .packages.six import string_types as basestring<\exit>
log = logging.getLogger(__name__)<\exit>
def decode_gzip(data):<\exit>
gzipper = gzip.GzipFile(fileobj=BytesIO(data))<\exit>
return gzipper.read()<\exit>
def decode_deflate(data):<\exit>
try:<\exit>
return zlib.decompress(data)<\exit>
except zlib.error:<\exit>
return zlib.decompress(data, -zlib.MAX_WBITS)<\exit>
class HTTPResponse(object):<\exit>
CONTENT_DECODERS = {<\exit>
'gzip': decode_gzip,<\exit>
'deflate': decode_deflate,<\exit>
}<\exit>
def __init__(self, body='', headers=None, status=0, version=0, reason=None,<\exit>
strict=0, preload_content=True, decode_content=True,<\exit>
original_response=None, pool=None, connection=None):<\exit>
self.headers = headers or {}<\exit>
self.status = status<\exit>
self.version = version<\exit>
self.reason = reason<\exit>
self.strict = strict<\exit>
self._decode_content = decode_content<\exit>
self._body = body if body and isinstance(body, basestring) else None<\exit>
self._fp = None<\exit>
self._original_response = original_response<\exit>
self._pool = pool<\exit>
self._connection = connection<\exit>
if hasattr(body, 'read'):<\exit>
self._fp = body<\exit>
if preload_content and not self._body:<\exit>
self._body = self.read(decode_content=decode_content)<\exit>
def get_redirect_location(self):<\exit>
if self.status in [301, 302, 303, 307]:<\exit>
return self.headers.get('location')<\exit>
return False<\exit>
def release_conn(self):<\exit>
if not self._pool or not self._connection:<\exit>
return<\exit>
self._pool._put_conn(self._connection)<\exit>
self._connection = None<\exit>
@property<\exit>
def data(self):<\exit>
if self._body:<\exit>
return self._body<\exit>
if self._fp:<\exit>
return self.read(cache_content=True)<\exit>
def read(self, amt=None, decode_content=None, cache_content=False):<\exit>
content_encoding = self.headers.get('content-encoding', '').lower()<\exit>
decoder = self.CONTENT_DECODERS.get(content_encoding)<\exit>
if decode_content is None:<\exit>
decode_content = self._decode_content<\exit>
if self._fp is None:<\exit>
return<\exit>
try:<\exit>
if amt is None:<\exit>
data = self._fp.read()<\exit>
else:<\exit>
return self._fp.read(amt)<\exit>
try:<\exit>
if decode_content and decoder:<\exit>
data = decoder(data)<\exit>
except (IOError, zlib.error):<\exit>
raise DecodeError("Received response with content-encoding: %s, but "<\exit>
"failed to decode it." % content_encoding)<\exit>
if cache_content:<\exit>
self._body = data<\exit>
return data<\exit>
finally:<\exit>
if self._original_response and self._original_response.isclosed():<\exit>
self.release_conn()<\exit>
@classmethod<\exit>
def from_httplib(ResponseCls, r, **response_kw):<\exit>
headers = {}<\exit>
for k, v in r.getheaders():<\exit>
k = k.lower()<\exit>
has_value = headers.get(k)<\exit>
if has_value:<\exit>
v = ', '.join([has_value, v])<\exit>
headers[k] = v<\exit>
strict = getattr(r, 'strict', 0)<\exit>
return ResponseCls(body=r,<\exit>
headers=headers,<\exit>
status=r.status,<\exit>
version=r.version,<\exit>
reason=r.reason,<\exit>
strict=strict,<\exit>
original_response=r,<\exit>
**response_kw)<\exit>
def getheaders(self):<\exit>
return self.headers<\exit>
def getheader(self, name, default=None):<\exit>
return self.headers.get(name, default)<\exit>
class Solution(object):<\exit>
def solve(self, cipher):<\exit>
l, b = cipher<\exit>
r = self.gcd(l, b)<\exit>
return (l * b) / (r * r)<\exit>
def gcd(self, a, b):<\exit>
while b:<\exit>
a, b = b, a % b<\exit>
return a<\exit>
if __name__ == "__main__":<\exit>
import sys<\exit>
f = open("1.in", "r")<\exit>
testcases = int(f.readline().strip())<\exit>
for t in xrange(testcases):<\exit>
cipher = map(int, f.readline().strip().split(' '))<\exit>
s = "%s\n" % (Solution().solve(cipher))<\exit>
print s,<\exit>
class Solution(object):<\exit>
def solve(self, cipher):<\exit>
N, K = cipher<\exit>
if K < N / 2:<\exit>
return 2 * K + 1<\exit>
else:<\exit>
return 2 * (N - 1 - K)<\exit>
if __name__ == "__main__":<\exit>
import sys<\exit>
f = open("1.in", "r")<\exit>
testcases = int(f.readline().strip())<\exit>
for t in xrange(testcases):<\exit>
cipher = map(int, f.readline().strip().split(' '))<\exit>
s = "%s\n" % (Solution().solve(cipher))<\exit>
print s,<\exit>
class ListNode:<\exit>
def __init__(self, x):<\exit>
self.val = x<\exit>
self.next = None<\exit>
class Solution:<\exit>
def rotateRight(self, head, k):<\exit>
if not head:<\exit>
return head<\exit>
dummy = ListNode(0)<\exit>
dummy.next = head<\exit>
l = self.get_len(head)<\exit>
k %= l<\exit>
pre = dummy<\exit>
i = 0<\exit>
while pre and i < l-k:<\exit>
pre = pre.next<\exit>
i += 1<\exit>
new_head = pre.next<\exit>
if not new_head:<\exit>
return dummy.next<\exit>
cur = new_head<\exit>
pre.next = None<\exit>
while cur.next:<\exit>
cur = cur.next<\exit>
cur.next = dummy.next<\exit>
dummy.next = new_head<\exit>
return dummy.next<\exit>
def get_len(self, head):<\exit>
l = 0<\exit>
cur = head<\exit>
while cur:<\exit>
l += 1<\exit>
cur = cur.next<\exit>
return l<\exit>
class DirectedGraphNode:<\exit>
def __init__(self, x):<\exit>
self.label = x<\exit>
self.neighbors = []<\exit>
class Solution(object):<\exit>
def hasRoute(self, graph, s, t):<\exit>
visited = set()<\exit>
return self.dfs(s, t, visited)<\exit>
def dfs(self, s, t, visited):<\exit>
if s == t:<\exit>
return True<\exit>
visited.add(s)<\exit>
for nbr in s.neighbors:<\exit>
if nbr not in visited:<\exit>
if self.dfs(nbr, t, visited):<\exit>
return True<\exit>
return False<\exit>
MOD = 1e9 + 7<\exit>
class Solution(object):<\exit>
def solve_TLE(self, cipher):<\exit>
A = map(int, list(cipher))<\exit>
f = A[0]<\exit>
num = A[0]<\exit>
sig = 1<\exit>
for i in xrange(1, len(A)):<\exit>
num = 10 * num + A[i]<\exit>
sig *= 10<\exit>
temp = num<\exit>
temp_sig = sig<\exit>
while temp_sig >= 1:<\exit>
f += temp<\exit>
f %= MOD<\exit>
temp %= temp_sig<\exit>
temp_sig /= 10<\exit>
return int(f)<\exit>
def solve(self, cipher):<\exit>
pre = [0 for _ in cipher]<\exit>
pre[0] = int(cipher[0])<\exit>
for i in xrange(1, len(cipher)):<\exit>
pre[i] = (pre[i - 1] * 10 + int(cipher[i]) * (i + 1)) % MOD<\exit>
s = 0<\exit>
for elt in pre:<\exit>
s = (s + elt) % MOD<\exit>
return int(s)<\exit>
if __name__ == "__main__":<\exit>
import sys<\exit>
f = open("0.in", "r")<\exit>
solution = Solution()<\exit>
cipher = f.readline().strip()<\exit>
s = "%s\n" % (solution.solve(cipher))<\exit>
print s,<\exit>
import numpy as np<\exit>
import matplotlib.pyplot as plt<\exit>
import ns.core<\exit>
rng = ns.core.NormalVariable(100.0, 225.0)<\exit>
x = [rng.GetValue() for t in range(10000)]<\exit>
n, bins, patches = plt.hist(x, 50, normed=1, facecolor='g', alpha=0.75)<\exit>
plt.title('ns-3 histogram')<\exit>
plt.text(60, .025, r'$\mu=100,\ \sigma=15$')<\exit>
plt.axis([40, 160, 0, 0.03])<\exit>
plt.grid(True)<\exit>
plt.show()<\exit>
import ns.core<\exit>
class MyModel(object):<\exit>
def Start(self):<\exit>
ns.core.Simulator.Schedule(ns.core.Seconds(10.0), self.HandleEvent, ns.core.Simulator.Now().GetSeconds())<\exit>
def HandleEvent(self, value):<\exit>
print "Member method received event at", ns.core.Simulator.Now().GetSeconds(), \<\exit>
"s started at", value, "s"<\exit>
def ExampleFunction(model):<\exit>
print "ExampleFunction received event at", ns.core.Simulator.Now().GetSeconds(), "s"<\exit>
model.Start()<\exit>
def RandomFunction(model):<\exit>
print "RandomFunction received event at", ns.core.Simulator.Now().GetSeconds(), "s"<\exit>
def CancelledEvent():<\exit>
print "I should never be called... "<\exit>
def main(dummy_argv):<\exit>
model = MyModel()<\exit>
v = ns.core.UniformVariable(10,20)<\exit>
ns.core.Simulator.Schedule(ns.core.Seconds(10.0), ExampleFunction, model)<\exit>
ns.core.Simulator.Schedule(ns.core.Seconds(v.GetValue()), RandomFunction, model)<\exit>
id = ns.core.Simulator.Schedule(ns.core.Seconds(30.0), CancelledEvent)<\exit>
ns.core.Simulator.Cancel(id)<\exit>
ns.core.Simulator.Run()<\exit>
ns.core.Simulator.Destroy()<\exit>
if __name__ == '__main__':<\exit>
import sys<\exit>
main(sys.argv)<\exit>
class Solution(object):<\exit>
def solve(self, cipher):<\exit>
N, A = cipher<\exit>
ret = 0<\exit>
for i, val in enumerate(A):<\exit>
if (i + 1) * (N - i) % 2 == 1:<\exit>
ret ^= val<\exit>
return ret<\exit>
if __name__ == "__main__":<\exit>
import sys<\exit>
f = open("1.in", "r")<\exit>
solution = Solution()<\exit>
testcases = int(f.readline().strip())<\exit>
for t in xrange(testcases):<\exit>
N = int(f.readline().strip())<\exit>
A = map(int, f.readline().strip().split(' '))<\exit>
cipher = N, A<\exit>
s = "%s\n" % (solution.solve(cipher))<\exit>
print s,<\exit>
import sys<\exit>
from . import constants<\exit>
from .charsetprober import CharSetProber<\exit>
from .compat import wrap_ord<\exit>
SAMPLE_SIZE = 64<\exit>
SB_ENOUGH_REL_THRESHOLD = 1024<\exit>
POSITIVE_SHORTCUT_THRESHOLD = 0.95<\exit>
NEGATIVE_SHORTCUT_THRESHOLD = 0.05<\exit>
SYMBOL_CAT_ORDER = 250<\exit>
NUMBER_OF_SEQ_CAT = 4<\exit>
POSITIVE_CAT = NUMBER_OF_SEQ_CAT - 1<\exit>
class SingleByteCharSetProber(CharSetProber):<\exit>
def __init__(self, model, reversed=False, nameProber=None):<\exit>
CharSetProber.__init__(self)<\exit>
self._mModel = model<\exit>
self._mReversed = reversed<\exit>
self._mNameProber = nameProber<\exit>
self.reset()<\exit>
def reset(self):<\exit>
CharSetProber.reset(self)<\exit>
self._mLastOrder = 255<\exit>
self._mSeqCounters = [0] * NUMBER_OF_SEQ_CAT<\exit>
self._mTotalSeqs = 0<\exit>
self._mTotalChar = 0<\exit>
self._mFreqChar = 0<\exit>
def get_charset_name(self):<\exit>
if self._mNameProber:<\exit>
return self._mNameProber.get_charset_name()<\exit>
else:<\exit>
return self._mModel['charsetName']<\exit>
def feed(self, aBuf):<\exit>
if not self._mModel['keepEnglishLetter']:<\exit>
aBuf = self.filter_without_english_letters(aBuf)<\exit>
aLen = len(aBuf)<\exit>
if not aLen:<\exit>
return self.get_state()<\exit>
for c in aBuf:<\exit>
order = self._mModel['charToOrderMap'][wrap_ord(c)]<\exit>
if order < SYMBOL_CAT_ORDER:<\exit>
self._mTotalChar += 1<\exit>
if order < SAMPLE_SIZE:<\exit>
self._mFreqChar += 1<\exit>
if self._mLastOrder < SAMPLE_SIZE:<\exit>
self._mTotalSeqs += 1<\exit>
if not self._mReversed:<\exit>
i = (self._mLastOrder * SAMPLE_SIZE) + order<\exit>
model = self._mModel['precedenceMatrix'][i]<\exit>
else:<\exit>
i = (order * SAMPLE_SIZE) + self._mLastOrder<\exit>
model = self._mModel['precedenceMatrix'][i]<\exit>
self._mSeqCounters[model] += 1<\exit>
self._mLastOrder = order<\exit>
if self.get_state() == constants.eDetecting:<\exit>
if self._mTotalSeqs > SB_ENOUGH_REL_THRESHOLD:<\exit>
cf = self.get_confidence()<\exit>
if cf > POSITIVE_SHORTCUT_THRESHOLD:<\exit>
if constants._debug:<\exit>
sys.stderr.write('%s confidence = %s, we have a'<\exit>
'winner\n' %<\exit>
(self._mModel['charsetName'], cf))<\exit>
self._mState = constants.eFoundIt<\exit>
elif cf < NEGATIVE_SHORTCUT_THRESHOLD:<\exit>
if constants._debug:<\exit>
sys.stderr.write('%s confidence = %s, below negative'<\exit>
'shortcut threshhold %s\n' %<\exit>
(self._mModel['charsetName'], cf,<\exit>
NEGATIVE_SHORTCUT_THRESHOLD))<\exit>
self._mState = constants.eNotMe<\exit>
return self.get_state()<\exit>
def get_confidence(self):<\exit>
r = 0.01<\exit>
if self._mTotalSeqs > 0:<\exit>
r = ((1.0 * self._mSeqCounters[POSITIVE_CAT]) / self._mTotalSeqs<\exit>
/ self._mModel['mTypicalPositiveRatio'])<\exit>
r = r * self._mFreqChar / self._mTotalChar<\exit>
if r >= 1.0:<\exit>
r = 0.99<\exit>
return r<\exit>
from .charsetgroupprober import CharSetGroupProber<\exit>
from .sbcharsetprober import SingleByteCharSetProber<\exit>
from .langcyrillicmodel import (Win1251CyrillicModel, Koi8rModel,<\exit>
Latin5CyrillicModel, MacCyrillicModel,<\exit>
Ibm866Model, Ibm855Model)<\exit>
from .langgreekmodel import Latin7GreekModel, Win1253GreekModel<\exit>
from .langbulgarianmodel import Latin5BulgarianModel, Win1251BulgarianModel<\exit>
from .langhungarianmodel import Latin2HungarianModel, Win1250HungarianModel<\exit>
from .langthaimodel import TIS620ThaiModel<\exit>
from .langhebrewmodel import Win1255HebrewModel<\exit>
from .hebrewprober import HebrewProber<\exit>
class SBCSGroupProber(CharSetGroupProber):<\exit>
def __init__(self):<\exit>
CharSetGroupProber.__init__(self)<\exit>
self._mProbers = [<\exit>
SingleByteCharSetProber(Win1251CyrillicModel),<\exit>
SingleByteCharSetProber(Koi8rModel),<\exit>
SingleByteCharSetProber(Latin5CyrillicModel),<\exit>
SingleByteCharSetProber(MacCyrillicModel),<\exit>
SingleByteCharSetProber(Ibm866Model),<\exit>
SingleByteCharSetProber(Ibm855Model),<\exit>
SingleByteCharSetProber(Latin7GreekModel),<\exit>
SingleByteCharSetProber(Win1253GreekModel),<\exit>
SingleByteCharSetProber(Latin5BulgarianModel),<\exit>
SingleByteCharSetProber(Win1251BulgarianModel),<\exit>
SingleByteCharSetProber(Latin2HungarianModel),<\exit>
SingleByteCharSetProber(Win1250HungarianModel),<\exit>
SingleByteCharSetProber(TIS620ThaiModel),<\exit>
]<\exit>
hebrewProber = HebrewProber()<\exit>
logicalHebrewProber = SingleByteCharSetProber(Win1255HebrewModel,<\exit>
False, hebrewProber)<\exit>
visualHebrewProber = SingleByteCharSetProber(Win1255HebrewModel, True,<\exit>
hebrewProber)<\exit>
hebrewProber.set_model_probers(logicalHebrewProber, visualHebrewProber)<\exit>
self._mProbers.extend([hebrewProber, logicalHebrewProber,<\exit>
visualHebrewProber])<\exit>
self.reset()<\exit>
from collections import defaultdict<\exit>
class Val(object):<\exit>
def __init__(self):<\exit>
self.cnt = 0<\exit>
self.start = 0<\exit>
class TaskScheduleSolution(object):<\exit>
def solve(self, A, intvl):<\exit>
m = defaultdict(Val)<\exit>
for e in A:<\exit>
m[e].cnt += 1<\exit>
t = 0<\exit>
for _ in A:<\exit>
maxa = None<\exit>
for k, v in m.items():<\exit>
if not maxa or m[maxa].cnt <= v.cnt:<\exit>
if m[maxa].cnt == v.cnt and m[maxa].start > v.start:<\exit>
maxa = k<\exit>
elif m[maxa].cnt < v.cnt:<\exit>
maxa = k<\exit>
t = max(t, m[maxa].start)+1<\exit>
m[maxa].cnt -= 1<\exit>
if m[maxa] <= 0:<\exit>
del m[maxa]<\exit>
m[maxa].start = t+intvl<\exit>
return t<\exit>
if __name__ == "__main__":<\exit>
assert TaskScheduleSolution().solve([1, 1, 2, 1], 2) == 7<\exit>
assert TaskScheduleSolution().solve([1, 2, 3, 1, 2, 3], 3) == 7<\exit>
class TreeNode:<\exit>
def __init__(self, val):<\exit>
self.val = val<\exit>
self.left, self.right = None, None<\exit>
class Solution(object):<\exit>
def searchRange(self, root, k1, k2):<\exit>
ret = []<\exit>
self.dfs(root, k1, k2, ret)<\exit>
return ret<\exit>
def dfs(self, root, k1, k2, ret):<\exit>
if not root:<\exit>
return<\exit>
if root.val < k1:<\exit>
self.dfs(root.right, k1, k2, ret)<\exit>
elif root.val > k2:<\exit>
self.dfs(root.left, k1, k2, ret)<\exit>
else:<\exit>
self.dfs(root.left, k1, k2, ret)<\exit>
ret.append(root.val)<\exit>
self.dfs(root.right, k1, k2, ret)<\exit>
class SegmentTreeNode:<\exit>
def __init__(self, start, end):<\exit>
self.start, self.end = start, end<\exit>
self.left, self.right = None, None<\exit>
class Solution:<\exit>
def build(self, start, end):<\exit>
if start > end:<\exit>
return None<\exit>
root = SegmentTreeNode(start, end)<\exit>
if start == end:<\exit>
return root<\exit>
root.left = self.build(start, (start+end)/2)<\exit>
root.right = self.build((start+end)/2+1, end)<\exit>
return root<\exit>
class SegmentTreeNode:<\exit>
def __init__(self, start, end, max):<\exit>
self.start, self.end, self.max = start, end, max<\exit>
self.left, self.right = None, None<\exit>
class Solution:<\exit>
def modify(self, root, index, value):<\exit>
if root is None:<\exit>
return<\exit>
if index < root.start or index > root.end:<\exit>
return<\exit>
if root.start == index and root.end == index:<\exit>
root.max = value<\exit>
return<\exit>
self.modify(root.left, index, value)<\exit>
self.modify(root.right, index, value)<\exit>
m = value<\exit>
if root.left:<\exit>
m = max(m, root.left.max)<\exit>
if root.right:<\exit>
m = max(m, root.right.max)<\exit>
root.max = m<\exit>
DEFAULT = 0<\exit>
f = lambda x, y: x+y<\exit>
class Solution:<\exit>
def query(self, root, s, e):<\exit>
if not root:<\exit>
return DEFAULT<\exit>
if s <= root.start and e >= root.end:<\exit>
return root.count<\exit>
if s > root.end or e < root.start:<\exit>
return DEFAULT<\exit>
l = self.query(root.left, s, e)<\exit>
r = self.query(root.right, s, e)<\exit>
return f(l, r)<\exit>
import sys<\exit>
class SegmentTreeNode:<\exit>
def __init__(self, start, end, max):<\exit>
self.start, self.end, self.max = start, end, max<\exit>
self.left, self.right = None, None<\exit>
class Solution:<\exit>
def query(self, root, start, end):<\exit>
if start <= root.start and end >= root.end:<\exit>
return root.max<\exit>
if start > end:<\exit>
return -sys.maxint-1<\exit>
maxa = -sys.maxint-1<\exit>
if root.left:<\exit>
left = self.query(root.left, start, end)<\exit>
maxa = max(maxa, left)<\exit>
if root.right:<\exit>
right = self.query(root.right, start, end)<\exit>
maxa = max(maxa, right)<\exit>
return maxa<\exit>
class Node(object):<\exit>
def __init__(self, lo, hi, cnt):<\exit>
self.lo = lo<\exit>
self.hi = hi<\exit>
self.cnt = cnt<\exit>
self.left = None<\exit>
self.right = None<\exit>
def __repr__(self):<\exit>
return repr("[%d,%d)" % (self.lo, self.hi))<\exit>
class SegmentTree(object):<\exit>
def __init__(self):<\exit>
self.root = None<\exit>
def build(self, lo, hi):<\exit>
if lo >= hi: return<\exit>
if lo == hi-1: return Node(lo, hi, 1)<\exit>
root = Node(lo, hi, hi-lo)<\exit>
root.left = self.build(lo, (hi+lo)/2)<\exit>
root.right = self.build((lo+hi)/2, hi)<\exit>
return root<\exit>
def find_delete(self, root, val):<\exit>
root.cnt -= 1<\exit>
if not root.left:<\exit>
return root.lo<\exit>
elif root.left.cnt >= val:<\exit>
return self.find_delete(root.left, val)<\exit>
else:<\exit>
return self.find_delete(root.right,<\exit>
val - root.left.cnt)<\exit>
class Solution(object):<\exit>
def reconstruct(self, A):<\exit>
st = SegmentTree()<\exit>
n = len(A)<\exit>
st.root = st.build(0, n)<\exit>
A = sorted(A, key=lambda x: x[0])<\exit>
ret = [0]*n<\exit>
for a in A:<\exit>
idx = st.find_delete(st.root, a[1]+1)<\exit>
ret[idx] = a[0]<\exit>
return ret<\exit>
if __name__ == "__main__":<\exit>
A = [(5, 0), (2, 1), (3, 1), (4, 1,), (1, 4)]<\exit>
assert Solution().reconstruct(A) == [5, 2, 3, 4, 1]<\exit>
import sys<\exit>
from os.path import join as path_join<\exit>
from os.path import dirname<\exit>
from sys import path as sys_path<\exit>
sys_path.append(path_join(dirname(__file__), '../server/src'))<\exit>
from ssplit import regex_sentence_boundary_gen<\exit>
def _text_by_offsets_gen(text, offsets):<\exit>
for start, end in offsets:<\exit>
yield text[start:end]<\exit>
def _normspace(s):<\exit>
import re<\exit>
return re.sub(r'\s', ' ', s)<\exit>
def sentencebreaks_to_newlines(text):<\exit>
line_offset = 1<\exit>
if "\r\n" in text:<\exit>
line_offset = 2<\exit>
offsets = [o for o in regex_sentence_boundary_gen(text)]<\exit>
sentences = [s for s in _text_by_offsets_gen(text, offsets)]<\exit>
orig_parts = []<\exit>
new_parts = []<\exit>
sentnum = len(sentences)<\exit>
for i in range(sentnum):<\exit>
sent = sentences[i]<\exit>
orig_parts.append(sent)<\exit>
new_parts.append(sent)<\exit>
if i < sentnum-1:<\exit>
orig_parts.append(text[offsets[i][1]:offsets[i+1][0]])<\exit>
if (offsets[i][1] < offsets[i+1][0] and<\exit>
text[offsets[i][1]].isspace()):<\exit>
new_parts.append('\n'+text[offsets[i][1]+line_offset:offsets[i+1][0]])<\exit>
else:<\exit>
new_parts.append(text[offsets[i][1]:offsets[i+1][0]])<\exit>
if len(offsets) and offsets[-1][1] < len(text):<\exit>
orig_parts.append(text[offsets[-1][1]:])<\exit>
new_parts.append(text[offsets[-1][1]:])<\exit>
assert text == ''.join(orig_parts), "INTERNAL ERROR:\n    '%s'\nvs\n    '%s'" % (text, ''.join(orig_parts))<\exit>
splittext = ''.join(new_parts)<\exit>
assert len(text) == len(splittext), "INTERNAL ERROR"<\exit>
assert _normspace(text) == _normspace(splittext), "INTERNAL ERROR:\n    '%s'\nvs\n    '%s'" % (_normspace(text), _normspace(splittext))<\exit>
return splittext<\exit>
def main(argv):<\exit>
while True:<\exit>
text = sys.stdin.readline()<\exit>
if len(text) == 0:<\exit>
break<\exit>
sys.stdout.write(sentencebreaks_to_newlines(text))<\exit>
if __name__ == "__main__":<\exit>
sys.exit(main(sys.argv))<\exit>
import cPickle<\exit>
def save_model(filename, model):<\exit>
output = open(filename, 'wb')<\exit>
cPickle.dump(model, output)<\exit>
output.close()<\exit>
def load_model(filename):<\exit>
pkl_file = open(filename, 'rb')<\exit>
res = cPickle.load(pkl_file)<\exit>
pkl_file.close()<\exit>
return res<\exit>
import cStringIO<\exit>
import base64<\exit>
try:<\exit>
from PIL import Image<\exit>
except ImportError:<\exit>
import Image<\exit>
from flask import Flask, request, request_finished, json, abort, make_response, Response, jsonify<\exit>
import sys<\exit>
sys.path.append("../../..")<\exit>
from facerec.model import PredictableModel<\exit>
from facerec.lbp import ExtendedLBP<\exit>
from facerec.feature import SpatialHistogram<\exit>
from facerec.distance import ChiSquareDistance<\exit>
from facerec.classifier import NearestNeighbor<\exit>
import logging<\exit>
from logging.handlers import RotatingFileHandler<\exit>
import recognition<\exit>
app = Flask(__name__)<\exit>
IMAGE_DECODE_ERROR = 10<\exit>
IMAGE_RESIZE_ERROR = 11<\exit>
PREDICTION_ERROR = 12<\exit>
SERVICE_TEMPORARY_UNAVAILABLE = 20<\exit>
UNKNOWN_ERROR = 21<\exit>
INVALID_FORMAT = 30<\exit>
INVALID_API_KEY = 31<\exit>
INVALID_API_TOKEN = 32<\exit>
MISSING_ARGUMENTS = 40<\exit>
errors = {<\exit>
IMAGE_DECODE_ERROR : "IMAGE_DECODE_ERROR",<\exit>
IMAGE_RESIZE_ERROR  : "IMAGE_RESIZE_ERROR",<\exit>
SERVICE_TEMPORARY_UNAVAILABLE	: "SERVICE_TEMPORARILY_UNAVAILABLE",<\exit>
PREDICTION_ERROR : "PREDICTION_ERROR",<\exit>
UNKNOWN_ERROR : "UNKNOWN_ERROR",<\exit>
INVALID_FORMAT : "INVALID_FORMAT",<\exit>
INVALID_API_KEY : "INVALID_API_KEY",<\exit>
INVALID_API_TOKEN : "INVALID_API_TOKEN",<\exit>
MISSING_ARGUMENTS : "MISSING_ARGUMENTS"<\exit>
}<\exit>
LOG_FILENAME = 'serverlog.log'<\exit>
LOG_BACKUP_COUNT = 5<\exit>
LOG_FILE_SIZE_BYTES = 50 * 1024 * 1024<\exit>
def init_logger(app):<\exit>
handler = RotatingFileHandler(LOG_FILENAME, maxBytes=LOG_FILE_SIZE_BYTES, backupCount=LOG_BACKUP_COUNT)<\exit>
handler.setLevel(logging.DEBUG)<\exit>
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')<\exit>
handler.setFormatter(formatter)<\exit>
loggers = [app.logger, logging.getLogger('facerec')]<\exit>
for logger in loggers:<\exit>
logger.addHandler(handler)<\exit>
def init_app(app):<\exit>
init_logger(app)<\exit>
init_app(app)<\exit>
@app.before_request<\exit>
def log_request():<\exit>
app.logger.debug("Request: %s %s", request.method, request.url)<\exit>
class WebAppException(Exception):<\exit>
def __init__(self, error_code, exception, status_code=None):<\exit>
Exception.__init__(self)<\exit>
self.status_code = 400<\exit>
self.exception = exception<\exit>
self.error_code = error_code<\exit>
try:<\exit>
self.message = errors[self.error_code]<\exit>
except:<\exit>
self.error_code = UNKNOWN_ERROR<\exit>
self.message = errors[self.error_code]<\exit>
if status_code is not None:<\exit>
self.status_code = status_code<\exit>
def to_dict(self):<\exit>
rv = dict()<\exit>
rv['status'] = 'failed'<\exit>
rv['code'] = self.error_code<\exit>
rv['message'] = self.message<\exit>
return rv<\exit>
class ThrowsWebAppException(object):<\exit>
def __init__(self, error_code, status_code=None):<\exit>
self.error_code = error_code<\exit>
self.status_code = status_code<\exit>
def __call__(self, function):<\exit>
def returnfunction(*args, **kwargs):<\exit>
try:<\exit>
return function(*args, **kwargs)<\exit>
except Exception as e:<\exit>
raise WebAppException(self.error_code, e)<\exit>
return returnfunction<\exit>
@app.errorhandler(WebAppException)<\exit>
def handle_exception(error):<\exit>
app.logger.exception(error.exception)<\exit>
response = jsonify(error.to_dict())<\exit>
response.status_code = error.status_code<\exit>
return response<\exit>
@ThrowsWebAppException(error_code = IMAGE_DECODE_ERROR)<\exit>
def read_image(base64_image):<\exit>
enc_data = base64.b64decode(base64_image)<\exit>
file_like = cStringIO.StringIO(enc_data)<\exit>
im = Image.open(file_like)<\exit>
im = im.convert("L")<\exit>
return im<\exit>
def preprocess_image(image_data):<\exit>
image = read_image(image_data)<\exit>
return image<\exit>
@ThrowsWebAppException(error_code = PREDICTION_ERROR)<\exit>
def get_prediction(image_data):<\exit>
image = preprocess_image(image_data)<\exit>
prediction = model.predict(image)<\exit>
return prediction<\exit>
@app.route('/api/recognize', methods=['GET', 'POST'])<\exit>
def identify():<\exit>
if request.headers['Content-Type'] == 'application/json':<\exit>
try:<\exit>
image_data = request.json['image']<\exit>
except:<\exit>
raise WebAppException(error_code=MISSING_ARGUMENTS)<\exit>
prediction = get_prediction(image_data)<\exit>
response = jsonify(name = prediction)<\exit>
return response<\exit>
else:<\exit>
raise WebAppException(error_code=INVALID_FORMAT)<\exit>
if __name__ == '__main__':<\exit>
long_description = ("server.py is a simple facerec webservice. It provides "<\exit>
"you with a simple RESTful API to recognize faces from a "<\exit>
"computed model. Please don't use this server in a production "<\exit>
"environment, as it provides no security and there might be "<\exit>
"ugly concurrency issues with the global state of the model." )<\exit>
print "=== Description ==="<\exit>
print long_description<\exit>
from argparse import ArgumentParser<\exit>
parser = ArgumentParser()<\exit>
parser.add_argument("-t", "--train", action="store", dest="dataset", default=None,<\exit>
help="Calculates a new model from a given CSV file. CSV format: <person>;</path/to/image/folder>.", required=False)<\exit>
parser.add_argument("-a", "--address", action="store", dest="host", default="0.0.0.0",<\exit>
help="Sets the endpoint for this server.", required=False)<\exit>
parser.add_argument("-p", "--port", action="store", dest="port", default=5000,<\exit>
help="Sets the port for this server.", required=False)<\exit>
parser.add_argument('model_filename', nargs='?', help="Filename of the model to use or store")<\exit>
print "=== Usage ==="<\exit>
parser.print_help()<\exit>
args = parser.parse_args()<\exit>
global model<\exit>
if args.dataset:<\exit>
model = recognition.get_model_from_csv(filename=args.dataset,out_model_filename=args.model_filename)<\exit>
else:<\exit>
model = recognition.load_model_file(args.model_filename)<\exit>
print "=== Server Log (also in %s) ===" % (LOG_FILENAME)<\exit>
app.run(host=args.host, port=args.port, debug=True, use_reloader=False, threaded=False)<\exit>
import os<\exit>
from .compat import cookielib<\exit>
from .cookies import cookiejar_from_dict<\exit>
from .models import Request<\exit>
from .hooks import dispatch_hook, default_hooks<\exit>
from .utils import from_key_val_list, default_headers<\exit>
from .exceptions import TooManyRedirects, InvalidSchema<\exit>
from .compat import urlparse, urljoin<\exit>
from .adapters import HTTPAdapter<\exit>
from .utils import requote_uri, get_environ_proxies, get_netrc_auth<\exit>
from .status_codes import codes<\exit>
REDIRECT_STATI = (codes.moved, codes.found, codes.other, codes.temporary_moved)<\exit>
DEFAULT_REDIRECT_LIMIT = 30<\exit>
def merge_kwargs(local_kwarg, default_kwarg):<\exit>
if default_kwarg is None:<\exit>
return local_kwarg<\exit>
if isinstance(local_kwarg, str):<\exit>
return local_kwarg<\exit>
if local_kwarg is None:<\exit>
return default_kwarg<\exit>
if not hasattr(default_kwarg, 'items'):<\exit>
return local_kwarg<\exit>
default_kwarg = from_key_val_list(default_kwarg)<\exit>
local_kwarg = from_key_val_list(local_kwarg)<\exit>
kwargs = default_kwarg.copy()<\exit>
kwargs.update(local_kwarg)<\exit>
for (k, v) in local_kwarg.items():<\exit>
if v is None:<\exit>
del kwargs[k]<\exit>
return kwargs<\exit>
class SessionRedirectMixin(object):<\exit>
def resolve_redirects(self, resp, req, stream=False, timeout=None, verify=True, cert=None, proxies=None):<\exit>
i = 0<\exit>
while (('location' in resp.headers and resp.status_code in REDIRECT_STATI)):<\exit>
resp.content<\exit>
if i >= self.max_redirects:<\exit>
raise TooManyRedirects('Exceeded %s redirects.' % self.max_redirects)<\exit>
resp.close()<\exit>
url = resp.headers['location']<\exit>
method = req.method<\exit>
if url.startswith('//'):<\exit>
parsed_rurl = urlparse(resp.url)<\exit>
url = '%s:%s' % (parsed_rurl.scheme, url)<\exit>
if not urlparse(url).netloc:<\exit>
url = urljoin(resp.url, requote_uri(url))<\exit>
if resp.status_code is codes.see_other:<\exit>
method = 'GET'<\exit>
if resp.status_code in (codes.moved, codes.found) and req.method == 'POST':<\exit>
method = 'GET'<\exit>
if (resp.status_code == 303) and req.method != 'HEAD':<\exit>
method = 'GET'<\exit>
headers = req.headers<\exit>
try:<\exit>
del headers['Cookie']<\exit>
except KeyError:<\exit>
pass<\exit>
resp = self.request(<\exit>
url=url,<\exit>
method=method,<\exit>
headers=headers,<\exit>
params=req.params,<\exit>
auth=req.auth,<\exit>
cookies=req.cookies,<\exit>
allow_redirects=False,<\exit>
stream=stream,<\exit>
timeout=timeout,<\exit>
verify=verify,<\exit>
cert=cert,<\exit>
proxies=proxies<\exit>
)<\exit>
i += 1<\exit>
yield resp<\exit>
class Session(SessionRedirectMixin):<\exit>
def __init__(self):<\exit>
self.headers = default_headers()<\exit>
self.auth = None<\exit>
self.proxies = {}<\exit>
self.hooks = default_hooks()<\exit>
self.params = {}<\exit>
self.stream = False<\exit>
self.verify = True<\exit>
self.cert = None<\exit>
self.max_redirects = DEFAULT_REDIRECT_LIMIT<\exit>
self.trust_env = True<\exit>
self.cookies = cookiejar_from_dict({})<\exit>
self.adapters = {}<\exit>
self.mount('http://', HTTPAdapter())<\exit>
self.mount('https://', HTTPAdapter())<\exit>
def __enter__(self):<\exit>
return self<\exit>
def __exit__(self, *args):<\exit>
self.close()<\exit>
def request(self, method, url,<\exit>
params=None,<\exit>
data=None,<\exit>
headers=None,<\exit>
cookies=None,<\exit>
files=None,<\exit>
auth=None,<\exit>
timeout=None,<\exit>
allow_redirects=True,<\exit>
proxies=None,<\exit>
hooks=None,<\exit>
stream=None,<\exit>
verify=None,<\exit>
cert=None):<\exit>
cookies = cookies or {}<\exit>
proxies = proxies or {}<\exit>
if not isinstance(cookies, cookielib.CookieJar):<\exit>
cookies = cookiejar_from_dict(cookies)<\exit>
for cookie in self.cookies:<\exit>
cookies.set_cookie(cookie)<\exit>
if self.trust_env:<\exit>
env_proxies = get_environ_proxies(url) or {}<\exit>
for (k, v) in env_proxies.items():<\exit>
proxies.setdefault(k, v)<\exit>
if not auth:<\exit>
auth = get_netrc_auth(url)<\exit>
if not verify and verify is not False:<\exit>
verify = os.environ.get('REQUESTS_CA_BUNDLE')<\exit>
if not verify and verify is not False:<\exit>
verify = os.environ.get('CURL_CA_BUNDLE')<\exit>
params = merge_kwargs(params, self.params)<\exit>
headers = merge_kwargs(headers, self.headers)<\exit>
auth = merge_kwargs(auth, self.auth)<\exit>
proxies = merge_kwargs(proxies, self.proxies)<\exit>
hooks = merge_kwargs(hooks, self.hooks)<\exit>
stream = merge_kwargs(stream, self.stream)<\exit>
verify = merge_kwargs(verify, self.verify)<\exit>
cert = merge_kwargs(cert, self.cert)<\exit>
req = Request()<\exit>
req.method = method<\exit>
req.url = url<\exit>
req.headers = headers<\exit>
req.files = files<\exit>
req.data = data<\exit>
req.params = params<\exit>
req.auth = auth<\exit>
req.cookies = cookies<\exit>
req.hooks = hooks<\exit>
prep = req.prepare()<\exit>
resp = self.send(prep, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<\exit>
for cookie in resp.cookies:<\exit>
self.cookies.set_cookie(cookie)<\exit>
gen = self.resolve_redirects(resp, req, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<\exit>
history = [r for r in gen] if allow_redirects else []<\exit>
if history:<\exit>
history.insert(0, resp)<\exit>
resp = history.pop()<\exit>
resp.history = tuple(history)<\exit>
self.response = dispatch_hook('response', hooks, resp)<\exit>
return resp<\exit>
def get(self, url, **kwargs):<\exit>
kwargs.setdefault('allow_redirects', True)<\exit>
return self.request('GET', url, **kwargs)<\exit>
def options(self, url, **kwargs):<\exit>
kwargs.setdefault('allow_redirects', True)<\exit>
return self.request('OPTIONS', url, **kwargs)<\exit>
def head(self, url, **kwargs):<\exit>
kwargs.setdefault('allow_redirects', False)<\exit>
return self.request('HEAD', url, **kwargs)<\exit>
def post(self, url, data=None, **kwargs):<\exit>
return self.request('POST', url, data=data, **kwargs)<\exit>
def put(self, url, data=None, **kwargs):<\exit>
return self.request('PUT', url, data=data, **kwargs)<\exit>
def patch(self, url, data=None, **kwargs):<\exit>
return self.request('PATCH', url,  data=data, **kwargs)<\exit>
def delete(self, url, **kwargs):<\exit>
return self.request('DELETE', url, **kwargs)<\exit>
def send(self, request, **kwargs):<\exit>
adapter = self.get_adapter(url=request.url)<\exit>
r = adapter.send(request, **kwargs)<\exit>
return r<\exit>
def get_adapter(self, url):<\exit>
for (prefix, adapter) in self.adapters.items():<\exit>
if url.startswith(prefix):<\exit>
return adapter<\exit>
raise InvalidSchema("No connection adapters were found for '%s'" % url)<\exit>
def close(self):<\exit>
for _, v in self.adapters.items():<\exit>
v.close()<\exit>
def mount(self, prefix, adapter):<\exit>
self.adapters[prefix] = adapter<\exit>
def __getstate__(self):<\exit>
return dict((attr, getattr(self, attr, None)) for attr in self.__attrs__)<\exit>
def __setstate__(self, state):<\exit>
for attr, value in state.items():<\exit>
setattr(self, attr, value)<\exit>
def session():<\exit>
return Session()<\exit>
import os<\exit>
import dj_database_url<\exit>
BASE_DIR = os.path.dirname(os.path.abspath(__file__))<\exit>
SECRET_KEY = 'zepnf(4ontqc)o2=owlr5354698rgdw_l8!8%rl056$d(td)!u'<\exit>
DEBUG = False<\exit>
ALLOWED_HOSTS = ["*"]<\exit>
INSTALLED_APPS = (<\exit>
'django.contrib.admin',<\exit>
'django.contrib.auth',<\exit>
'django.contrib.contenttypes',<\exit>
'django.contrib.sessions',<\exit>
'django.contrib.messages',<\exit>
'django.contrib.staticfiles',<\exit>
'rake_app',<\exit>
)<\exit>
MIDDLEWARE_CLASSES = (<\exit>
'django.contrib.sessions.middleware.SessionMiddleware',<\exit>
'django.middleware.common.CommonMiddleware',<\exit>
'django.middleware.csrf.CsrfViewMiddleware',<\exit>
'django.contrib.auth.middleware.AuthenticationMiddleware',<\exit>
'django.contrib.auth.middleware.SessionAuthenticationMiddleware',<\exit>
'django.contrib.messages.middleware.MessageMiddleware',<\exit>
'django.middleware.clickjacking.XFrameOptionsMiddleware',<\exit>
'django.middleware.security.SecurityMiddleware',<\exit>
)<\exit>
ROOT_URLCONF = 'tagr.urls'<\exit>
TEMPLATES = [<\exit>
{<\exit>
'BACKEND': 'django.template.backends.django.DjangoTemplates',<\exit>
'DIRS': [<\exit>
os.path.join(BASE_DIR, 'templates').replace('\\', '/'),<\exit>
],<\exit>
'APP_DIRS': True,<\exit>
'OPTIONS': {<\exit>
'context_processors': [<\exit>
'django.template.context_processors.debug',<\exit>
'django.template.context_processors.request',<\exit>
'django.contrib.auth.context_processors.auth',<\exit>
'django.contrib.messages.context_processors.messages',<\exit>
],<\exit>
},<\exit>
},<\exit>
]<\exit>
WSGI_APPLICATION = 'tagr.wsgi.application'<\exit>
DATABASES = {<\exit>
'default': {<\exit>
'ENGINE': 'django.db.backends.sqlite3',<\exit>
'NAME': os.path.join(BASE_DIR, 'db.sqlite3'),<\exit>
}<\exit>
}<\exit>
LANGUAGE_CODE = 'en-us'<\exit>
TIME_ZONE = 'UTC'<\exit>
USE_I18N = True<\exit>
USE_L10N = True<\exit>
USE_TZ = True<\exit>
SECURE_PROXY_SSL_HEADER = ('HTTP_X_FORWARDED_PROTO', 'https')<\exit>
STATIC_ROOT = 'staticfiles'<\exit>
STATIC_URL = '/static/'<\exit>
STATICFILES_DIRS = (<\exit>
os.path.join(BASE_DIR, 'static'),<\exit>
)<\exit>
STATICFILES_STORAGE = 'whitenoise.django.GzipManifestStaticFilesStorage'<\exit>
MEDIA_URL = 'media/'<\exit>
MEDIA_DIRS = (<\exit>
os.path.join(BASE_DIR, 'media'),<\exit>
)<\exit>
from distutils.core import setup<\exit>
import os<\exit>
setup(<\exit>
name         = 'snippyt',<\exit>
version      = '0.0.1',<\exit>
author       = 'Daniel D. Zhang',<\exit>
author_email = 'dzhang.idf@gmail.com',<\exit>
license      = 'BSD-3',<\exit>
description  = 'A command line snippet management for modern developers.',<\exit>
url          = 'https://github.com/idf/snippyt',<\exit>
packages     = [<\exit>
'snippyt',<\exit>
'snippyt.templates',<\exit>
],<\exit>
package_data = {<\exit>
'snippyt.templates': [f for f in os.listdir('snippyt/templates') if '.' not in f]<\exit>
},<\exit>
scripts          = ['snip'],<\exit>
install_requires = [<\exit>
'docopt >= 0.6.2',<\exit>
'Jinja2 >= 2.9.5',<\exit>
'MarkupSafe >= 1.0',<\exit>
]<\exit>
)<\exit>
import shlex<\exit>
import subprocess<\exit>
import sys<\exit>
import re<\exit>
import os<\exit>
env_var_rx = re.compile(r"^([a-zA-Z0-9_]+)=(\S+)$")<\exit>
def debug(message):<\exit>
print >> sys.stderr, message<\exit>
if sys.platform == 'win32':<\exit>
dev_null = open("NUL:", "w")<\exit>
else:<\exit>
dev_null = open("/dev/null", "w")<\exit>
fcntl = fd = fl = None<\exit>
try:<\exit>
import fcntl<\exit>
except ImportError:<\exit>
pass<\exit>
else:<\exit>
fd = dev_null.fileno()<\exit>
fl = fcntl.fcntl(fd, fcntl.F_GETFD)<\exit>
fcntl.fcntl(fd, fcntl.F_SETFD, fl | fcntl.FD_CLOEXEC)<\exit>
del fcntl, fd, fl<\exit>
def _open_out_file(filename):<\exit>
if filename in ['NUL:', '/dev/null']:<\exit>
return dev_null<\exit>
else:<\exit>
return open(filename, 'wb')<\exit>
class Node(object):<\exit>
pass<\exit>
class Op(Node):<\exit>
pass<\exit>
class Pipe(Op):<\exit>
pass<\exit>
class And(Op):<\exit>
pass<\exit>
class Or(Op):<\exit>
pass<\exit>
class Command(Node):<\exit>
class PIPE(object):<\exit>
pass<\exit>
class STDOUT(object):<\exit>
pass<\exit>
def __init__(self, name):<\exit>
super(Command, self).__init__()<\exit>
self.name = name<\exit>
self.argv = [name]<\exit>
self.stdin = None<\exit>
self.stdout = None<\exit>
self.stderr = None<\exit>
self.env_vars = None<\exit>
def __repr__(self):<\exit>
return "Command(%r, argv=%r, stdin=%r, stdout=%r, stderr=%r)" \<\exit>
% (self.name, self.argv, self.stdin, self.stdout, self.stderr)<\exit>
class Chdir(Node):<\exit>
def __init__(self):<\exit>
super(Chdir, self).__init__()<\exit>
self.dir = None<\exit>
def __repr__(self):<\exit>
return "Chdir(%r)" \<\exit>
% (self.dir)<\exit>
class Pipeline(object):<\exit>
def __init__(self):<\exit>
self.current_command = None<\exit>
self.pipeline = []<\exit>
def _commit_command(self):<\exit>
assert self.current_command is not None<\exit>
self.pipeline.append(self.current_command)<\exit>
self.current_command = None<\exit>
def get_abbreviated_command(self):<\exit>
l = []<\exit>
for node in self.pipeline:<\exit>
if isinstance(node, Command):<\exit>
l.append(node.name)<\exit>
if isinstance(node, Chdir):<\exit>
l.append('cd %s' % node.dir)<\exit>
elif isinstance(node, Pipe):<\exit>
l.append('|')<\exit>
elif isinstance(node, And):<\exit>
l.append('&&')<\exit>
elif isinstance(node, And):<\exit>
l.append('||')<\exit>
return ' '.join(l)<\exit>
def parse(self, command):<\exit>
self.current_command = None<\exit>
self.pipeline = []<\exit>
if isinstance(command, list):<\exit>
tokens = list(command)<\exit>
else:<\exit>
tokens = shlex.split(command)<\exit>
debug("command: shlex: %r" % (tokens,))<\exit>
BEGIN, COMMAND, CHDIR, STDERR, STDOUT, STDIN = range(6)<\exit>
state = BEGIN<\exit>
self.current_command = None<\exit>
env_vars = dict()<\exit>
while tokens:<\exit>
token = tokens.pop(0)<\exit>
if state == BEGIN:<\exit>
env_var_match = env_var_rx.match(token)<\exit>
if env_var_match is not None:<\exit>
env_vars[env_var_match.group(1)] = env_var_match.group(2)<\exit>
else:<\exit>
assert self.current_command is None<\exit>
if token == 'cd':<\exit>
self.current_command = Chdir()<\exit>
assert not env_vars<\exit>
state = CHDIR<\exit>
else:<\exit>
self.current_command = Command(token)<\exit>
if env_vars:<\exit>
self.current_command.env_vars = env_vars<\exit>
env_vars = dict()<\exit>
state = COMMAND<\exit>
elif state == COMMAND:<\exit>
if token == '>':<\exit>
state = STDOUT<\exit>
elif token == '2>':<\exit>
state = STDERR<\exit>
elif token == '2>&1':<\exit>
assert self.current_command.stderr is None<\exit>
self.current_command.stderr = Command.STDOUT<\exit>
elif token == '<':<\exit>
state = STDIN<\exit>
elif token == '|':<\exit>
assert self.current_command.stdout is None<\exit>
self.current_command.stdout = Command.PIPE<\exit>
self._commit_command()<\exit>
self.pipeline.append(Pipe())<\exit>
state = BEGIN<\exit>
elif token == '&&':<\exit>
self._commit_command()<\exit>
self.pipeline.append(And())<\exit>
state = BEGIN<\exit>
elif token == '||':<\exit>
self._commit_command()<\exit>
self.pipeline.append(Or())<\exit>
state = BEGIN<\exit>
else:<\exit>
self.current_command.argv.append(token)<\exit>
elif state == CHDIR:<\exit>
if token == '&&':<\exit>
self._commit_command()<\exit>
self.pipeline.append(And())<\exit>
state = BEGIN<\exit>
else:<\exit>
assert self.current_command.dir is None<\exit>
self.current_command.dir = token<\exit>
elif state == STDOUT:<\exit>
assert self.current_command.stdout is None<\exit>
self.current_command.stdout = token<\exit>
state = COMMAND<\exit>
elif state == STDERR:<\exit>
assert self.current_command.stderr is None<\exit>
self.current_command.stderr = token<\exit>
state = COMMAND<\exit>
elif state == STDIN:<\exit>
assert self.current_command.stdin is None<\exit>
self.current_command.stdin = token<\exit>
state = COMMAND<\exit>
self._commit_command()<\exit>
return self.pipeline<\exit>
def _exec_piped_commands(self, commands):<\exit>
retvals = []<\exit>
for cmd in commands:<\exit>
retvals.append(cmd.wait())<\exit>
retval = 0<\exit>
for r in retvals:<\exit>
if r:<\exit>
retval = retvals[-1]<\exit>
break<\exit>
return retval<\exit>
def run(self, verbose=False):<\exit>
pipeline = list(self.pipeline)<\exit>
files_to_close = []<\exit>
piped_commands = []<\exit>
piped_commands_display = []<\exit>
BEGIN, PIPE = range(2)<\exit>
state = BEGIN<\exit>
cwd = '.'<\exit>
while pipeline:<\exit>
node = pipeline.pop(0)<\exit>
if isinstance(node, Chdir):<\exit>
next_op = pipeline.pop(0)<\exit>
assert isinstance(next_op, And)<\exit>
cwd = os.path.join(cwd, node.dir)<\exit>
if verbose:<\exit>
piped_commands_display.append("cd %s &&" % node.dir)<\exit>
continue<\exit>
assert isinstance(node, (Command, Chdir))<\exit>
cmd = node<\exit>
if verbose:<\exit>
if cmd.env_vars:<\exit>
env_vars_str = ' '.join(['%s=%s' % (key, val) for key, val in cmd.env_vars.iteritems()])<\exit>
piped_commands_display.append("%s %s" % (env_vars_str, ' '.join(cmd.argv)))<\exit>
else:<\exit>
piped_commands_display.append(' '.join(cmd.argv))<\exit>
if state == PIPE:<\exit>
stdin = piped_commands[-1].stdout<\exit>
elif cmd.stdin is not None:<\exit>
stdin = open(cmd.stdin, "r")<\exit>
if verbose:<\exit>
piped_commands_display.append('< %s' % cmd.stdin)<\exit>
files_to_close.append(stdin)<\exit>
else:<\exit>
stdin = None<\exit>
if cmd.stdout is None:<\exit>
stdout = None<\exit>
elif cmd.stdout is Command.PIPE:<\exit>
stdout = subprocess.PIPE<\exit>
else:<\exit>
stdout = _open_out_file(cmd.stdout)<\exit>
files_to_close.append(stdout)<\exit>
if verbose:<\exit>
piped_commands_display.append('> %s' % cmd.stdout)<\exit>
if cmd.stderr is None:<\exit>
stderr = None<\exit>
elif cmd.stderr is Command.PIPE:<\exit>
stderr = subprocess.PIPE<\exit>
elif cmd.stderr is Command.STDOUT:<\exit>
stderr = subprocess.STDOUT<\exit>
if verbose:<\exit>
piped_commands_display.append('2>&1')<\exit>
else:<\exit>
stderr = _open_out_file(cmd.stderr)<\exit>
files_to_close.append(stderr)<\exit>
if verbose:<\exit>
piped_commands_display.append('2> %s' % cmd.stderr)<\exit>
if cmd.env_vars:<\exit>
env = dict(os.environ)<\exit>
env.update(cmd.env_vars)<\exit>
else:<\exit>
env = None<\exit>
if cwd == '.':<\exit>
proc_cwd = None<\exit>
else:<\exit>
proc_cwd = cwd<\exit>
debug("command: subprocess.Popen(argv=%r, stdin=%r, stdout=%r, stderr=%r, env_vars=%r, cwd=%r)"<\exit>
% (cmd.argv, stdin, stdout, stderr, cmd.env_vars, proc_cwd))<\exit>
proc = subprocess.Popen(cmd.argv, stdin=stdin, stdout=stdout, stderr=stderr, env=env, cwd=proc_cwd)<\exit>
del stdin, stdout, stderr<\exit>
piped_commands.append(proc)<\exit>
try:<\exit>
next_node = pipeline.pop(0)<\exit>
except IndexError:<\exit>
try:<\exit>
retval = self._exec_piped_commands(piped_commands)<\exit>
if verbose:<\exit>
print "%s: exit code %i" % (' '.join(piped_commands_display), retval)<\exit>
finally:<\exit>
for f in files_to_close:<\exit>
if f is not dev_null:<\exit>
f.close()<\exit>
files_to_close = []<\exit>
return retval<\exit>
else:<\exit>
if isinstance(next_node, Pipe):<\exit>
state = PIPE<\exit>
piped_commands_display.append('|')<\exit>
elif isinstance(next_node, Or):<\exit>
try:<\exit>
this_retval = self._exec_piped_commands(piped_commands)<\exit>
finally:<\exit>
for f in files_to_close:<\exit>
if f is not dev_null:<\exit>
f.close()<\exit>
files_to_close = []<\exit>
if this_retval == 0:<\exit>
if verbose:<\exit>
print "%s: exit code %i (|| is short-circuited)" % (' '.join(piped_commands_display), retval)<\exit>
return this_retval<\exit>
if verbose:<\exit>
print "%s: exit code %i (|| proceeds)" % (' '.join(piped_commands_display), retval)<\exit>
state = BEGIN<\exit>
piped_commands = []<\exit>
piped_commands_display = []<\exit>
elif isinstance(next_node, And):<\exit>
try:<\exit>
this_retval = self._exec_piped_commands(piped_commands)<\exit>
finally:<\exit>
for f in files_to_close:<\exit>
if f is not dev_null:<\exit>
f.close()<\exit>
files_to_close = []<\exit>
if this_retval != 0:<\exit>
if verbose:<\exit>
print "%s: exit code %i (&& is short-circuited)" % (' '.join(piped_commands_display), retval)<\exit>
return this_retval<\exit>
if verbose:<\exit>
print "%s: exit code %i (&& proceeds)" % (' '.join(piped_commands_display), retval)<\exit>
state = BEGIN<\exit>
piped_commands = []<\exit>
piped_commands_display = []<\exit>
def _main():<\exit>
pipeline = Pipeline()<\exit>
pipeline.parse('./foo.py 2>&1 < xxx | cat && ls')<\exit>
print pipeline.run()<\exit>
if __name__ == '__main__':<\exit>
_main()<\exit>
import collections<\exit>
class Solution(object):<\exit>
def solve(self, cipher):<\exit>
d = collections.defaultdict(int)<\exit>
lst = list(cipher)<\exit>
n = len(lst)<\exit>
for i in xrange(n):<\exit>
for l in xrange(1, n - i + 1):<\exit>
sub = lst[i: i + l]<\exit>
sub.sort()<\exit>
d["".join(sub)] += 1<\exit>
s = 0<\exit>
for v in d.values():<\exit>
s += v * (v - 1) / 2<\exit>
return s<\exit>
if __name__ == "__main__":<\exit>
import sys<\exit>
f = open("0.in", "r")<\exit>
solution = Solution()<\exit>
testcases = int(f.readline().strip())<\exit>
for t in xrange(testcases):<\exit>
cipher = f.readline().strip()<\exit>
s = "%s\n" % (solution.solve(cipher))<\exit>
print s,<\exit>
class Solution(object):<\exit>
def solve(self, cipher):<\exit>
N, A = cipher<\exit>
f = [0 for _ in xrange(N + 1)]<\exit>
for i in xrange(1, N + 1):<\exit>
f[i] = f[i - 1] + A[i - 1]<\exit>
for i in xrange(N):<\exit>
if f[i] == f[N] - f[i + 1]:<\exit>
return "YES"<\exit>
return "NO"<\exit>
if __name__ == "__main__":<\exit>
import sys<\exit>
f = open("1.in", "r")<\exit>
solution = Solution()<\exit>
testcases = int(f.readline().strip())<\exit>
for t in xrange(testcases):<\exit>
N = int(f.readline().strip())<\exit>
A = map(int, f.readline().strip().split(' '))<\exit>
cipher = N, A<\exit>
s = "%s\n" % (solution.solve(cipher))<\exit>
print s,<\exit>
class Solution(object):<\exit>
def solve(self, cipher):<\exit>
B = cipher<\exit>
N = len(B)<\exit>
dp = [[0, 0] for _ in xrange(N + 1)]<\exit>
LOW = 0<\exit>
HIGH = 1<\exit>
for i in xrange(2, N + 1):<\exit>
dp[i][LOW] = max(dp[i - 1][LOW], dp[i - 1][HIGH] + abs(1 - B[i - 2]))<\exit>
dp[i][HIGH] = max(dp[i - 1][HIGH], dp[i - 1][LOW] + abs(B[i - 1] - 1))<\exit>
return str(max(dp[-1][LOW], dp[-1][HIGH]))<\exit>
if __name__ == "__main__":<\exit>
import sys<\exit>
f = open("1.in", "r")<\exit>
testcases = int(f.readline().strip())<\exit>
for t in xrange(testcases):<\exit>
N = int(f.readline().strip())<\exit>
cipher = map(int, f.readline().strip().split(' '))<\exit>
s = "%s\n" % (Solution().solve(cipher))<\exit>
print s,<\exit>
import math<\exit>
class Solution(object):<\exit>
def solve(self, cipher):<\exit>
N = cipher<\exit>
if N % 2 == 1:<\exit>
return 0<\exit>
cnt = 0<\exit>
i = 1<\exit>
sq = math.sqrt(N)<\exit>
while i <= sq:<\exit>
if N % i == 0:<\exit>
if i % 2 == 0:<\exit>
cnt += 1<\exit>
other = N / i<\exit>
if other != i and other % 2 == 0:<\exit>
cnt += 1<\exit>
i += 1<\exit>
return cnt<\exit>
if __name__ == "__main__":<\exit>
import sys<\exit>
f = open("1.in", "r")<\exit>
testcases = int(f.readline().strip())<\exit>
for t in xrange(testcases):<\exit>
cipher = int(f.readline().strip())<\exit>
s = "%s\n" % (Solution().solve(cipher))<\exit>
print s,<\exit>
class Solution(object):<\exit>
def solve(self, cipher):<\exit>
N, lst = cipher<\exit>
for i in xrange(N):<\exit>
for j in xrange(i + 1, N):<\exit>
if self.gcd(lst[i], lst[j]) == 1:<\exit>
return "YES"<\exit>
return "NO"<\exit>
def gcd(self, a, b):<\exit>
while b:<\exit>
a, b = b, a % b<\exit>
return a<\exit>
if __name__ == "__main__":<\exit>
import sys<\exit>
f = open("1.in", "r")<\exit>
testcases = int(f.readline().strip())<\exit>
for t in xrange(testcases):<\exit>
N = int(f.readline().strip())<\exit>
lst = map(int, f.readline().strip().split(' '))<\exit>
cipher = (N, lst)<\exit>
s = "%s\n" % (Solution().solve(cipher))<\exit>
print s,<\exit>
class Solution(object):<\exit>
def solve(self, cipher):<\exit>
A, P, Q = cipher<\exit>
A.sort()<\exit>
gmax = -1 << 32<\exit>
M = -1<\exit>
if P <= A[0] and gmax < A[0] - P:<\exit>
gmax = A[0] - P<\exit>
M = P<\exit>
if Q >= A[-1] and gmax < Q - A[-1]:<\exit>
gmax = Q - A[-1]<\exit>
M = Q<\exit>
for i in xrange(1, len(A)):<\exit>
max_cnd = (A[i] - A[i - 1]) / 2<\exit>
if gmax < max_cnd:<\exit>
M_cnd = (A[i] + A[i - 1]) / 2<\exit>
if P <= M_cnd <= Q:<\exit>
gmax = max_cnd<\exit>
M = M_cnd<\exit>
else:<\exit>
if M_cnd > Q and A[i - 1] <= Q <= A[i]:<\exit>
max_cnd = min(abs(A[i] - Q), abs(A[i - 1] - Q))<\exit>
if gmax < max_cnd:<\exit>
gmax = max_cnd<\exit>
M = Q<\exit>
if M_cnd < P and A[i - 1] <= P <= A[i]:<\exit>
max_cnd = min(abs(A[i] - P), abs(A[i - 1] - P))<\exit>
if gmax < max_cnd:<\exit>
gmax = max_cnd<\exit>
M = P<\exit>
return M<\exit>
if __name__ == "__main__":<\exit>
import sys<\exit>
f = open("1.in", "r")<\exit>
testcases = int(f.readline().strip())<\exit>
lst = map(int, f.readline().strip().split(" "))<\exit>
P, Q = map(int, f.readline().strip().split(" "))<\exit>
cipher = lst, P, Q<\exit>
s = "%s\n" % (Solution().solve(cipher))<\exit>
print s,<\exit>
import math<\exit>
class Solution(object):<\exit>
def solve(self, cipher):<\exit>
L, S1, S2, qs = cipher<\exit>
v = abs(S1 - S2) / math.sqrt(2)<\exit>
rets = []<\exit>
for q in qs:<\exit>
t = (L - math.sqrt(q)) / v<\exit>
rets.append(t)<\exit>
return "\n".join(map(lambda x: "%f" % x, rets))<\exit>
if __name__ == "__main__":<\exit>
import sys<\exit>
f = open("1.in", "r")<\exit>
solution = Solution()<\exit>
L, S1, S2 = map(int, f.readline().strip().split(' '))<\exit>
q = int(f.readline().strip())<\exit>
qs = []<\exit>
for t in xrange(q):<\exit>
qs.append(int(f.readline().strip()))<\exit>
cipher = L, S1, S2, qs<\exit>
s = "%s\n" % (solution.solve(cipher))<\exit>
print s,<\exit>
class Solution(object):<\exit>
def solve(self, cipher):<\exit>
hm = {}<\exit>
cnt = 0<\exit>
for ind, val in enumerate(cipher):<\exit>
if val in hm:<\exit>
cnt += 2 * len(hm[val])<\exit>
hm[val].append(ind)<\exit>
else:<\exit>
hm[val] = [ind]<\exit>
return cnt<\exit>
if __name__ == "__main__":<\exit>
import sys<\exit>
f = open("1.in", "r")<\exit>
testcases = int(f.readline().strip())<\exit>
for t in xrange(testcases):<\exit>
N = f.readline().strip()<\exit>
cipher = map(int, f.readline().strip().split(' '))<\exit>
s = "%s\n" % (Solution().solve(cipher))<\exit>
print s,<\exit>
MOD = 10 ** 9 + 7<\exit>
import math<\exit>
class Solution(object):<\exit>
def solve(self, cipher):<\exit>
N, M = cipher<\exit>
return math.factorial(N + M - 1) / math.factorial(N) / math.factorial(M - 1) % MOD<\exit>
if __name__ == "__main__":<\exit>
import sys<\exit>
f = open("1.in", "r")<\exit>
testcases = int(f.readline().strip())<\exit>
for t in xrange(testcases):<\exit>
cipher = map(int, f.readline().strip().split(' '))<\exit>
s = "%s\n" % (Solution().solve(cipher))<\exit>
print s,<\exit>
class Solution(object):<\exit>
def solve(self, N):<\exit>
for i in xrange(N / 3 * 3, -1, -3):<\exit>
if (N - i) % 5 == 0:<\exit>
return "5" * i + "3" * (N - i)<\exit>
return "-1"<\exit>
if __name__ == "__main__":<\exit>
import sys<\exit>
f = open("1.in", "r")<\exit>
solution = Solution()<\exit>
testcases = int(f.readline().strip())<\exit>
for t in xrange(testcases):<\exit>
cipher = int(f.readline().strip())<\exit>
s = "%s\n" % (solution.solve(cipher))<\exit>
print s,<\exit>
class Solution(object):<\exit>
def solve(self, cipher):<\exit>
N, K, Q, A, q = cipher<\exit>
result = []<\exit>
for i in q:<\exit>
result.append(A[(i - K) % N])<\exit>
return "\n".join(map(str, result))<\exit>
if __name__ == "__main__":<\exit>
import sys<\exit>
f = open("1.in", "r")<\exit>
N, K, Q = map(int, f.readline().strip().split(' '))<\exit>
A = map(int, f.readline().strip().split(' '))<\exit>
q = []<\exit>
for i in xrange(Q):<\exit>
q.append(int(f.readline().strip()))<\exit>
cipher = N, K, Q, A, q<\exit>
s = "%s\n" % (Solution().solve(cipher))<\exit>
print s,<\exit>
import gobject<\exit>
import gtk<\exit>
import ns.core<\exit>
import ns.network<\exit>
import ns.visualizer<\exit>
from visualizer.base import InformationWindow<\exit>
from visualizer.higcontainer import HIGContainer<\exit>
from kiwi.ui.objectlist import ObjectList, Column<\exit>
class ShowLastPackets(InformationWindow):<\exit>
class PacketList(gtk.ScrolledWindow):<\exit>
(<\exit>
COLUMN_TIME,<\exit>
COLUMN_INTERFACE,<\exit>
COLUMN_SIZE,<\exit>
COLUMN_CONTENTS,<\exit>
) = range(4)<\exit>
def __init__(self):<\exit>
super(ShowLastPackets.PacketList, self).__init__()<\exit>
self.set_properties(hscrollbar_policy=gtk.POLICY_AUTOMATIC,<\exit>
vscrollbar_policy=gtk.POLICY_AUTOMATIC)<\exit>
self.table_model = gtk.ListStore(*([str]*4))<\exit>
treeview = gtk.TreeView(self.table_model)<\exit>
treeview.show()<\exit>
self.add(treeview)<\exit>
def add_column(descr, colid):<\exit>
column = gtk.TreeViewColumn(descr, gtk.CellRendererText(), text=colid)<\exit>
treeview.append_column(column)<\exit>
add_column("Time", self.COLUMN_TIME)<\exit>
add_column("Interface", self.COLUMN_INTERFACE)<\exit>
add_column("Size", self.COLUMN_SIZE)<\exit>
add_column("Contents", self.COLUMN_CONTENTS)<\exit>
def update(self, node, packet_list):<\exit>
self.table_model.clear()<\exit>
for sample in packet_list:<\exit>
tree_iter = self.table_model.append()<\exit>
if sample.device is None:<\exit>
interface_name = "(unknown)"<\exit>
else:<\exit>
interface_name = ns.core.Names.FindName(sample.device)<\exit>
if not interface_name:<\exit>
interface_name = "(interface %i)" % sample.device.GetIfIndex()<\exit>
self.table_model.set(tree_iter,<\exit>
self.COLUMN_TIME, str(sample.time.GetSeconds()),<\exit>
self.COLUMN_INTERFACE, interface_name,<\exit>
self.COLUMN_SIZE, str(sample.packet.GetSize ()),<\exit>
self.COLUMN_CONTENTS, str(sample.packet)<\exit>
)<\exit>
def __init__(self, visualizer, node_index):<\exit>
InformationWindow.__init__(self)<\exit>
self.win = gtk.Dialog(parent=visualizer.window,<\exit>
flags=gtk.DIALOG_DESTROY_WITH_PARENT|gtk.DIALOG_NO_SEPARATOR,<\exit>
buttons=(gtk.STOCK_CLOSE, gtk.RESPONSE_CLOSE))<\exit>
self.win.connect("response", self._response_cb)<\exit>
self.win.set_title("Last packets for node %i" % node_index)<\exit>
self.visualizer = visualizer<\exit>
self.viz_node = visualizer.get_node(node_index)<\exit>
self.node = ns.network.NodeList.GetNode(node_index)<\exit>
def smart_expand(expander, vbox):<\exit>
if expander.get_expanded():<\exit>
vbox.set_child_packing(expander, expand=True, fill=True, padding=0, pack_type=gtk.PACK_START)<\exit>
else:<\exit>
vbox.set_child_packing(expander, expand=False, fill=False, padding=0, pack_type=gtk.PACK_START)<\exit>
main_hbox = gtk.HBox(False, 4)<\exit>
main_hbox.show()<\exit>
main_vbox = gtk.VBox(False, 4)<\exit>
main_vbox.show()<\exit>
self.win.vbox.add(main_hbox)<\exit>
main_hbox.add(main_vbox)<\exit>
self.tx_list = self.PacketList()<\exit>
self.tx_list.show()<\exit>
group = gtk.Expander("Last transmitted packets")<\exit>
group.show()<\exit>
group.add(self.tx_list)<\exit>
main_vbox.pack_start(group, expand=False, fill=False)<\exit>
group.connect_after("activate", smart_expand, main_vbox)<\exit>
self.rx_list = self.PacketList()<\exit>
self.rx_list.show()<\exit>
group = gtk.Expander("Last received packets")<\exit>
group.show()<\exit>
group.add(self.rx_list)<\exit>
main_vbox.pack_start(group, expand=False, fill=False)<\exit>
group.connect_after("activate", smart_expand, main_vbox)<\exit>
self.drop_list = self.PacketList()<\exit>
self.drop_list.show()<\exit>
group = gtk.Expander("Last dropped packets")<\exit>
group.show()<\exit>
group.add(self.drop_list)<\exit>
main_vbox.pack_start(group, expand=False, fill=False)<\exit>
group.connect_after("activate", smart_expand, main_vbox)<\exit>
self.packet_capture_options = ns.visualizer.PyViz.PacketCaptureOptions()<\exit>
self.packet_capture_options.numLastPackets = 100<\exit>
packet_filter_vbox = gtk.VBox(False, 4)<\exit>
packet_filter_vbox.show()<\exit>
main_hbox.add(packet_filter_vbox)<\exit>
sel_buttons_box = gtk.HButtonBox()<\exit>
sel_buttons_box.show()<\exit>
packet_filter_vbox.pack_start(sel_buttons_box, False, False, 4)<\exit>
select_all_button = gobject.new(gtk.Button, label="Sel. All", visible=True)<\exit>
select_none_button = gobject.new(gtk.Button, label="Sel. None", visible=True)<\exit>
sel_buttons_box.add(select_all_button)<\exit>
sel_buttons_box.add(select_none_button)<\exit>
self.packet_filter_widget = ObjectList([<\exit>
Column('selected', title="Sel.", data_type=bool, editable=True),<\exit>
Column('name', title="Header"),<\exit>
], sortable=True)<\exit>
self.packet_filter_widget.show()<\exit>
packet_filter_vbox.pack_start(self.packet_filter_widget, True, True, 4)<\exit>
class TypeIdConfig(object):<\exit>
__slots__ = ['name', 'selected', 'typeid']<\exit>
self.packet_filter_list = []<\exit>
Header = ns.core.TypeId.LookupByName("ns3::Header")<\exit>
Trailer = ns.core.TypeId.LookupByName("ns3::Trailer")<\exit>
for typeid_i in range(ns.core.TypeId.GetRegisteredN()):<\exit>
typeid = ns.core.TypeId.GetRegistered(typeid_i)<\exit>
typeid_tmp = typeid<\exit>
type_is_good = False<\exit>
while 1:<\exit>
if typeid_tmp == Header or typeid_tmp == Trailer:<\exit>
type_is_good = True<\exit>
break<\exit>
if typeid_tmp.HasParent():<\exit>
typeid_tmp = typeid_tmp.GetParent()<\exit>
else:<\exit>
break<\exit>
if not type_is_good:<\exit>
